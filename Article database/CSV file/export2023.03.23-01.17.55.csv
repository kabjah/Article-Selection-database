Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans,O. Ozdemir; R. L. Russell; A. A. Berlin,"Google, Cambridge, USA; Draper, Cambridge, USA; Draper, Cambridge, USA",IEEE Transactions on Medical Imaging,1-May-20,2020,39,5,1419,1429,"We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results.",1558-254X,,10.1109/TMI.2019.2947595,Charles Stark Draper Laboratory IR&D program under the guidance of Amy Duwel and Sheila Hemami; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886352,Machine learning;artificial neural networks;medical diagnostic imaging;image segmentation;image classification,Solid modeling;Lung;Three-dimensional displays;Cancer;Computed tomography;Deep learning;Uncertainty,cancer;computerised tomography;convolutional neural nets;decision making;diseases;image classification;learning (artificial intelligence);lung;medical image processing,computer aided detection;3D probabilistic deep learning system;probability-based patient referral strategy;patient malignancy diagnosis;classification probabilities;lung CT analysis;deep learning systems;end-to-end system;diagnosis components;nodule detection systems;Kaggle Data Science Bowl;malignancy classification tasks;lung nodule detection;low-dose CT scans;lung cancer screening;diagnosis system,"Deep Learning;Early Detection of Cancer;Humans;Imaging, Three-Dimensional;Lung Neoplasms;Tomography, X-Ray Computed",72,,34,CCBY,30-Oct-19,,,IEEE,IEEE Journals
Semi-Supervised Deep Transfer Learning for Benign-Malignant Diagnosis of Pulmonary Nodules in Chest CT Images,F. Shi; B. Chen; Q. Cao; Y. Wei; Q. Zhou; R. Zhang; Y. Zhou; W. Yang; X. Wang; R. Fan; F. Yang; Y. Chen; W. Li; Y. Gao; D. Shen,"Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; Department of Respiratory and Critical Care Medicine, West China Hospital of Sichuan University, Chengdu, China; Department of Radiology, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; Department of Respiratory and Critical Care Medicine, West China Hospital of Sichuan University, Chengdu, China; Department of Respiratory and Critical Care Medicine, West China Hospital of Sichuan University, Chengdu, China; Department of Radiology, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Radiology, Changzheng Hospital, Second Military Medical University, Shanghai, China; Department of Radiology, Changzheng Hospital, Second Military Medical University, Shanghai, China; Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; Department of Respiratory and Critical Care Medicine, West China Hospital of Sichuan University, Chengdu, China; Department of Research and Development, Shanghai United Imaging Intelligence Company Ltd, Shanghai, China; School of Biomedical Engineering, ShanghaiTech University, Shanghai, China",IEEE Transactions on Medical Imaging,1-Apr-22,2022,41,4,771,781,"Lung cancer is the leading cause of cancer deaths worldwide. Accurately diagnosing the malignancy of suspected lung nodules is of paramount clinical importance. However, to date, the pathologically-proven lung nodule dataset is largely limited and is highly imbalanced in benign and malignant distributions. In this study, we proposed a Semi-supervised Deep Transfer Learning (SDTL) framework for benign-malignant pulmonary nodule diagnosis. First, we utilize a transfer learning strategy by adopting a pre-trained classification network that is used to differentiate pulmonary nodules from nodule-like tissues. Second, since the size of samples with pathological-proven is small, an iterated feature-matching-based semi-supervised method is proposed to take advantage of a large available dataset with no pathological results. Specifically, a similarity metric function is adopted in the network semantic representation space for gradually including a small subset of samples with no pathological results to iteratively optimize the classification network. In this study, a total of 3,038 pulmonary nodules (from 2,853 subjects) with pathologically-proven benign or malignant labels and 14,735 unlabeled nodules (from 4,391 subjects) were retrospectively collected. Experimental results demonstrate that our proposed SDTL framework achieves superior diagnosis performance, with accuracy = 88.3%, AUC = 91.0% in the main dataset, and accuracy = 74.5%, AUC = 79.5% in the independent testing dataset. Furthermore, ablation study shows that the use of transfer learning provides 2% accuracy improvement, and the use of semi-supervised learning further contributes 2.9% accuracy improvement. Results implicate that our proposed classification network could provide an effective diagnostic tool for suspected lung nodules, and might have a promising application in clinical practice.",1558-254X,,10.1109/TMI.2021.3123572,National Key Research and Development Program of China(grant numbers:2018YFC0116400); National Natural Science Foundation of China(grant numbers:91859203); Sichuan International Science and Technology Innovation Cooperation/ HongKong-Macao-Taiwan Science and Technology Innovation Cooperation Project(grant numbers:2018HH0161); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591607,Pulmonary nodule;deep learning;transfer learning;semi-supervised learning;benign-malignant classification,Lung;Computed tomography;Lung cancer;Tumors;Transfer learning;Semisupervised learning;Medical diagnostic imaging,cancer;computerised tomography;deep learning (artificial intelligence);feature extraction;image classification;lung;medical image processing;semi-supervised learning (artificial intelligence);tumours,pulmonary nodules;SDTL framework;independent testing dataset;suspected lung nodules;semisupervised deep transfer learning;benign-malignant diagnosis;chest CT;lung cancer;cancer deaths;paramount clinical importance;pathologically-proven lung nodule dataset;benign distributions;malignant distributions;benign-malignant pulmonary nodule diagnosis;transfer learning strategy;pre-trained classification network;differentiate pulmonary nodules;nodule-like tissues;iterated feature-matching-based semisupervised method;network semantic representation space,"Humans;Lung Neoplasms;Retrospective Studies;Solitary Pulmonary Nodule;Supervised Machine Learning;Tomography, X-Ray Computed",9,,33,IEEE,27-Oct-21,,,IEEE,IEEE Journals
EGFR Assessment in Lung Cancer CT Images: Analysis of Local and Holistic Regions of Interest Using Deep Unsupervised Transfer Learning,F. Silva; T. Pereira; J. Morgado; J. Frade; J. Mendes; C. Freitas; E. Negrão; B. F. De Lima; M. C. D. Silva; A. J. Madureira; I. Ramos; V. Hespanhol; J. L. Costa; A. Cunha; H. P. Oliveira,"Faculty of Engineering, University of Porto (FEUP), Porto, Portugal; Institute for Systems and Computer Engineering, Technology and Science (INESC TEC), Porto, Portugal; Faculty of Science, University of Porto (FCUP), Porto, Portugal; Faculty of Engineering, University of Porto (FEUP), Porto, Portugal; Faculty of Engineering, University of Porto (FEUP), Porto, Portugal; Faculty of Medicine, University of Porto (FMUP), Porto, Portugal; Centro Hospitalar e Universitário de São João (CHUSJ), Porto, Portugal; Centro Hospitalar e Universitário de São João (CHUSJ), Porto, Portugal; Centro Hospitalar e Universitário de São João (CHUSJ), Porto, Portugal; Faculty of Medicine, University of Porto (FMUP), Porto, Portugal; Faculty of Medicine, University of Porto (FMUP), Porto, Portugal; Faculty of Medicine, University of Porto (FMUP), Porto, Portugal; Institute of Molecular Pathology and Immunology, University of Porto (IPATIMUP), Porto, Portugal; University of Trás-os-Montes and Alto Douro (UTAD), Vila Real, Portugal; Faculty of Science, University of Porto (FCUP), Porto, Portugal",IEEE Access,20-Apr-21,2021,9,,58667,58676,"Statistics have demonstrated that one of the main factors responsible for the high mortality rate related to lung cancer is the late diagnosis. Precision medicine practices have shown advances in the individualized treatment according to the genetic profile of each patient, providing better control on cancer response. Medical imaging offers valuable information with an extensive perspective of the cancer, opening opportunities to explore the imaging manifestations associated with the tumor genotype in a non-invasive way. This work aims to study the relevance of physiological features captured from Computed Tomography images, using three different 2D regions of interest to assess the Epidermal growth factor receptor (EGFR) mutation status: nodule, lung containing the main nodule, and both lungs. A Convolutional Autoencoder was developed for the reconstruction of the input image. Thereafter, the encoder block was used as a feature extractor, stacking a classifier on top to assess the EGFR mutation status. Results showed that extending the analysis beyond the local nodule allowed the capture of more relevant information, suggesting the presence of useful biomarkers using the lung with nodule region of interest, which allowed to obtain the best prediction ability. This comparative study represents an innovative approach for gene mutations status assessment, contributing to the discussion on the extent of pathological phenomena associated with cancer development, and its contribution to more accurate Artificial Intelligence-based solutions, and constituting, to the best of our knowledge, the first deep learning approach that explores a comprehensive analysis for the EGFR mutation status classification.",2169-3536,,10.1109/ACCESS.2021.3070701,"European Regional Development Fund (ERDF) through the Operational Program for Competitiveness and Internationalization—COMPETE 2020 Program; National Funds through the Portuguese Funding Agency, Fundação para a Ciência e a Tecnologia (FCT)(grant numbers:POCI-01-0145-FEDER-030263); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393886,Convolutional autoencoder;EGFR prediction;lung cancer;transfer learning;unsupervised feature learning,Computed tomography;Lung;Feature extraction;Lung cancer;Transfer learning;Databases;Tumors,cancer;computerised tomography;feature extraction;genetics;image classification;learning (artificial intelligence);lung;medical computing;medical image processing;patient diagnosis;patient treatment;tumours,EGFR assessment;EGFR mutation status classification;deep learning approach;cancer development;gene mutations status assessment;local nodule;feature extractor;input image;main nodule;Epidermal growth factor receptor mutation status;Computed Tomography images;physiological features;tumor genotype;imaging manifestations;extensive perspective;medical imaging offers valuable information;cancer response;genetic profile;individualized treatment;precision medicine practices;late diagnosis;high mortality rate;deep unsupervised transfer learning;lung cancer CT images,,13,,30,CCBYNCND,2-Apr-21,,,IEEE,IEEE Journals
LDNNET: Towards Robust Classification of Lung Nodule and Cancer Using Lung Dense Neural Network,Y. Chen; Y. Wang; F. Hu; L. Feng; T. Zhou; C. Zheng,"School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China",IEEE Access,5-Apr-21,2021,9,,50301,50320,"Lung nodule classification plays an important role in diagnosis of lung cancer which is essential to patients' survival. However, because the number of lung CT images in current dataset is relatively small and the ratio of nodule samples to non-nodule samples is usually very different, this makes the training of neural networks difficult and poor performance of neural networks. Hence, LDNNET is proposed, which adopts Dense-Block, batch normalization (BN) and dropout to cope with these problems. Meanwhile, LDNNET is an adaptive architecture based on convnets combining softmax classifier which is utilized to alleviate the problems of training deep convnets. Follows are our main work: Firstly, we utilized LDNNET on database LUng Nodule Analysis 2016 (LUNA16) for lung nodule classification and database KAGGLE DATA-SCIENCE-BOWL-2017(Kaggle DSB 2017) for lung cancer classification; Secondly, the comparison experiments are designed to compare the performance of dense connection, pooling layer and the input pixel size of lung CT(Computed Tomography) images; Thirdly, data enhancement, dense connection and dropout layer were utilized in LDNNET to reduce overfitting; Fourthly, pre-processing methods, for instance enhanced contrast, median filtering, Laplacian filtering are compared to the no-processing method to explore the effect of pre-processing on lung CT images classification. Fifthly, accuracy, specificity and sensitivity on LUNA16 are 0.988396, 0.994585 and 0.982072 and these indicators on Kaggle DSB 2017 are 0.999480, 0.999652 and 0.998974. Furthermore, AUC for both two datasets is over 0.98. Consequently, this paper conducts experiments with uniform parameter settings on two publicly available databases and shows that even in challenging situation where lung images are directly utilized as input images without preprocessing, LDNNET is still the more advanced algorithm than other recent algorithms respectively. Moreover, a series of comparative experiments were conducted to further confirm that the proposed algorithm has the higher accuracy and robustness through verification and discussion.",2169-3536,,10.1109/ACCESS.2021.3068896,"National Natural Science Foundation of China(grant numbers:61762067,61867004); Natural Science Foundation of Jiangxi Province(grant numbers:20202BABC202029,20202BABC202028); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386129,Deep dense neural network;classification;lung nodule;lung cancer,Lung;Computed tomography;Lung cancer;Classification algorithms;Feature extraction;Neural networks;Medical diagnostic imaging,cancer;computerised tomography;deep learning (artificial intelligence);image classification;image filtering;lung;medical image processing;neural nets,Laplacian filtering;median filtering;dropout layer;computed tomography images;pooling layer;Kaggle DSB 2017 database;KAGGLE DATA-SCIENCE-BOWL-2017 database;softmax classifier;batch normalization;lung dense neural network;LUNA16 database;LUng Nodule Analysis 2016 database;deep convnets;Dense-Block;nonnodule samples;lung CT images classification;dense connection;lung cancer classification;lung nodule classification;LDNNET,,4,,56,CCBY,24-Mar-21,,,IEEE,IEEE Journals
Self-Supervised Transfer Learning Based on Domain Adaptation for Benign-Malignant Lung Nodule Classification on Thoracic CT,H. Huang; R. Wu; Y. Li; C. Peng,"Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing, China; Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing, China; Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing, China; Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing, China",IEEE Journal of Biomedical and Health Informatics,11-Aug-22,2022,26,8,3860,3871,"The spatial heterogeneity is an important indicator of the malignancy of lung nodules in lung cancer diagnosis. Compared with 2D nodule CT images, the 3D volumes with entire nodule objects hold richer discriminative information. However, for deep learning methods driven by massive data, effectively capturing the 3D discriminative features of nodules in limited labeled samples is a challenging task. Different from previous models that proposed transfer learning models in a 2D pattern or learning from scratch 3D models, we develop a self-supervised transfer learning based on domain adaptation (SSTL-DA) 3D CNN framework for benign-malignant lung nodule classification. At first, a data pre-processing strategy termed adaptive slice selection (ASS) is developed to eliminate the redundant noise of the input samples with lung nodules. Then, the self-supervised learning network is constructed to learn robust image representations from CT images. Finally, a transfer learning method based on domain adaptation is designed to obtain discriminant features for classification. The proposed SSTL-DA method has been assessed on the LIDC-IDRI benchmark dataset, and it obtains an accuracy of 91.07% and an AUC of 95.84%. These results demonstrate that the SSTL-DA model achieves quite a competitive classification performance compared with some state-of-the-art approaches",2168-2208,,10.1109/JBHI.2022.3171851,National Natural Science Foundation of China(grant numbers:42071302); Graduate Research and Innovation Foundation of Chongqing(grant numbers:CYB21060); Fundamental Research Funds for the Central Universities(grant numbers:2019CDYGYB008); Innovation Program for Chongqing Overseas Returnees(grant numbers:cx2019144); Visiting Scholar Foundation of Key Laboratory of Optoelectronic Technology and Systems; NVIDIA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767702,Lung nodule classification;3D transfer learning;self-supervised learning;domain adaptation learning;thoracic CT,Lung;Feature extraction;Three-dimensional displays;Computed tomography;Task analysis;Solid modeling;Adaptation models,cancer;computerised tomography;convolutional neural nets;deep learning (artificial intelligence);feature extraction;image classification;image denoising;image representation;lung;medical image processing;supervised learning,lung cancer diagnosis;2D nodule CT images;discriminative information;deep learning methods;scratch 3D models;self-supervised transfer learning;domain adaptation 3D CNN framework;benign-malignant lung nodule classification;adaptive slice selection;self-supervised learning network;computed tomography;nodule objects;thoracic CT;spatial heterogeneity;3D discriminative features;data preprocessing strategy;redundant noise elimination;robust image representations;LIDC-IDRI benchmark dataset,"Deep Learning;Humans;Lung;Lung Neoplasms;Radiographic Image Interpretation, Computer-Assisted;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",6,,59,IEEE,3-May-22,,,IEEE,IEEE Journals
Integrating Lung Parenchyma Segmentation and Nodule Detection With Deep Multi-Task Learning,W. Liu; X. Liu; H. Li; M. Li; X. Zhao; Z. Zhu,"Beijing Lab of Intelligent Information, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Lab of Intelligent Information, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Lab of Intelligent Information, School of Computer Science, Beijing Institute of Technology, Beijing, China; Department of Computer Science, Brunel University London, Uxbridge, Middlesex, U.K.; Department of Imaging Diagnosis Chinese, Cancer Hospital, Academy of Medical Sciences, Beijing, China; Department of Imaging Diagnosis Chinese, Cancer Hospital, Academy of Medical Sciences, Beijing, China",IEEE Journal of Biomedical and Health Informatics,5-Aug-21,2021,25,8,3073,3081,"Lung parenchyma segmentation is valuable for improving the performance of lung nodule detection in computed tomography (CT) images. Traditionally, the two tasks are performed separately. This paper proposes a deep multi-task learning (MTL) approach to integrate these tasks for better lung nodule detection. Three new ideas lead to our proposed approach. First, lung parenchyma segmentation is used as the attention module and is combined with nodule detection in a single deep network. Second, lung nodule detection is performed in an anchor-free manner by dividing it into two subtasks, nodule center identification and nodule size regression. Third, a novel pyramid dilated convolution block (PDCB) is proposed to utilize the advantage of dilated convolution and tackle its gridding problem for better lung parenchyma segmentation. Based on these ideas, we design our end-to-end deep network architecture and corresponding MTL method to achieve lung parenchyma segmentation and nodule detection simultaneously. We evaluate the proposed approach on the commonly used Lung Nodule Analysis 2016 (LUNA16) dataset. The experimental results show the value of our contributions and demonstrate that our approach can yield significant improvements compared with state-of-the-art counterparts.",2168-2208,,10.1109/JBHI.2021.3053023,"Beijing Municipal Science, and Technology Project(grant numbers:Z181100001918002); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9329031,Deep convolutional networks;lung nodule detection;lung paranchyma segmentation;multi-tasking learning,Lung;Image segmentation;Convolution;Computed tomography;Task analysis;Feature extraction;Three-dimensional displays,computerised tomography;image segmentation;learning (artificial intelligence);lung;medical image processing,lung nodule detection;nodule center identification;nodule size regression;lung parenchyma segmentation;commonly used Lung Nodule Analysis 2016 dataset;deep multitask learning,"Humans;Lung;Lung Neoplasms;Tomography, X-Ray Computed",10,,51,IEEE,20-Jan-21,,,IEEE,IEEE Journals
Efficient Lung Nodule Classification Using Transferable Texture Convolutional Neural Network,I. Ali; M. Muzammil; I. U. Haq; A. A. Khaliq; S. Abdullah,"Faculty of Engineering and Technology, International Islamic University, Islamabad, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Islamabad, Pakistan",IEEE Access,1-Oct-20,2020,8,,175859,175870,"Lung nodules are vital indicators for the presence of lung cancer. An early detection enhances the survival rate of the patient by starting treatment at the right time. The detection and classification of malignancy in Computed Tomography (CT) images is a very time-consuming and difficult task for radiologists which lead the researchers to develop algorithms for Computer-Aided Diagnosis (CAD) systems to mitigate this burden. The performance of CAD systems is continuously improving by using various deep learning techniques for screening of lung cancer. In this paper, we proposed transferable texture Convolutional Neural Networks (CNN) to improve the classification performance of pulmonary nodules in CT scans. An Energy Layer (EL) is incorporated in our scheme, which extracts texture features from the convolutional layer. The inclusion of EL reduces the number of learnable parameters of the network, which further reduces the memory requirements and computational complexity. The proposed model has only three convolutional layers and one EL, instead of pooling layer. Overall proposed CNN architecture comprises of nine layers for automatic feature extraction and classification of pulmonary nodule candidates as malignant or benign. Furthermore, the pre-trained model of proposed CNN is also used to handle the smaller dataset classification problem by using transfer learning. This work has been evaluated on publicly available LIDC-IDRI and the LUNGx Challenge database through different evaluation matrices, such as; the accuracy, specificity, error rate and AUC. The proposed model is trained by six-fold cross-validation and achieved an accuracy score of 96.69%±0.72% with only 3.30%±0.72% error rate. Whereas, the measured AUC and recall is 99.11%±0.45% and 97.19%±0.57%, respectively. Moreover, we also tested our proposed technique on the MNIST dataset and achieved state-of-the-art results in terms of accuracy and error rate.",2169-3536,,10.1109/ACCESS.2020.3026080,Higher Education Commission(grant numbers:20-4849/NRPU/R&D/HEC/14/1215); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204580,Computed tomography;cancer detection;computer aided diagnosis;image classification;machine learning;transfer learning;lung nodule;CNN;LIDC-IDRI;LUNGx challenge,Lung;Feature extraction;Cancer;Databases;Computed tomography;Biomedical imaging;Task analysis,CAD;cancer;computerised tomography;convolutional neural nets;feature extraction;image classification;image segmentation;image texture;learning (artificial intelligence);lung;medical image processing,efficient lung nodule classification;transferable texture convolutional neural network;lung nodules;lung cancer;computed tomography images;computer-aided diagnosis systems;CAD systems;deep learning techniques;pulmonary nodules;energy layer;texture features;convolutional layer;computational complexity;feature extraction;pulmonary nodule;transfer learning;dataset classification problem;transferable texture convolutional neural networks;CT scan;LIDC-IDRI,,22,,55,CCBY,23-Sep-20,,,IEEE,IEEE Journals
HSN: Hybrid Segmentation Network for Small Cell Lung Cancer Segmentation,W. Chen; H. Wei; S. Peng; J. Sun; X. Qiao; B. Liu,"Department of Biomedical Engineering, Shandong University, Jinan, China; First Clinical Medical College, Shandong University of Traditional Chinese Medicine, Jinan, China; Department of Biomedical Engineering, Shandong University, Jinan, China; Department of Biomedical Engineering, Shandong University, Jinan, China; Department of Biomedical Engineering, Shandong University, Jinan, China; Department of Biomedical Engineering, Shandong University, Jinan, China",IEEE Access,19-Jun-19,2019,7,,75591,75603,"Small cell lung cancer (SCLC) is one of the most common types of malignant tumors, characterized by rapid growth and early metastasis spread. Early and accurate diagnosis of SCLC is vital for improved survival. Accurate cancer segmentation helps doctors understand the location and size of cancer and make better diagnostic decisions. However, manual segmentation of lung cancers from large amounts of medical images is a time-consuming and challenging task. In this paper, we propose a hybrid segmentation network (referred to as HSN) based on convolutional neural network (CNN) to automatically segment SCLC from computed tomography (CT) images. The design philosophy of our model is to combine a lightweight 3D CNN to learn long-range 3D contextual information and a 2D CNN to learn fine-grained semantic information, which is essential for accurate cancer segmentation. We propose a hybrid features fusion module to effectively fuse the 2D and 3D features and to jointly train these two CNNs. We utilize a generalized Dice loss function to tackle the severe class imbalance problem in data. A dataset consists of 134 CT scans was constructed to evaluate our model. Our model achieved high performances with a mean Dice score of 0.888, a mean sensitivity score of 0.872 and a mean precision of 0.909, outperforming the other state-of-the-art 2D and 3D CNN methods by a large margin.",2169-3536,,10.1109/ACCESS.2019.2921434,"Department of Science and Technology of Shandong Province(grant numbers:2017CXGC1502); Natural Science Foundation of Shandong Province(grant numbers:ZR2014HQ054); National Natural Science Foundation of China(grant numbers:61603218,U1806202); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732325,Small cell lung cancer;CT;deep convolutional neural network;hybrid features fusion,Three-dimensional displays;Cancer;Two dimensional displays;Computed tomography;Image segmentation;Lung;Biomedical imaging,cancer;computerised tomography;convolutional neural nets;feature extraction;image fusion;image segmentation;lung;medical image processing;patient diagnosis;tumours,CNN;computed tomography images;long-range 3D contextual information;accurate cancer segmentation;hybrid features fusion module;HSN;hybrid segmentation network;small cell lung cancer segmentation;early metastasis spread;convolutional neural network;malignant tumors;accurate SCLC diagnosis;generalized Dice loss function;2D feature fusion;3D feature fusion,,23,,38,OAPA,6-Jun-19,,,IEEE,IEEE Journals
A Lightweight Multi-Section CNN for Lung Nodule Classification and Malignancy Estimation,P. Sahu; D. Yu; M. Dasari; F. Hou; H. Qin,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; Martin Tuchman School of Management, New Jersey Institute of Technology, Newark, NJ, USA; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Science, Beijing, China; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",IEEE Journal of Biomedical and Health Informatics,3-May-19,2019,23,3,960,968,"The size and shape of a nodule are the essential indicators of malignancy in lung cancer diagnosis. However, effectively capturing the nodule's structural information from CT scans in a computer-aided system is a challenging task. Unlike previous models that proposed computationally intensive deep ensemble models or three-dimensional CNN models, we propose a lightweight, multiple view sampling based multi-section CNN architecture. The model obtains a nodule's cross sections from multiple view angles and encodes the nodule's volumetric information into a compact representation by aggregating information from its different cross sections via a view pooling layer. The compact feature is subsequently used for the task of nodule classification. The method does not require the nodule's spatial annotation and works directly on the cross sections generated from volume enclosing the nodule. We evaluated the proposed method on lung image database consortium (LIDC) and image database resource initiative (IDRI) dataset. It achieved the state-of-the-art performance with a mean 93.18% classification accuracy. The architecture could also be used to select the representative cross sections determining the nodule's malignancy that facilitates in the interpretation of results. Because of being lightweight, the model could be ported to mobile devices, which brings the power of artificial intelligence (AI) driven application directly into the practitioner's hand.",2168-2208,,10.1109/JBHI.2018.2879834,Brookhaven National Laboratory and National Science Foundation(grant numbers:NSF IIS-1715985); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525322,Lung cancer;deep learning;nodule classification;transfer Learning;spherical sampling,Lung;Cancer;Three-dimensional displays;Training;Task analysis;Computational modeling;Feature extraction,cancer;computerised tomography;image classification;lung;medical image processing;visual databases,nodule's malignancy;image database resource initiative dataset;lung image database consortium;pooling layer;classification accuracy;compact feature;compact representation;multiple view angles;multisection CNN architecture;multiple view sampling;lightweight view sampling;three-dimensional CNN models;computer-aided system;CT scans;lung cancer diagnosis;malignancy estimation;lung nodule classification;lightweight multisection CNN,"Algorithms;Humans;Imaging, Three-Dimensional;Lung;Lung Neoplasms;Neural Networks, Computer;ROC Curve;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",41,,31,IEEE,6-Nov-18,,,IEEE,IEEE Journals
A Deep Model for Lung Cancer Type Identification by Densely Connected Convolutional Networks and Adaptive Boosting,S. Pang; Y. Zhang; M. Ding; X. Wang; X. Xie,"College of Computer Science and Technology, China University of Petroleum, Qingdao, China; College of Computer Science and Technology, China University of Petroleum, Qingdao, China; Department of Neurology, The Second Hospital of Shandong University, Jinan, China; College of Computer Science and Technology, China University of Petroleum, Qingdao, China; Department of Respiratory Medicine, Shandong Provincial Third Hospital, Jinan, China",IEEE Access,9-Jan-20,2020,8,,4799,4805,"Timely diagnosis and determination to the type of lung cancer has important clinical significance. Generally, it requires multiple imaging methods to complement each other to obtain a comprehensive diagnosis. In this work, we propose a deep learning model to identify lung cancer type from CT images for patients in Shandong Provincial Hospital. It has a two-fold challenge: artificial intelligent models trained by public datasets cannot meet such practical requires, and the amount of collected patients' data is quite few. To solve the two-fold problem, we use image rotation, translation and transformation methods to expand and balance our training data, and then densely connected convolutional networks (DenseNet) is used to classify malignant tumor from images collected from, and finally adaptive boosting (adaboost) algorithm is used to aggregate multiple classification results to improve classification performance. Experimental results show that our method can achieve identifying accuracy 89.85%, which performs better than DenseNet without adaboost, ResNet, VGG16 and AlexNet. This provides an efficient, non-invasive detection tool for pathological diagnosis to lung cancer type.",2169-3536,,10.1109/ACCESS.2019.2962862,"National Natural Science Foundation of China(grant numbers:61572523,61502535,61972416); Key Technology Research and Development Program of Shandong(grant numbers:2019GGX101067); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945194,Adaboost algorithm;data enhancement;densely connected convolutional networks;lung cancer,Lung cancer;Convolution;Training;Computed tomography;Computational modeling;Hospitals,cancer;computerised tomography;convolutional neural nets;diseases;image classification;learning (artificial intelligence);lung;medical image processing;patient diagnosis;tumours,AlexNet;VGG16;ResNet;DenseNet;malignant tumor classification;noninvasive detection tool;Shandong provincial hospital;adaboost algorithm;image rotation;artificial intelligent models;CT images;deep learning model;comprehensive diagnosis;multiple imaging methods;important clinical significance;lung cancer type identification;pathological diagnosis;multiple classification results;adaptive boosting algorithm;densely connected convolutional networks,,17,,30,CCBY,30-Dec-19,,,IEEE,IEEE Journals
A Joint Detection and Recognition Approach to Lung Cancer Diagnosis From CT Images With Label Uncertainty,L. Chenyang; S. -C. Chan,"Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong",IEEE Access,30-Dec-20,2020,8,,228905,228921,"Automatic lung cancer diagnosis from computer tomography (CT) images requires the detection of nodule location as well as nodule malignancy prediction. This article proposes a joint lung nodule detection and classification network for simultaneous lung nodule detection, segmentation and classification subject to possible label uncertainty in the training set. It operates in an end-to-end manner and provides detection and classification of nodules simultaneously together with a segmentation of the detected nodules. Both the nodule detection and classification subnetworks of the proposed joint network adopt a 3-D encoder-decoder architecture for better exploration of the 3-D data. Moreover, the classification subnetwork utilizes the features extracted from the detection subnetwork and multiscale nodule-specific features for boosting the classification performance. The former serves as valuable prior information for optimizing the more complicated 3D classification network directly to better distinguish suspicious nodules from other tissues compared with direct backpropagation from the decoder. Experimental results show that this co-training yields better performance on both tasks. The framework is validated on the LUNA16 and LIDC-IDRI datasets and a pseudo-label approach is proposed for addressing the label uncertainty problem due to inconsistent annotations/labels. Experimental results show that the proposed nodule detector outperforms the state-of-the-art algorithms and yields comparable performance as state-of-the-art nodule classification algorithms when classification alone is considered. Since our joint detection/recognition approach can directly detect nodules and classify its malignancy instead of performing the tasks separately, our approach is more practical for automatic cancer and nodules detection.",2169-3536,,10.1109/ACCESS.2020.3044941,Hong Kong Research Grant Council General Research Fund(grant numbers:GRF 17211320); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9294013,Deep learning;multi-task learning;nodule detection;nodule malignancy classification;label noise,Cancer;Computed tomography;Lung;Feature extraction;Training;Task analysis;Three-dimensional displays,backpropagation;cancer;computerised tomography;feature extraction;image classification;image segmentation;lung;medical image processing,CT images;automatic lung cancer diagnosis;computer tomography images;nodule location;nodule malignancy prediction;joint lung nodule detection;simultaneous lung nodule detection;classification subnetwork;3-D encoder-decoder architecture;multiscale nodule-specific features;pseudolabel approach;label uncertainty problem;nodule detector;state-of-the-art nodule classification algorithms;LIDC-IDRI datasets,,6,,60,CCBY,15-Dec-20,,,IEEE,IEEE Journals
Automatic Lung Nodule Detection Combined With Gaze Information Improves Radiologists’ Screening Performance,G. Aresta; C. Ferreira; J. Pedrosa; T. Araújo; J. Rebelo; E. Negrão; M. Morgado; F. Alves; A. Cunha; I. Ramos; A. Campilho,"Institute for Systems and Computer Engineering, Technology and Science (INESC TEC), Porto, Portugal; FEUP and INESC TEC, Porto, Portugal; INESC TEC, Porto, Portugal; FEUP and INESC TEC, Porto, Portugal; Faculty of Medicine of University of Porto (FMUP), Porto, Portugal; Faculty of Medicine of University of Porto (FMUP), Porto, Portugal; Faculty of Medicine of University of Porto (FMUP), Porto, Portugal; Faculty of Medicine of University of Porto (FMUP), Porto, Portugal; INESC TEC, University of Trás-os-Montes e Alto Douro (UTAD), Vila Real, Portugal; Faculty of Medicine of University of Porto (FMUP), Porto, Portugal; INESC TEC and FEUP, Porto, Portugal",IEEE Journal of Biomedical and Health Informatics,7-Oct-20,2020,24,10,2894,2901,"Early diagnosis of lung cancer via computed tomography can significantly reduce the morbidity and mortality rates associated with the pathology. However, searching lung nodules is a high complexity task, which affects the success of screening programs. Whilst computer-aided detection systems can be used as second observers, they may bias radiologists and introduce significant time overheads. With this in mind, this study assesses the potential of using gaze information for integrating automatic detection systems in the clinical practice. For that purpose, 4 radiologists were asked to annotate 20 scans from a public dataset while being monitored by an eye tracker device, and an automatic lung nodule detection system was developed. Our results show that radiologists follow a similar search routine and tend to have lower fixation periods in regions where finding errors occur. The overall detection sensitivity of the specialists was $\mathbf {0.67\pm 0.07}$, whereas the system achieved 0.69. Combining the annotations of one radiologist with the automatic system significantly improves the detection performance to similar levels of two annotators. Filtering automatic detection candidates only for low fixation regions still significantly improves the detection sensitivity without increasing the number of false-positives.",2168-2208,,10.1109/JBHI.2020.2976150,LNDetector; European Regional Development Fund; Operational Programme for Competitiveness - COMPETE 2020 Programme; National Fundus; Portuguese funding agency; Fundação para a Ciência e a Tecnologia(grant numbers:POCI-01-0145-FEDER-016673); FCT(grant numbers:SFRH/BD/120435/2016); FCT(grant numbers:SFRH/BD/146437/2019); FCT(grant numbers:SFRH/BD/122365/2016); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9007735,Lung cancer;computer-aided diagnosis;eye-tracking;deep learning;clinical environment,Lung;Cancer;Sensitivity;Computed tomography;Search problems;Informatics;Task analysis,cancer;computerised tomography;diagnostic radiography;lung;medical image processing,searching lung nodules;mortality rates;computed tomography;lung cancer;automatic detection candidates;detection performance;automatic system;detection sensitivity;automatic lung nodule detection system;eye tracker device;integrating automatic detection systems;gaze information;computer-aided detection systems,"Deep Learning;Eye-Tracking Technology;Fixation, Ocular;Humans;Lung Neoplasms;Radiographic Image Interpretation, Computer-Assisted;Radiologists;Tomography, X-Ray Computed",7,,26,IEEE,24-Feb-20,,,IEEE,IEEE Journals
A Lung Dense Deep Convolution Neural Network for Robust Lung Parenchyma Segmentation,Y. Chen; Y. Wang; F. Hu; D. Wang,"School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China",IEEE Access,28-May-20,2020,8,,93527,93547,"Lung parenchyma segmentation is the prerequisite for an automatic diagnosis system to analyze lung CT (computed tomography) images. However, traditional lung segmentation algorithms have poor adaptability and are not effectively robust regarding lung databases with blood vessels and small voids which can interfere the segmentation. The main work of this paper is as follows: Firstly, a lung dense deep convolutional neural network (LDDNet) is proposed, which adopts some popular optimizer methods, such as dense block, batch normalization (BN) and dropout. The performance of LDDNet is tested on the public lung database LIDC-IDRI which contains many cases of interference for segmentation. Secondly, the labeled with blood vessels and small voids are not contained by the public ground-truth masks of the LIDC-IDRI database, therefore these regions are labeled by us with LabelMe software. Thirdly, for the aim of exploring the effect of image preprocessing on segmenting lung CT images with deep neural network, contrast enhancing, median filtering and Laplacian filtering are used to preprocess the image as comparative experiments. Finally, dataset is classified into four classes by the geometrical shapes to test the performance of LDDNet. The accuracy of the segmentation experiment reaches over 99% and the four classes can all reach over 95%. Additionally, blood vessels and small voids are segmented out from the lung parenchyma which is not achieved by other methods. Experimental results confirm that the proposed LDDNet can segment the lung parenchymal area more accurately and has better robustness in comparison with other neural networks and most of the traditional methods.",2169-3536,,10.1109/ACCESS.2020.2993953,"National Natural Science Foundation of China(grant numbers:61762067,61662049,61867004); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091318,Deep dense neural network;lung segmentation;robustness,Lung;Image segmentation;Computed tomography;Cancer;Clustering algorithms;Biomedical imaging;Neural networks,blood vessels;computerised tomography;convolutional neural nets;image classification;image filtering;image segmentation;learning (artificial intelligence);lung;median filters;medical image processing,LDDNet;blood vessels;voids;lung dense deep convolution neural network;robust lung parenchyma segmentation;lung CT images;public lung database;LIDC-IDRI database;batch normalization;public ground-truth masks;LabelMe software;contrast enhancing;median filtering;Laplacian filtering,,9,,44,CCBY,11-May-20,,,IEEE,IEEE Journals
Adaptive Local Ternary Pattern on Parameter Optimized-Faster Region Convolutional Neural Network for Pulmonary Emphysema Diagnosis,S. Mondal; A. K. Sadhu; P. K. Dutta,"School of Medical Science and Technology, Indian Institute of Technology Kharagpur, Kharagpur, India; EKO CT & MRI Scan Centre, Medical College and Hospital Campus, Kolkata, India; Department of Electrical Engineering, Indian Institute of Technology Kharagpur, Kharagpur, India",IEEE Access,20-Aug-21,2021,9,,114135,114152,"Emphysema is a lung disease that occurs due to abnormal alveoli expansion. This chronic disease causes difficulty in breathing which can lead to lung cancer. The progressive destruction of emphysema can be assessed by Computed Tomography (CT) scans and pulmonary function tests. The severity of the disease may extend to a stage where one can risk their life emphasizing the early detection of emphysema. Primary diagnosis can be done using spirometry and CT for early detection of the disease reducing the mortality rates. Difficulties associated with different diagnostic procedures and inter and intra-observer variations have made blooming researches on more computer-aided techniques. This paper intends to develop a computer-aided technique using the improved deep learning strategy. The initial process is image pre-processing, which is performed by histogram equalization and median filtering. Further, the Fuzzy C Means (FCM) clustering is used for segmentation. After segmentation, a new Adaptive Local Ternary Pattern (ALTP) is used for extracting the pattern descriptor, which is further utilized for classification. As a new contribution, the Parameter Optimized-Faster Region Convolutional Neural Network (PO-FRCNN) is developed for performing the diagnosis. The enhancement of pattern formation and deep classification is accomplished by the Improved Red Deer Algorithm (IRDA), which helps to tune the significant parameters that have a positive influence on the accurateness. The benchmark and real-time dataset are used for performing the experimentation. The results show that the proposed method yields the best result and can effectively diagnose emphysema when compared to state-of-the-art techniques.",2169-3536,,10.1109/ACCESS.2021.3105114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514591,Adaptive local ternary pattern;fuzzy C means clustering;modified deep learning;parameter optimized-faster region convolutional neural network;pulmonary emphysema,Lung;Computed tomography;Diseases;Feature extraction;Image segmentation;Lung cancer;Deep learning,cancer;computerised tomography;convolutional neural nets;deep learning (artificial intelligence);fuzzy set theory;image classification;image segmentation;lung;median filters;medical image processing;pattern clustering;pattern formation;pneumodynamics,pattern formation;pulmonary emphysema diagnosis;lung disease;abnormal alveoli expansion;chronic disease;lung cancer;computed tomography scans;pulmonary function tests;spirometry;intraobserver variations;computer-aided technique;deep learning strategy;adaptive local ternary pattern;parameter optimized-faster region convolutional neural network;interobserver variations;histogram equalization;median filtering;fuzzy C means clustering;image segmentation;deep classification;improved red deer algorithm,,3,,54,CCBYNCND,16-Aug-21,,,IEEE,IEEE Journals
Detection and Classification of Pulmonary Nodules Using Convolutional Neural Networks: A Survey,P. Monkam; S. Qi; H. Ma; W. Gao; Y. Yao; W. Qian,"Sino–Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Neusoft Research of Intelligent Healthcare Technology, Company, Ltd., Shenyang, China; Sino–Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Shenzhen Qianhai AnyCheck Information Technology Co., Ltd., Shenzhen, China; Deparment of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; College of Engineering, University of Texas at El Paso, El Paso, USA",IEEE Access,24-Jun-19,2019,7,,78075,78091,"CT screening has been proven to be effective for diagnosing lung cancer at its early manifestation in the form of pulmonary nodules, thus decreasing the mortality. However, the exponential increase of image data makes their accurate assessment a very challenging task given that the number of radiologists is limited and they have been overworked. Recently, numerous methods, especially ones based on deep learning with convolutional neural network (CNN), have been developed to automatically detect and classify pulmonary nodules in medical images. In this paper, we present a comprehensive analysis of these methods and their performances. First, we briefly introduce the fundamental knowledge of CNN as well as the reasons for their suitability to medical images analysis. Then, a brief description of various medical images datasets, as well as the environmental setup essential for facilitating lung nodule investigations with CNNs, is presented. Furthermore, comprehensive overviews of recent progress in pulmonary nodule analysis using CNNs are provided. Finally, existing challenges and promising directions for further improving the application of CNN to medical images analysis and pulmonary nodule assessment, in particular, are discussed. It is shown that CNNs have transformed greatly the early diagnosis and management of lung cancer. We believe that this review will provide all the medical research communities with the necessary knowledge to master the concept of CNN so as to utilize it for improving the overall human healthcare system.",2169-3536,,10.1109/ACCESS.2019.2920980,"National Natural Science Foundation of China(grant numbers:81671773,61672146); Fundamental Research Funds for the Central Universities(grant numbers:N172008008); Open Program of Neusoft Research of Intelligent Healthcare Technology, Company, Ltd.(grant numbers:NRIHTOP1803); Pearl River Talent Plan of Guangdong Province(grant numbers:2017ZT07X261); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736217,Lung cancer;deep learning;convolutional neural networks;computed tomography (CT) images;pulmonary nodules;image classification,Cancer;Lung;Computed tomography;Medical diagnostic imaging;Deep learning;Convolutional neural networks,cancer;computerised tomography;convolutional neural nets;image classification;learning (artificial intelligence);lung;medical image processing,human healthcare system;lung nodule;medical image datasets;medical image analysis;medical research communities;pulmonary nodule assessment;pulmonary nodule analysis;image data;lung cancer;convolutional neural network;pulmonary nodules,,48,,83,OAPA,13-Jun-19,,,IEEE,IEEE Journals
Lung Nodule Malignancy Prediction in Sequential CT Scans: Summary of ISBI 2018 Challenge,Y. Balagurunathan; A. Beers; M. Mcnitt-Gray; L. Hadjiiski; S. Napel; D. Goldgof; G. Perez; P. Arbelaez; A. Mehrtash; T. Kapur; E. Yang; J. W. Moon; G. B. Perez; R. Delgado-Gonzalo; M. M. Farhangi; A. A. Amini; R. Ni; X. Feng; A. Bagari; K. Vaidhya; B. Veasey; W. Safta; H. Frigui; J. Enguehard; A. Gholipour; L. S. Castillo; L. A. Daza; P. Pinsky; J. Kalpathy-Cramer; K. Farahani,"Department of Machine Learning, H Lee Moffitt Cancer Center (MCC) and Research Institute, Tampa, FL, USA; Massachusetts General Hospital (MGH), Boston, MA, USA; Thoracic Imaging Section, David Geffen School of Medicine, University of California at Los Angeles (UCLA), Los Angeles, CA, USA; Department of Radiology, University of Michigan (UMICH), Ann Arbor, MI, USA; Department of Radiology, School of Medicine, Stanford University (SU), Stanford, CA, USA; Department of Computer Science, University of South Florida (USF), Tampa, FL, USA; Biomedical Computer Vision Laboratory (BCV), Universidad de Los Andes, Bogota, Colombia; Biomedical Computer Vision Laboratory (BCV), Universidad de Los Andes, Bogota, Colombia; Department of Radiology, Surgical Planning Laboratory (SPL), Brigham and Women’s Faulkner Hospital, Boston, MA, USA; Department of Radiology, Surgical Planning Laboratory (SPL), Brigham and Women’s Faulkner Hospital, Boston, MA, USA; School of Medicine, Sungkyunkwan University, Seoul, South Korea; Human Medical Imaging and Intervention Center, Seoul, South Korea; Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Centre Suisse d’Électronique et de Microtechnique, Neuchâtel, Switzerland; Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA; Springbok Inc., Charlottesville, VA, USA; Department of Biomedical Engineering, University of Virginia, Charlottesville, VA, USA; Predible Health Inc., Bengaluru, India; Predible Health Inc., Bengaluru, India; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA; Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, USA; Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, USA; Harvard Medical School, Boston, MA, USA; Harvard Medical School, Boston, MA, USA; Department of Biomedical Engineering, Universidad de los Andes, Bogota, Colombia; Department of Biomedical Engineering, Universidad de los Andes, Bogota, Colombia; Division of Cancer Prevention, Bethesda, MD, USA; Massachusetts General Hospital (MGH), Boston, MA, USA; Center for Biomedical Informatics and Information Technology, National Cancer Institute (NCI), Bethesda, MD, USA",IEEE Transactions on Medical Imaging,30-Nov-21,2021,40,12,3748,3761,"Lung cancer is by far the leading cause of cancer death in the US. Recent studies have demonstrated the effectiveness of screening using low dose CT (LDCT) in reducing lung cancer related mortality. While lung nodules are detected with a high rate of sensitivity, this exam has a low specificity rate and it is still difficult to separate benign and malignant lesions. The ISBI 2018 Lung Nodule Malignancy Prediction Challenge, developed by a team from the Quantitative Imaging Network of the National Cancer Institute, was focused on the prediction of lung nodule malignancy from two sequential LDCT screening exams using automated (non-manual) algorithms. We curated a cohort of 100 subjects who participated in the National Lung Screening Trial and had established pathological diagnoses. Data from 30 subjects were randomly selected for training and the remaining was used for testing. Participants were evaluated based on the area under the receiver operating characteristic curve (AUC) of nodule-wise malignancy scores generated by their algorithms on the test set. The challenge had 17 participants, with 11 teams submitting reports with method description, mandated by the challenge rules. Participants used quantitative methods, resulting in a reporting test AUC ranging from 0.698 to 0.913. The top five contestants used deep learning approaches, reporting an AUC between 0.87 – 0.91. The team’s predictor did not achieve significant differences from each other nor from a volume change estimate (p =.05 with Bonferroni-Holm’s correction).",1558-254X,,10.1109/TMI.2021.3097665,"National Cancer Institute(grant numbers:U01-CA200464,U01CA143062); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9486926,Lung cancer;nodules challenge;ISBI 2018;indeterminate pulmonary nodules;cancer detection in longitudinal CT;NLST;computed comography;deep learning methods in lung CT,Training;Lung;Deep learning;Lung cancer;Computed tomography;Biomedical imaging;Pathology,cancer;computerised tomography;image classification;image segmentation;lung;medical image processing,sequential CT scans;ISBI 2018 Challenge;cancer death;low dose CT;lung cancer related mortality;lung nodules;low specificity rate;benign lesions;malignant lesions;ISBI 2018 Lung Nodule Malignancy Prediction Challenge;Quantitative Imaging Network;National Cancer Institute;sequential LDCT screening exams;National Lung Screening Trial;nodule-wise malignancy scores;challenge rules;reporting test AUC,"Algorithms;Humans;Lung;Lung Neoplasms;ROC Curve;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",4,,87,IEEE,15-Jul-21,,,IEEE,IEEE Journals
Nodule-Plus R-CNN and Deep Self-Paced Active Learning for 3D Instance Segmentation of Pulmonary Nodules,W. Wang; R. Feng; J. Chen; Y. Lu; T. Chen; H. Yu; D. Z. Chen; J. Wu,"Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China",IEEE Access,18-Sep-19,2019,7,,128796,128805,"Accurate and automatic segmentation of pulmonary nodules in 3D thoracic Computed Tomography (CT) images is of great significance for Computer-Aided medical Diagnosis (CAD) of lung cancer. Currently, this important task remains challenging for lack of the voxel-level annotation and training strategies that balance target/background voxels in thoracic CT images. In this paper, a new region-based network, called Nodule-plus Region-based CNN, is proposed to detect pulmonary nodules in 3D thoracic CT images effectively while synchronously generating an instance segmentation mask for every detected instance. Our new network is constructed with a stack of convolutional blocks in which lateral connections are used to alleviate the difficulty of vanishing gradients. In addition, in order to reduce annotation workload and make best use of unannotated samples, we proposed a new Deep Self-paced Active Learning (DSAL) strategy by combining Active Learning (AL) and Self-Paced Learning (SPL) strategies. For the purpose of evaluating the performance of our proposed Nodule-plus R-CNN, we conduct a series of experiments on the public LIDC-IDRI dataset, and our model achieves 0.66 Dice and 0.96 TP Dice, which are state-of-the-art best results of pulmonary nodule segmentation. When the amount of available annotated samples is limited, our model trained with the DSAL strategy performs much better than that trained with the standard strategy.",2169-3536,,10.1109/ACCESS.2019.2939850,"National Natural Science Foundation of China(grant numbers:81700882,71804161); National Science Foundation(grant numbers:CCF-1617735); Zhejiang University(grant numbers:K18-511120-004,K17-518051-021); National Natural Science Foundation of China(grant numbers:61672453); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826589,Pulmonary nodule segmentation;3D CT images;R-CNN;active learning;self-paced learning,Three-dimensional displays;Computed tomography;Image segmentation;Feature extraction;Training;Cancer;Lung,cancer;computerised tomography;convolutional neural nets;feature extraction;image classification;image segmentation;learning (artificial intelligence);lung;medical image processing,pulmonary nodules;thoracic CT images;instance segmentation mask;pulmonary nodule segmentation;3D instance segmentation;automatic segmentation;voxel-level annotation;region-based network;computed tomography images;computer-aided medical diagnosis;nodule-plus region-based CNN;nodule-plus R-CNN;deep self-paced active learning strategy;3D thoracic computed tomography images;lung cancer;LIDC-IDRI dataset,,11,,29,CCBY,6-Sep-19,,,IEEE,IEEE Journals
Multiple Resolution Residually Connected Feature Streams for Automatic Lung Tumor Segmentation From CT Images,J. Jiang; Y. -C. Hu; C. -J. Liu; D. Halpenny; M. D. Hellmann; J. O. Deasy; G. Mageras; H. Veeraraghavan,"Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Nuclear Medicine, National Taiwan University Hospital Yunlin Branch, Douliou, Taiwan; Department of Radiology, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Medical Oncology, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA",IEEE Transactions on Medical Imaging,28-Dec-18,2019,38,1,134,144,"Volumetric lung tumor segmentation and accurate longitudinal tracking of tumor volume changes from computed tomography images are essential for monitoring tumor response to therapy. Hence, we developed two multiple resolution residually connected network (MRRN) formulations called incremental-MRRN and dense-MRRN. Our networks simultaneously combine features across multiple image resolution and feature levels through residual connections to detect and segment the lung tumors. We evaluated our method on a total of 1210 non-small cell (NSCLC) lung tumors and nodules from three data sets consisting of 377 tumors from the open-source Cancer Imaging Archive (TCIA), 304 advanced stage NSCLC treated with anti- PD-1 checkpoint immunotherapy from internal institution MSKCC data set, and 529 lung nodules from the Lung Image Database Consortium (LIDC). The algorithm was trained using 377 tumors from the TCIA data set and validated on the MSKCC and tested on LIDC data sets. The segmentation accuracy compared to expert delineations was evaluated by computing the dice similarity coefficient, Hausdorff distances, sensitivity, and precision metrics. Our best performing incremental-MRRN method produced the highest DSC of 0.74 ± 0.13 for TCIA, 0.75±0.12 for MSKCC, and 0.68±0.23 for the LIDC data sets. There was no significant difference in the estimations of volumetric tumor changes computed using the incremental-MRRN method compared with the expert segmentation. In summary, we have developed a multi-scale CNN approach for volumetrically segmenting lung tumors which enables accurate, automated identification of and serial measurement of tumor volumes in the lung.",1558-254X,,10.1109/TMI.2018.2857800,Breast Cancer Research Foundation; MSK Cancer Center Support(grant numbers:P30 CA008748); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417454,Deep learning;segmentation;longitudinal;lung cancer;detection,Image resolution;Tumors;Streaming media;Lung;Cancer;Feature extraction;Image segmentation,cancer;cellular biophysics;computerised tomography;feature extraction;image resolution;image segmentation;lung;medical image processing;radiation therapy;tumours,accurate longitudinal tracking;tumor volume changes;computed tomography images;multiple resolution residually connected network formulations;dense-MRRN;multiple image resolution;feature levels;nonsmall cell lung tumors;open-source Cancer Imaging Archive;internal institution MSKCC data;Lung Image Database Consortium;TCIA data;LIDC data sets;segmentation accuracy;volumetric tumor changes;expert segmentation;tumor volumes;tumor response;lung nodules;multiple resolution residually connected feature streams;antiPD-1 checkpoint immunotherapy;incremental-MRRN method;dice similarity coefficient;Hausdorff distances;precision metrics;volumetric lung tumor segmentation;CT images;automatic lung tumor segmentation,"Algorithms;Databases, Factual;Deep Learning;Humans;Image Interpretation, Computer-Assisted;Lung;Lung Neoplasms;Tomography, X-Ray Computed",123,,39,IEEE,23-Jul-18,,,IEEE,IEEE Journals
Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
Evaluate the Malignancy of Pulmonary Nodules Using the 3-D Deep Leaky Noisy-OR Network,F. Liao; M. Liang; Z. Li; X. Hu; S. Song,"School of Medicine, Tsinghua University, Beijing, China; Institute for Artificial Intelligence, Tsinghua University, Beijing, China; School of Medicine, Tsinghua University, Beijing, China; Institute for Artificial Intelligence, Tsinghua University, Beijing, China; School of Medicine, Tsinghua University, Beijing, China",IEEE Transactions on Neural Networks and Learning Systems,30-Oct-19,2019,30,11,3484,3495,"Automatic diagnosing lung cancer from computed tomography scans involves two steps: detect all suspicious lesions (pulmonary nodules) and evaluate the whole-lung/pulmonary malignancy. Currently, there are many studies about the first step, but few about the second step. Since the existence of nodule does not definitely indicate cancer, and the morphology of nodule has a complicated relationship with cancer, the diagnosis of lung cancer demands careful investigations on every suspicious nodule and integration of information of all nodules. We propose a 3-D deep neural network to solve this problem. The model consists of two modules. The first one is a 3-D region proposal network for nodule detection, which outputs all suspicious nodules for a subject. The second one selects the top five nodules based on the detection confidence, evaluates their cancer probabilities, and combines them with a leaky noisy-OR gate to obtain the probability of lung cancer for the subject. The two modules share the same backbone network, a modified U-net. The overfitting caused by the shortage of the training data is alleviated by training the two modules alternately. The proposed model won the first place in the Data Science Bowl 2017 competition.",2162-2388,,10.1109/TNNLS.2019.2892409,"National Natural Science Foundation of China(grant numbers:61836014,91420201,61621136008,61620106010); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642524,3-D convolutional neural network (CNN);deep learning;nodule malignancy evaluation;noisy-OR model;pulmonary nodule detection,Cancer;Solid modeling;Noise measurement;Lung;Proposals;Task analysis;Object detection,cancer;computerised tomography;lung;medical image processing;neural nets;patient diagnosis;probability,pulmonary nodules;3-D deep leaky noisy;automatic diagnosing lung cancer;computed tomography scans;suspicious lesions;suspicious nodule;3-D deep neural network;3-D region proposal network;nodule detection;suspicious nodules;detection confidence;cancer probabilities;backbone network,"Diagnosis, Computer-Assisted;Humans;Imaging, Three-Dimensional;Lung Neoplasms;Neural Networks, Computer;Tomography, X-Ray Computed",198,,42,IEEE,14-Feb-19,,,IEEE,IEEE Journals
Pulmonary Nodule Detection Based on Faster R-CNN With Adaptive Anchor Box,C. C. Nguyen; G. S. Tran; V. T. Nguyen; J. -C. Burie; T. P. Nghiem,"ICTLab, University of Science and Technology of Hanoi, Vietnam Academy of Science and Technology, Cau Giay, Vietnam; ICTLab, University of Science and Technology of Hanoi, Vietnam Academy of Science and Technology, Cau Giay, Vietnam; Department of Radiology, Vietnam National Cancer Hospital, Hanoi, Vietnam; L3i Laboratory, La Rochelle University, La Rochelle, France; ICTLab, University of Science and Technology of Hanoi, Vietnam Academy of Science and Technology, Cau Giay, Vietnam",IEEE Access,24-Nov-21,2021,9,,154740,154751,"Early pulmonary nodule detection is very important in lung cancer diagnosis and screening. Most state-of-the-art lung nodule detection models are based on Faster Region-based Convolutional Neural Network (Faster R-CNN) due to its superior performance. However, this object detection approach faces difficulties with the variety of nodule sizes in training datasets. In this paper, we propose a novel Computer-Aided Detection (CAD) system based on Faster R-CNN model with adaptive anchor box for lung nodule detection. Our method employs ground-truth nodule sizes in the training dataset to generate adaptive anchor box sizes of Faster R-CNN. Learned anchors are used as hyper-parameter to boost Faster R-CNN’s detection performance. A residual convolutional neural network is proposed to reduce false positives from Faster R-CNN’s output. Our method is trained and tested on the largest publicly available LUNA16 dataset. Experiments show that our proposed system achieves a high sensitivity of 95.64% at 1.72 false positives per scan, and a Competition Performance Metric (CPM) score of 88.2%, which outperforms other recent state-of-the-art detection methods. The false positive reduction network achieves a sensitivity of 93.8%, specificity of 97.6% and accuracy of 95.7%. An additional evaluation on a completely independent SPIE-AAPM dataset demonstrates the generalization of our proposed model with 89.3% sensitivity.",2169-3536,,10.1109/ACCESS.2021.3128942,University of Science and Technology of Hanoi(grant numbers:USTH.ICT.01/20-22); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619980,Pulmonary nodules;CT~images;deep learning;faster R-CNN;anchor box,Lung;Sensitivity;Computed tomography;Three-dimensional displays;Feature extraction;Lung cancer;Proposals,CAD;cancer;computerised tomography;diagnostic radiography;learning (artificial intelligence);lung;medical image processing;neural nets;object detection,screening;state-of-the-art lung nodule detection models;Faster Region-based Convolutional Neural Network;object detection approach;nodule sizes;training dataset;novel Computer-Aided Detection system;Faster R-CNN model;ground-truth nodule;adaptive anchor box sizes;learned anchors;Faster R-CNN's detection performance;residual convolutional neural network;false positives;Faster R-CNN's output;largest publicly available LUNA16 dataset;recent state-of-the-art detection methods;false positive reduction network;pulmonary nodule detection;lung cancer diagnosis,,7,,50,CCBY,18-Nov-21,,,IEEE,IEEE Journals
Multilevel Contextual 3-D CNNs for False Positive Reduction in Pulmonary Nodule Detection,Q. Dou; H. Chen; L. Yu; J. Qin; P. -A. Heng,"Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong",IEEE Transactions on Biomedical Engineering,15-Jun-17,2017,64,7,1558,1567,"Objective: False positive reduction is one of the most crucial components in an automated pulmonary nodule detection system, which plays an important role in lung cancer diagnosis and early treatment. The objective of this paper is to effectively address the challenges in this task and therefore to accurately discriminate the true nodules from a large number of candidates. Methods: We propose a novel method employing three-dimensional (3-D) convolutional neural networks (CNNs) for false positive reduction in automated pulmonary nodule detection from volumetric computed tomography (CT) scans. Compared with its 2-D counterparts, the 3-D CNNs can encode richer spatial information and extract more representative features via their hierarchical architecture trained with 3-D samples. More importantly, we further propose a simple yet effective strategy to encode multilevel contextual information to meet the challenges coming with the large variations and hard mimics of pulmonary nodules. Results: The proposed framework has been extensively validated in the LUNA16 challenge held in conjunction with ISBI 2016, where we achieved the highest competition performance metric (CPM) score in the false positive reduction track. Conclusion: Experimental results demonstrated the importance and effectiveness of integrating multilevel contextual information into 3-D CNN framework for automated pulmonary nodule detection in volumetric CT data. Significance: While our method is tailored for pulmonary nodule detection, the proposed framework is general and can be easily extended to many other 3-D object detection tasks from volumetric medical images, where the targeting objects have large variations and are accompanied by a number of hard mimics.",1558-2531,,10.1109/TBME.2016.2613502,"The Hong Kong Special Administrative Region(grant numbers:CUHK 412513); National Natural Science Foundation of China(grant numbers:61233012); Shenzhen-Hong Kong Innovation Circle(grant numbers:SGLH20131010151755080,GHP/002/13SZ); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576695,Computer-aided diagnosis;deep learning;false positive reduction;pulmonary nodule detection;3-D convolutional neural networks,Three-dimensional displays;Feature extraction;Two dimensional displays;Computed tomography;Kernel;Cancer;Lungs,cancer;computerised tomography;feature extraction;lung;medical image processing;neural nets,automated pulmonary nodule detection system;lung cancer diagnosis;3D convolutional neural network;contextual 3D CNN;volumetric computed tomography;volumetric CT scans;feature extraction;LUNA16 challenge;ISBI 2016;competition performance metric score;CPM score;false positive reduction track;multilevel contextual information;3D object detection tasks;volumetric medical images,"Algorithms;Diagnostic Errors;False Positive Reactions;Humans;Imaging, Three-Dimensional;Machine Learning;Neural Networks (Computer);Pattern Recognition, Automated;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",354,,37,IEEE,26-Sep-16,,,IEEE,IEEE Journals
Pulmonary Nodule Classification Using Feature and Ensemble Learning-Based Fusion Techniques,M. Muzammil; I. Ali; I. U. Haq; A. A. Khaliq; S. Abdullah,"Faculty of Engineering and Technology, International Islamic University, Islamabad, Pakistan; National Center for Physics, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Pakistan; Faculty of Engineering and Technology, International Islamic University, Islamabad, Pakistan",IEEE Access,18-Aug-21,2021,9,,113415,113427,"The Pulmonary nodule indicates the presence of lung cancer. The deep convolutional neural networks (DCNNs) have been widely used to classify the pulmonary nodule as benign or malignant. However, an individual learner usually performs unsatisfactorily due to limited response space, incorrect selection of hypothesis space, or falling into local minimums. To investigate these issues, we propose ensemble learners fusion techniques based on averaging of prediction score and maximum vote score (MAX-VOTE). First, the support vector machine (SVM) and AdaBoostM2 machine learning algorithms are trained on the deep features from DCNNs. The results of both classifiers are fused separately based on averaging of the prediction score. Secondly, the feature fusion technique is developed by fusing the feature of three DCNNs (AlexNet, VGG-16 and VGG-19) through predefined rules. After that, the SVM and AdaBoostM2 are trained on fused features independently to build ensemble learners by fusing the multiple DCNN learners. The predictions of all DCNN learners are fused based on the MAX-VOTE. The results show that the ensemble learners based MAX-VOTE technique yields better performance out of twelve single learners for binary class classification of pulmonary nodules. The proposed fusion techniques are also tested for multi-class classification problem. The SVM based feature fusion technique performs better as compared to all the implemented and the state-of-the-art techniques. The achieved maximum accuracy, AUC and specificity scores are 96.89%±0.25, 99.21%±0.10 and 97.70%±0.21, respectively.",2169-3536,,10.1109/ACCESS.2021.3102707,Higher Education Commission(grant numbers:20-4849/NRPU/R&D/HEC/14/1215); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507437,Deep convolutional neural network;computer aided diagnosis;computed tomography;pulmonary nodule;deep features;deep feature fusion;ensemble learner;support vector machine;nodule classification;LUNA16 challenge,Lung;Feature extraction;Lung cancer;Tumors;Support vector machines;Computed tomography;Cancer,cancer;feature extraction;image classification;image fusion;learning (artificial intelligence);lung;medical image processing;neural nets;pattern classification;support vector machines,Pulmonary nodule classification;ensemble learning-based fusion techniques;lung cancer;deep convolutional neural networks;DCNNs;individual learner;response space;hypothesis space;ensemble learners fusion techniques;prediction score;maximum vote score;SVM;deep features;feature fusion technique;VGG-16;VGG-19;AdaBoostM2;fused features;multiple DCNN learners;MAX-VOTE technique;single learners;binary class classification;multiclass classification problem;specificity scores,,3,,72,CCBY,5-Aug-21,,,IEEE,IEEE Journals
No Surprises: Training Robust Lung Nodule Detection for Low-Dose CT Scans by Augmenting With Adversarial Attacks,S. Liu; A. A. A. Setio; F. C. Ghesu; E. Gibson; S. Grbic; B. Georgescu; D. Comaniciu,"Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA; Digital Technology and Innovation, Siemens Healthineers, Erlangen, Germany; Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA; Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA; Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA; Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA; Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA",IEEE Transactions on Medical Imaging,29-Dec-20,2021,40,1,335,345,"Detecting malignant pulmonary nodules at an early stage can allow medical interventions which may increase the survival rate of lung cancer patients. Using computer vision techniques to detect nodules can improve the sensitivity and the speed of interpreting chest CT for lung cancer screening. Many studies have used CNNs to detect nodule candidates. Though such approaches have been shown to outperform the conventional image processing based methods regarding the detection accuracy, CNNs are also known to be limited to generalize on under-represented samples in the training set and prone to imperceptible noise perturbations. Such limitations can not be easily addressed by scaling up the dataset or the models. In this work, we propose to add adversarial synthetic nodules and adversarial attack samples to the training data to improve the generalization and the robustness of the lung nodule detection systems. To generate hard examples of nodules from a differentiable nodule synthesizer, we use projected gradient descent (PGD) to search the latent code within a bounded neighbourhood that would generate nodules to decrease the detector response. To make the network more robust to unanticipated noise perturbations, we use PGD to search for noise patterns that can trigger the network to give over-confident mistakes. By evaluating on two different benchmark datasets containing consensus annotations from three radiologists, we show that the proposed techniques can improve the detection performance on real CT data. To understand the limitations of both the conventional networks and the proposed augmented networks, we also perform stress-tests on the false positive reduction networks by feeding different types of artificially produced patches. We show that the augmented networks are more robust to both under-represented nodules as well as resistant to noise perturbations.",1558-254X,,10.1109/TMI.2020.3026261,National Cancer Institute for Access to NCI’s Data Collected; National Lung Screening Trial (NLST); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204673,Lung nodule detection;adversarial attack;medical image synthesis;deep learning,Training;Robustness;Lung;Cancer;Computed tomography;Biomedical imaging;Benchmark testing,cancer;computer vision;computerised tomography;diagnostic radiography;gradient methods;lung;medical image processing,unanticipated noise perturbations;CT data;augmented networks;training robust lung nodule detection;low-dose CT scans;adversarial attacks;malignant pulmonary nodules;lung cancer patients;computer vision techniques;chest CT;lung cancer screening;CNN;conventional image processing based methods;adversarial synthetic nodules;training data;lung nodule detection systems;imperceptible noise perturbations;projected gradient descent,"Early Detection of Cancer;Humans;Image Processing, Computer-Assisted;Lung;Lung Neoplasms;Radiographic Image Interpretation, Computer-Assisted;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",12,,49,IEEE,23-Sep-20,,,IEEE,IEEE Journals
Comprehensive and Comparative Global and Local Feature Extraction Framework for Lung Cancer Detection Using CT Scan Images,M. A. Alzubaidi; M. Otoom; H. Jaradat,"Department of Computer Engineering, Yarmouk University, Irbid, Jordan; Department of Computer Engineering, Yarmouk University, Irbid, Jordan; Department of Computer Engineering, Yarmouk University, Irbid, Jordan",IEEE Access,6-Dec-21,2021,9,,158140,158154,"Lung cancer is reported to be the second most common cancer disease. This paper proposes a comprehensive and comparative global and local feature extraction framework for lung cancer detection using CT scan images. This framework consists of three main phases: data collection, global training and testing, and local training and testing. A set of 1000 CT scan images is used in this study. During the global training and testing phase, the collected images are preprocessed through image warping and cropping. Global features are then extracted from images to represent each image with feature vectors, using ten different image feature types. The feature vectors are then used to build detection models with six different machine learning algorithms. In the local training and testing phase, each image is divided into a set of local blocks. Those feature types that performed well in the global phase are then extracted from each of these blocks, to represent each block with feature vectors. These feature vectors are then used to build detection models for all of the image blocks, using the learning algorithms that performed well in the global phase. The results show that the Gabor Filter, the Histogram of Oriented Gradients (HOG), and the Haar Wavelet feature types outperformed the other seven feature types. The results also show that Support Vector Machine (SVM) outperforms the other five learning algorithms. Of most importance, the proposed local feature extraction approach outperforms the traditional global one. In the local phase, using SVM with Haar Wavelet features achieved 90% accuracy, 88% sensitivity, and 91% specificity. Using SVM with HOG features achieved 88% accuracy, 85% sensitivity, and 89% specificity. Finally, using SVM with Gabor Filter features achieved the best accuracy, sensitivity, and specificity rates of 97%, 96%, and 97%, respectively.",2169-3536,,10.1109/ACCESS.2021.3129597,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622257,CT scan;lung cancer;global feature extraction;local feature extraction;SVM;Gabor filter,Lung cancer;Feature extraction;Computed tomography;Lung;Cancer;Support vector machines;Tumors,cancer;computerised tomography;diseases;feature extraction;Gabor filters;image classification;learning (artificial intelligence);lung;medical image processing;support vector machines;wavelet transforms,local phase;Haar Wavelet features;HOG features;Gabor Filter features;comparative global feature extraction framework;local feature extraction framework;lung cancer detection;common cancer disease;comprehensive feature extraction framework;global training;local training;1000 CT scan images;testing phase;image warping;cropping;global features;feature vectors;different image feature types;detection models;local blocks;global phase;image blocks;Haar Wavelet feature types;seven feature types;local feature extraction approach,,4,,61,CCBY,19-Nov-21,,,IEEE,IEEE Journals
Automatic Pulmonary Nodule Detection in CT Scans Using Convolutional Neural Networks Based on Maximum Intensity Projection,S. Zheng; J. Guo; X. Cui; R. N. J. Veldhuis; M. Oudkerk; P. M. A. van Ooijen,"Department of Radiation Oncology, University Medical Center Groningen, Groningen, The Netherlands; Department of Radiotherapy, University Medical Center Groningen, Groningen, The Netherlands; Department of Radiology, National Clinical Research Centre of Cancer, Tianjin Medical University Cancer Institute and Hospital, Tianjin, China; Faculty of Electrical Engineering, University of Twente, Enschede, The Netherlands; Faculty of Medical Sciences, University of Groningen, Groningen, The Netherlands; Department of Radiation Oncology, University Medical Center Groningen, Groningen, The Netherlands",IEEE Transactions on Medical Imaging,3-Mar-20,2020,39,3,797,805,"Accurate pulmonary nodule detection is a crucial step in lung cancer screening. Computer-aided detection (CAD) systems are not routinely used by radiologists for pulmonary nodule detection in clinical practice despite their potential benefits. Maximum intensity projection (MIP) images improve the detection of pulmonary nodules in radiological evaluation with computed tomography (CT) scans. Inspired by the clinical methodology of radiologists, we aim to explore the feasibility of applying MIP images to improve the effectiveness of automatic lung nodule detection using convolutional neural networks (CNNs). We propose a CNN-based approach that takes MIP images of different slab thicknesses (5 mm, 10 mm, 15 mm) and 1 mm axial section slices as input. Such an approach augments the two-dimensional (2-D) CT slice images with more representative spatial information that helps discriminate nodules from vessels through their morphologies. Our proposed method achieves sensitivity of 92.7% with 1 false positive per scan and sensitivity of 94.2% with 2 false positives per scan for lung nodule detection on 888 scans in the LIDC-IDRI dataset. The use of thick MIP images helps the detection of small pulmonary nodules (3 mm-10 mm) and results in fewer false positives. Experimental results show that utilizing MIP images can increase the sensitivity and lower the number of false positives, which demonstrates the effectiveness and significance of the proposed MIP-based CNNs framework for automatic pulmonary nodule detection in CT scans. The proposed method also shows the potential that CNNs could gain benefits for nodule detection by combining the clinical procedure.",1558-254X,,10.1109/TMI.2019.2935553,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801875,Maximum intensity projection (MIP);convolutional neural network (CNN);computer-aided detection (CAD);pulmonary nodule detection;computed tomography scan,Lung;Computed tomography;Convolutional neural networks;Image segmentation;Medical diagnostic imaging;Lung cancer,cancer;computerised tomography;convolutional neural nets;lung;medical image processing;object detection,automatic pulmonary nodule detection;CT scans;convolutional neural networks;maximum intensity projection images;lung cancer screening;computer-aided detection systems;computed tomography scans;MIP images;automatic lung nodule detection;CNN-based approach;MIP-based CNN framework;axial section slices;two-dimensional CT slice images;LIDC-IDRI dataset;size 10.0 mm;size 15.0 mm;size 3.0 mm to 10.0 mm;size 1.0 mm;size 5.0 mm,"Databases, Factual;Early Detection of Cancer;Humans;Imaging, Three-Dimensional;Lung Neoplasms;Neural Networks, Computer;Radiographic Image Interpretation, Computer-Assisted;Sensitivity and Specificity;Solitary Pulmonary Nodule;Tomography, X-Ray Computed",65,,44,IEEE,15-Aug-19,,,IEEE,IEEE Journals
An Automatic Detection System of Lung Nodule Based on Multigroup Patch-Based Deep Learning Network,H. Jiang; H. Ma; W. Qian; M. Gao; Y. Li,"Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Sino-Dutch Biomedical and Information Engineering School and the Key Laboratory of Medical Image Computing, Ministry of Education, Northeastern University, Shenyang, China; College of Engineering, University of Texas at El Paso, El Paso, TX, USA; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; College of Engineering, University of Texas at El Paso, El Paso, TX, USA",IEEE Journal of Biomedical and Health Informatics,2-Jul-18,2018,22,4,1227,1237,"High-efficiency lung nodule detection dramatically contributes to the risk assessment of lung cancer. It is a significant and challenging task to quickly locate the exact positions of lung nodules. Extensive work has been done by researchers around this domain for approximately two decades. However, previous computer-aided detection (CADe) schemes are mostly intricate and time-consuming since they may require more image processing modules, such as the computed tomography image transformation, the lung nodule segmentation, and the feature extraction, to construct a whole CADe system. It is difficult for these schemes to process and analyze enormous data when the medical images continue to increase. Besides, some state of the art deep learning schemes may be strict in the standard of database. This study proposes an effective lung nodule detection scheme based on multigroup patches cut out from the lung images, which are enhanced by the Frangi filter. Through combining two groups of images, a four-channel convolution neural networks model is designed to learn the knowledge of radiologists for detecting nodules of four levels. This CADe scheme can acquire the sensitivity of 80.06% with 4.7 false positives per scan and the sensitivity of 94% with 15.1 false positives per scan. The results demonstrate that the multigroup patch-based learning system is efficient to improve the performance of lung nodule detection and greatly reduce the false positives under a huge amount of image data.",2168-2208,,10.1109/JBHI.2017.2725903,Recruitment Program of Global Experts(grant numbers:01270021814101/022); Fundamental Research Funds for the Central Universities(grant numbers:N151903002/N150408001); Bureau of Science and Technology of Liaoning Province(grant numbers:201501146); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981333,Computer aided detection (CADe);computed tomography (CT) images;deep learning network;Frangi filter;lung nodule detection,Lungs;Computed tomography;Feature extraction;Cancer;Image segmentation;Databases;Biomedical imaging,cancer;computerised tomography;feature extraction;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets,high-efficiency lung nodule detection;lung cancer;image processing modules;computed tomography image transformation;lung nodule segmentation;CADe system;medical images;lung images;four-channel convolution neural networks model;CADe scheme;deep learning network;feature extraction;computer-aided detection;multigroup patch-based deep learning network;deep learning schemes,"Algorithms;Deep Learning;Humans;Lung;Lung Neoplasms;Radiographic Image Interpretation, Computer-Assisted;Tomography, X-Ray Computed",127,,44,IEEE,14-Jul-17,,,IEEE,IEEE Journals
Semi-Supervised Segmentation of Radiation-Induced Pulmonary Fibrosis From Lung CT Scans With Multi-Scale Guided Dense Attention,G. Wang; S. Zhai; G. Lasio; B. Zhang; B. Yi; S. Chen; T. J. Macvittie; D. Metaxas; J. Zhou; S. Zhang,"School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Radiation Oncology, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Radiation Oncology, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Radiation Oncology, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Radiation Oncology, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Radiation Oncology, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Computer Science, Rutgers, The State University of New Jersey, Piscataway, NJ, USA; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China",IEEE Transactions on Medical Imaging,2-Mar-22,2022,41,3,531,542,"Computed Tomography (CT) plays an important role in monitoring radiation-induced Pulmonary Fibrosis (PF), where accurate segmentation of the PF lesions is highly desired for diagnosis and treatment follow-up. However, the task is challenged by ambiguous boundary, irregular shape, various position and size of the lesions, as well as the difficulty in acquiring a large set of annotated volumetric images for training. To overcome these problems, we propose a novel convolutional neural network called PF-Net and incorporate it into a semi-supervised learning framework based on Iterative Confidence-based Refinement And Weighting of pseudo Labels (I-CRAWL). Our PF-Net combines 2D and 3D convolutions to deal with CT volumes with large inter-slice spacing, and uses multi-scale guided dense attention to segment complex PF lesions. For semi-supervised learning, our I-CRAWL employs pixel-level uncertainty-based confidence-aware refinement to improve the accuracy of pseudo labels of unannotated images, and uses image-level uncertainty for confidence-based image weighting to suppress low-quality pseudo labels in an iterative training process. Extensive experiments with CT scans of Rhesus Macaques with radiation-induced PF showed that: 1) PF-Net achieved higher segmentation accuracy than existing 2D, 3D and 2.5D neural networks, and 2) I-CRAWL outperformed state-of-the-art semi-supervised learning methods for the PF lesion segmentation task. Our method has a potential to improve the diagnosis of PF and clinical assessment of side effects of radiotherapy for lung cancers.",1558-254X,,10.1109/TMI.2021.3117564,"National Natural Science Foundation of China(grant numbers:81771921,61901084); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9558828,Semi-supervised learning;convolutional neural networks;pulmonary fibrosis;lung CT,Image segmentation;Lesions;Lung;Three-dimensional displays;Computed tomography;Task analysis;Lung cancer,cancer;computerised tomography;image classification;image segmentation;lung;medical image processing;neural nets;radiation therapy;semi-supervised learning (artificial intelligence),image-level uncertainty;confidence-based image;low-quality pseudolabels;iterative training process;radiation-induced PF;2.5D neural networks;I-CRAWL outperformed state-of-the-art semisupervised learning;PF lesion segmentation task;semisupervised segmentation;lung CT scans;multiscale guided dense attention;Computed Tomography;monitoring radiation-induced Pulmonary Fibrosis;ambiguous boundary;annotated volumetric images;semisupervised learning framework;PF-Net combines 2D;CT volumes;inter-slice spacing;segment complex PF lesions;pixel-level uncertainty-based confidence-aware refinement;unannotated images,"Animals;Image Processing, Computer-Assisted;Lung;Macaca mulatta;Pulmonary Fibrosis;Tomography, X-Ray Computed",14,,48,IEEE,4-Oct-21,,,IEEE,IEEE Journals
