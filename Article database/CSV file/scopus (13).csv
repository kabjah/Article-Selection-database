Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
"Liu J., Wang Z., Zhang Y., Traverso A., Dekker A., Zhang Z., Chen Q.",57933845400;57208488517;57814816300;56769295400;57225379184;57443658100;56479518400;,CycleGAN Clinical Image Augmentation Based on Mask Self-Attention Mechanism,2022,IEEE Access,10,,,105942,105953,,,10.1109/ACCESS.2022.3211670,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140198208&doi=10.1109%2fACCESS.2022.3211670&partnerID=40&md5=aed8b02f8066993ffa7e8c2278fee921,"Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Key Laboratory of Cancer Prevention and Therapy, National Clinical Research Center for Cancer, Tianjin's Clinical Research Center for Cancer, Department of Radiation Oncology, Tianjin Medical University, Cancer Institute and Hospital, Tianjin, 300070, China","Liu, J., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Wang, Z., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Zhang, Y., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Traverso, A., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Dekker, A., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Zhang, Z., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands, Key Laboratory of Cancer Prevention and Therapy, National Clinical Research Center for Cancer, Tianjin's Clinical Research Center for Cancer, Department of Radiation Oncology, Tianjin Medical University, Cancer Institute and Hospital, Tianjin, 300070, China; Chen, Q., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China","With the development of society and the advancement of science and technology, artificial intelligence has also emerged as the times require. In computer vision, deep learning based on convolutional neural networks(CNN) achieves state-of-the-art performance. However, the massive data requirements of deep learning have long been a pain point in the field, especially in the medical field, where it is often difficult (and sometimes impossible) to obtain enough training data for some specific tasks. To overcome insufficient and unbalanced data, in this paper, we focus on the generation and balance of data on radiation-induced pneumonia, an extremely rare disease with a low incidence. As a result, datasets on this disease are extremely sparse and unevenly distributed. To address the above problems, the predecessors' method is often to use generative models to generate data as a complement of the fewer samples to achieve a balanced distribution of data samples. Among various generative models, CycleGAN is widely used in medical image generation due to its cycle consistency to achieve style migration without changing the basic content. However, the original CycleGAN method has many shortcomings, especially in Few-shot and the data unevenly distributed, its performance will be greatly reduced. To make the generated data samples retain the original structure and have finer and clearer details, this paper proposes a mask-based self-attention CycleGAN data augmentation method. A self-attention branch is added to the generator and two different loss functions named Self-Attention Loss and Mask Loss are designed. To stabilize the training process, spectral normalization is introduced to improve the discriminator and MS-SSIM and L1 joint loss are used to improve the original identity loss. The ResNet18 is used to complete classification experiments on the radiation-induced pneumonia dataset and the COVID-19 dataset respectively. Four classification performance indicators: the area under the ROC curve (AUC), Accuracy (ACC), Sensitivity (SEN), and Specificity (SPE) are calculated to verify the effectiveness and generalization of our method. Compared with the original CycleGAN and traditional data augmentation, the classifier trained by data augmentation using our method has outstanding performance in multiple classification indicators and has better classification performance. Experimental results show that our method solves the problem of insufficient samples and data imbalance in the pneumonia dataset by generating high-quality pneumonia images. © 2013 IEEE.",Cycle generative adversarial networks; deep learning; medical data augmentation,Classification (of information); COVID-19; Deep learning; Diagnosis; Medical imaging; Neural networks; Biomedical monitoring; Cycle generative adversarial network; Data augmentation; Deep learning; Generator; Lung; Medical data; Medical data augmentation; Medical diagnostic imaging; Training data; Generative adversarial networks,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85140198208
"Xu B., Zhou F.",57735639500;57735475100;,The Roles of Cloud-Based Systems on the Cancer-Related Studies: A Systematic Literature Review,2022,IEEE Access,10,,,64126,64145,,1,10.1109/ACCESS.2022.3181147,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131745122&doi=10.1109%2fACCESS.2022.3181147&partnerID=40&md5=4ac0ad50f22d7faf80b3b28a31b61c43,"Library and Information Centre, Taizhou Vocational & Technical College, Taizhou, Zhejiang, 318000, China; Digital Office, Zhejiang Gongshang University, Hangzhou, Zhejiang, 310018, China","Xu, B., Library and Information Centre, Taizhou Vocational & Technical College, Taizhou, Zhejiang, 318000, China; Zhou, F., Digital Office, Zhejiang Gongshang University, Hangzhou, Zhejiang, 310018, China","The advances in wireless-based technologies and intelligent diagnostics and forecasting such as cloud computing have significantly affected our lifestyle, observed in many fields, especially healthcare. Also, since the number of new cases of cancer has become very high, there is a need to investigate this matter deeply. Still, there is no systematic review on the application or implementation of the cloud in cancer-care services. Hence, this paper has introduced a comprehensive review of a cloud-centered healthcare system that emphasizes treatment ways for different types of cancer until Sep 2021. The results have shown that the largest study was about the relationship between cancer and the cloud associated with breast cancer. Also, the results have shown that cloud computing eases data protection, privacy, and medical record access. Using cloud computing in hospitals, physicians will use advanced programs and tools, and nurses will quickly access patients- information with new Wireless-based technologies. A strong understanding of the practical features of cloud computing will help scientists navigate the massive data ecosystems in cancer research. So, by highlighting the advantages and drawbacks of analyzed articles, this study provides a comprehensive and up-to-date report on the field of cloud-based cancer studies to fill the previous gaps. © 2022 IEEE.",artificial intelligence; cancer; Cloud computing; intelligent diagnostics; wireless-based technologies,Cloud computing; Diagnosis; Health care; Medical imaging; Breast Cancer; Cloud-based; Cloud-computing; Colon; Intelligent diagnostics; Medical diagnostic imaging; Medical services; Systematic literature review; Wireless-based technology; Diseases,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85131745122
"Xu B., Zhou D., Li W.",57232013200;57559593400;57560695500;,Image Enhancement Algorithm Based on GAN Neural Network,2022,IEEE Access,10,,,36766,36777,,5,10.1109/ACCESS.2022.3163241,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127490368&doi=10.1109%2fACCESS.2022.3163241&partnerID=40&md5=c6c2d846fc81a5320cc2e0be3930f58b,"School of Electronic Computer Engineering, Hainan Vocational University of Science and Technology, Hainan, 570100, China; Library, China Jiliang University, Zhejiang, Hangzhou, 310018, China; Department of Electronic Science and Engineering, North China Electrical Power University, Beijing, 100096, China","Xu, B., School of Electronic Computer Engineering, Hainan Vocational University of Science and Technology, Hainan, 570100, China; Zhou, D., Library, China Jiliang University, Zhejiang, Hangzhou, 310018, China; Li, W., Department of Electronic Science and Engineering, North China Electrical Power University, Beijing, 100096, China","Deep underwater color images have problems such as low brightness, poor contrast, and loss of local details. In order to effectively enhance low-quality underwater images, this paper proposes an enhancement method based on GAN (Generative Adversarial Network). This paper studies low-light image enhancement algorithms, aiming to improve the quality of low-light images by studying some technical means and methods, and restore the original scene information of low-quality images, so as to obtain natural and clear images with complete details and structural information. In order to verify the effectiveness of this method, image databases such as DIARETDB0 and SID are used as the research object, combined with multi-scale Retinex color reproduction contrast-constrained adaptive histogram equalization to compare the performance of the enhanced algorithm. The results show that the processed image is better than other image enhancement methods in terms of color protection, contrast enhancement, and image detail enhancement. The proposed method significantly improves the indicators proposed in the article. © 2013 IEEE.",deep learning; GAN; image enhancement; Underwater image enhancement,Color; Deep neural networks; Image enhancement; Underwater imaging; Colour image; Convolutional neural network; Deep learning; Image color analysis; Image enhancement algorithm; Low qualities; Low-light images; Neural-networks; Quality image; Underwater image enhancements; Generative adversarial networks,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85127490368
"Lu Z., Zhao J., Sun Y., Xu F., Ma X.",16643517200;57551986100;57549646800;14919969100;57551986200;,A Multi-Feature Fusion Network for Pathological Identification of Tumor Cells,2022,IEEE Access,10,,,31145,31154,,,10.1109/ACCESS.2022.3160290,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127057431&doi=10.1109%2fACCESS.2022.3160290&partnerID=40&md5=35d3c3b4160a8390ee5ab934f23a2e5d,"College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; State Grid Heilongjiang Provincial Electric Power Company Ltd., Heilongjiang, Daqing, 163458, China","Lu, Z., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Zhao, J., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Sun, Y., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Xu, F., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Ma, X., State Grid Heilongjiang Provincial Electric Power Company Ltd., Heilongjiang, Daqing, 163458, China","A novel multi-feature fusion neural network (MFNet) is proposed to address the lack of applicability of existing medical aid diagnostic methods for cross-site and cross-tissue cytopathic lesion screening. MFNet consists of a data-sharing layer, a detailed feature transfer branch, a microscopic identification branch, and an auxiliary loss function. The data-sharing layer converts data images into a feature matrix and extracts detailed elements such as cell morphology, contour, and texture. The microscopic recognition branch obtains multilevel elements by convolving the input elements in stages and fusing them, so that the network can focus on high-level semantic elements such as minor differences of cytopathy. The detail feature transfer branch transfers detail elements across layers and achieves cross-layer fusion with semantic elements. The auxiliary loss function enables the network feature classification capability to be enhanced. MFNet is experimentally compared with AlexNet, VGG-16, ResNet-50, and other models on the tumor cell datasets, and the results show that the proposed method can effectively improve the recognition accuracy. © 2013 IEEE.",convolutional neural network; multi-feature fusion; pathology recognition; Tumour cells,Cells; Convolution; Cytology; Data mining; Diagnosis; Neural networks; Tumors; Convolutional neural network; Data Sharing; Feature transfers; Features extraction; License; Loss functions; Multi-feature fusion; Neural-networks; Pathology recognition; Tumour cells; Semantics,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85127057431
"Iqbal T., Shaukat A., Akram M.U., Muzaffar A.W., Mustansar Z., Byun Y.-C.",57221870946;36634907200;24474159700;56809060000;25422450100;8897891700;,A Hybrid VDV Model for Automatic Diagnosis of Pneumothorax Using Class-Imbalanced Chest X-Rays Dataset,2022,IEEE Access,10,,,27670,27683,,1,10.1109/ACCESS.2022.3157316,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126313004&doi=10.1109%2fACCESS.2022.3157316&partnerID=40&md5=83381031e5f2fe33ce8ae79926fa3b2c,"Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; College of Computing and Informatics, Saudi Electronic University, Riyadh, 11673, Saudi Arabia; Research Centre for Modelling and Simulation (RCMS), National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Department of Computer Engineering, Jeju National University, Jeju, 690756, South Korea","Iqbal, T., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Shaukat, A., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Akram, M.U., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Muzaffar, A.W., College of Computing and Informatics, Saudi Electronic University, Riyadh, 11673, Saudi Arabia; Mustansar, Z., Research Centre for Modelling and Simulation (RCMS), National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Byun, Y.-C., Department of Computer Engineering, Jeju National University, Jeju, 690756, South Korea","Pneumothorax, a life-threatening disease, needs to be diagnosed immediately and efficiently. The prognosis, in this case, is not only time-consuming but also prone to human errors. So, an automatic way of accurate diagnosis using chest X-rays is the utmost requirement. To date, most of the available medical image datasets have a class-imbalance (CI) issue. The main theme of this study is to solve this problem along with proposing an automated way of detecting pneumothorax. To find the optimal approach for CI problem, we first compare the existing approaches and find that under-bagging method (referred as data-level-ensemble formed by creating subsets of majority class and then combining each subset with all samples of minority class) outperforms other existing approaches. After selection of best approach for CI problem, we propose a novel framework, named as VDV model, for pneumothorax detection from highly imbalance dataset. The proposed VDV model is a complex model-level ensemble of data-level-ensembles and uses three convolutional neural networks (CNN) including VGG16, VGG-19, and DenseNet-121 as fixed feature extractors. In each data-level-ensemble, features extracted from one of the pre-defined CNN architectures are fed to support vector machine (SVM) classifier, and output is calculated using the voting method. Once outputs from the three data-level-ensembles (corresponding to three different CNN architectures as feature extractor) are obtained, then, again, the voting method is used to calculate the final prediction. Our proposed framework is tested on the SIIM ACR Pneumothorax dataset and Random Sample of NIH Chest X-ray dataset (RS-NIH). For the first dataset, 85.17% Recall with 86.0% Area under the Receiver Operating Characteristic curve (AUC) is attained. For the second dataset, 90.9% Recall with 95.0% AUC is achieved with a random split of data while 85.45% recall with 77.06% AUC is obtained with a patient-wise split of data. The comparison of our results for both the datasets with related work proves the effectiveness of proposed VDV model for pneumothorax detection. © 2013 IEEE.",chest X-rays; Class-imbalance; classification; deep learning; ensemble; machine learning; pneumothorax; under-bagging,Classification (of information); Convolution; Deep learning; Diagnosis; Medical imaging; Network architecture; Neural networks; Problem solving; Biomedical imaging; Chest X-ray; Class imbalance; Convolutional neural network; Deep learning; Ensemble; Features extraction; Machine-learning; Pneumothorax; Support vectors machine; Under-bagging; X-ray imaging; Support vector machines,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85126313004
"Mehmood S., Ghazal T.M., Khan M.A., Zubair M., Naseem M.T., Faiz T., Ahmad M.",57226140474;57224545303;57215096761;57215854699;54956353900;57217314048;57226132376;,Malignancy Detection in Lung and Colon Histopathology Images Using Transfer Learning with Class Selective Image Processing,2022,IEEE Access,10,,,25657,25668,,30,10.1109/ACCESS.2022.3150924,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124745643&doi=10.1109%2fACCESS.2022.3150924&partnerID=40&md5=059e4feb0ac3111cba8dc4edbf07eaec,"Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Selangor, Bangi, Malaysia; School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Pattern Recognition and Machine Learning Laboratory, Department of Software, Gachon University, Seongnam-si, 13557, South Korea; Faculty of Computing, Riphah International University, Islamabad, Pakistan; Human Ecology Research Center, Yeungnam University, Gyeongsan-si, 712-749, South Korea; School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan","Mehmood, S., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Ghazal, T.M., Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Selangor, Bangi, Malaysia, School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Khan, M.A., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan, Pattern Recognition and Machine Learning Laboratory, Department of Software, Gachon University, Seongnam-si, 13557, South Korea; Zubair, M., Faculty of Computing, Riphah International University, Islamabad, Pakistan; Naseem, M.T., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan, Human Ecology Research Center, Yeungnam University, Gyeongsan-si, 712-749, South Korea; Faiz, T., School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Ahmad, M., School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan","Cancer accounts for a huge mortality rate due to its aggressiveness, colossal potential of metastasis, and heterogeneity (causing resistance against chemotherapy). Lung and colon cancers are among the most prevalent types of cancer around the globe that can occur in both males and females. Early and accurate diagnosis of these cancers can substantially improve the quality of treatment as well as the survival rate of cancer patients. We propose a highly accurate and computationally efficient model for the swift and accurate diagnosis of lung and colon cancers as an alternative to current cancer detection methods. In this study, a large dataset of lung and colon histopathology images was employed for training and the validation process. The dataset is comprised of 25000 histopathology images of lung and colon tissues equally divided into 5 classes. A pretrained neural network (AlexNet) was tuned by modifying the four of its layers before training it on the dataset. Initial classification results were promising for all classes of images except for one class with an overall accuracy of 89%. To improve the overall accuracy and keep the model computationally efficient, instead of implementing image enhancement techniques on the entire dataset, the quality of images of the underperforming class was improved by applying a contrast enhancement technique which is fairly simple and efficient. The implementation of the proposed methodology has not only improved the overall accuracy from 89% to 98.4% but has also proved computationally efficient. © 2013 IEEE.",Colon cancer; convolutional neural networks; histopathology; image processing; lung cancer; transfer learning,Biological organs; Chemotherapy; Computational efficiency; Computerized tomography; Convolution; Diagnosis; Diseases; Image enhancement; Neural networks; Colon; Colon cancer; Convolutional neural network; Features extraction; Histopathology; Images processing; Lung Cancer; Transfer learning; Feature extraction,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124745643
"Khan M.Z., Gajendran M.K., Lee Y., Khan M.A.",57224310759;57224319816;57293981900;57202773102;,Deep Neural Architectures for Medical Image Semantic Segmentation: Review,2021,IEEE Access,9,,9447006,83002,83024,,30,10.1109/ACCESS.2021.3086530,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107324395&doi=10.1109%2fACCESS.2021.3086530&partnerID=40&md5=fb42cf670da714db9b4e293d888dc568,"School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Department of Computer Science, Quaid-i-Azam University, Islamabad, 44000, Pakistan","Khan, M.Z., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Gajendran, M.K., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Lee, Y., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Khan, M.A., Department of Computer Science, Quaid-i-Azam University, Islamabad, 44000, Pakistan","Deep learning has an enormous impact on medical image analysis. Many computer-aided diagnostic systems equipped with deep networks are rapidly reducing human intervention in healthcare. Among several applications, medical image semantic segmentation is one of the core areas of active research to delineate the anatomical structures and other regions of interest. It has a significant contribution to healthcare and provides guided interventions, radiotherapy, and improved radiological diagnostics. The underlying article provides a brief overview of deep convolutional neural architecture, the platforms and applications of deep neural networks, metrics used for empirical evaluation, state-of-the-art semantic segmentation architectures based on a foundational convolution concept, and a review of publicly available medical image datasets highlighting four distinct regions of interest. The article also analyzes the existing work and provides open-ended potential research directions in deep medical image semantic segmentation. © 2013 IEEE.",computer-aided diagnostics; convolution neural network; Deep learning; encoder-decoder; healthcare; medical image analysis; semantic segmentation; skip-connections,Convolution; Deep learning; Deep neural networks; Diagnosis; Health care; Image analysis; Image segmentation; Medical computing; Network architecture; Semantics; Anatomical structures; Computer aided diagnostics; Empirical evaluations; Human intervention; Neural architectures; Potential researches; Regions of interest; Semantic segmentation; Medical image processing,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85107324395
"Guo W., Zhou H., Gong Z., Zhang G.",57087666000;16834001800;56421223000;56906335400;,Double U-Nets for Image Segmentation by Integrating the Region and Boundary Information,2021,IEEE Access,9,,9416935,69382,69390,,4,10.1109/ACCESS.2021.3075294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105071675&doi=10.1109%2fACCESS.2021.3075294&partnerID=40&md5=7063b44cbd923860ad39af88740192c0,"School of Computer, Shenyang Aerospace University, Shenyang, China; Department of Information Science, Liaoning University, Shenyang, China","Guo, W., School of Computer, Shenyang Aerospace University, Shenyang, China; Zhou, H., Department of Information Science, Liaoning University, Shenyang, China; Gong, Z., School of Computer, Shenyang Aerospace University, Shenyang, China; Zhang, G., School of Computer, Shenyang Aerospace University, Shenyang, China","The existing CNN-based segmentation methods use the object regions alone as the labels to train their networks, and the potentially useful boundaries annotated by radiologists are not used directly during the training. Thus, we proposed a framework of double U-Nets to integrate object regions and boundaries for more accurate segmentation. The proposed network consisted of a down-sampling path followed by two symmetric up-sampling paths. The down-sampling path learned the low-level features of regions and boundaries, and two up-sampling paths learned the high-level features of regions and boundaries, respectively. The outputs from the down-sampling path were concatenated with the corresponding ones from two up-sampling paths by skip connections. The outputs of double U-Nets were the predicted probability images of object regions and boundaries, and they were integrated to calculate the dice loss with the corresponding labels. The proposed double U-Nets were evaluated on two datasets: 247 radiographs for the segmentation of lungs, hearts, and clavicles, and 284 radiographs for the segmentation of pelvises. Compared with the baseline U-Net, our double U-Nets improved the mean dices and reduced the 90% Hausdorff distances for the 'difficult' objects (lower lungs, clavicles, and pelvises), and the integration of 'difficult' object regions and boundaries can improve the segmentation results compared with the use of object regions alone. However, for the 'easy' objects (entire lungs and hearts) or 'very difficult' objects (pelvises in lateral and implanted images), the integration did not improve the segmentation performance. © 2013 IEEE.",double U-Nets; Image segmentation; integrate regions and boundaries,Image enhancement; Radiography; Signal sampling; Boundary information; Hausdorff distance; High-level features; Low-level features; Probability image; Segmentation methods; Segmentation performance; Segmentation results; Image segmentation,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85105071675
"Zhang H., Lai H., Wang Y., Lv X., Hong Y., Peng J., Zhang Z., Chen C., Chen C.",57222405149;57193405714;57221509994;36149385700;57218527607;57222406776;57215061375;57201197524;57211218832;,Research on the Classification of Benign and Malignant Parotid Tumors Based on Transfer Learning and a Convolutional Neural Network,2021,IEEE Access,9,,9373340,40360,40371,,10,10.1109/ACCESS.2021.3064752,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102619943&doi=10.1109%2fACCESS.2021.3064752&partnerID=40&md5=f6b216da5e5f980558a282829df749d8,"College of Information Science and Engineering, Xinjiang University, Urumqi, China; Radiology Center, People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, China; College of Software, Xinjiang University, Urumqi, China; Key Laboratory of Signal Detection and Processing, Xinjiang University, Urumqi, 830001, China; Department of Information, People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, China","Zhang, H., College of Information Science and Engineering, Xinjiang University, Urumqi, China, Key Laboratory of Signal Detection and Processing, Xinjiang University, Urumqi, 830001, China; Lai, H., College of Information Science and Engineering, Xinjiang University, Urumqi, China, Key Laboratory of Signal Detection and Processing, Xinjiang University, Urumqi, 830001, China; Wang, Y., Radiology Center, People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, China; Lv, X., College of Software, Xinjiang University, Urumqi, China, Key Laboratory of Signal Detection and Processing, Xinjiang University, Urumqi, 830001, China; Hong, Y., Radiology Center, People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, China; Peng, J., Department of Information, People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, China; Zhang, Z., College of Information Science and Engineering, Xinjiang University, Urumqi, China; Chen, C., College of Information Science and Engineering, Xinjiang University, Urumqi, China; Chen, C., College of Information Science and Engineering, Xinjiang University, Urumqi, China","The classification of benign and malignant parotid tumors is very crucial for the selection of surgical methods and their prognoses. The wide application of deep learning technology in the field of medical imaging also provides new ideas for the computer-aided diagnosis of parotid gland tumors. In addition, because the pathological types of parotid gland tumors are very complicated and the computed tomography (CT) images of benign and malignant patients are also very similar, some clinicians may misjudge tumors due to a lack of experience, which affects the effect of surgical treatment and prognosis. Therefore, this research proposes using deep learning methods to solve this problem. This study uses the four classic pretraining models of VGG16, InceptionV3, ResNet and DenseNet to classify parotid CT images using transfer learning methods and uses an improved convolutional neural network (CNN) model to classify parotid CT images. The experimental results show that the improved CNN model achieves an accuracy of 97.78%, and its classification performance is better than those of the other four transfer learning methods. It can effectively diagnose benign and malignant parotid tumors and improve the diagnostic accuracy. © 2013 IEEE.",convolutional neural network; CT image; deep learning; Parotid gland tumor; transfer learning,Computer aided diagnosis; Computer aided instruction; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Image classification; Image enhancement; Medical imaging; Surgery; Transfer learning; Tumors; Classification performance; Diagnostic accuracy; Learning methods; Learning technology; Malignant parotid tumors; Parotid gland tumors; Surgical treatment; Transfer learning methods; Learning systems,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85102619943
"Peng J., Wang Y.",55265406900;57207004099;,Medical image segmentation with limited supervision: A review of deep network models,2021,IEEE Access,9,,9363892,36827,36851,,20,10.1109/ACCESS.2021.3062380,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101798258&doi=10.1109%2fACCESS.2021.3062380&partnerID=40&md5=4418eb1a70dc9bfcf72f81ef5f664760,"College of Computer Science and Technology, Huaqiao University, Xiamen, 361021, China; School of Economics and Finance, Huaqiao University, Xiamen, 361021, China","Peng, J., College of Computer Science and Technology, Huaqiao University, Xiamen, 361021, China; Wang, Y., School of Economics and Finance, Huaqiao University, Xiamen, 361021, China","Despite the remarkable performance of deep learning methods on various tasks, most cutting-edge models rely heavily on large-scale annotated training examples, which are often unavailable for clinical and health care tasks. The labeling costs for medical images are very high, especially in medical image segmentation, which typically requires intensive pixel/voxel-wise labeling. Therefore, the strong capability of learning and generalizing from limited supervision, including a limited amount of annotations, sparse annotations, and inaccurate annotations, is crucial for the successful application of deep learning models in medical image segmentation. However, due to its intrinsic difficulty, segmentation with limited supervision is challenging and specific model design and/or learning strategies are needed. In this paper, we provide a systematic and up-to-date review of the solutions above, with summaries and comments about the methodologies. We also highlight several problems in this field, discussed future directions observing further investigations. © 2013 IEEE.",Medical image segmentation; noisy label; partially-supervised segmentation; semi-supervised segmentation; sparse annotation,Deep learning; Image segmentation; Learning systems; Cutting edges; Learning methods; Learning models; Learning strategy; Model design; Network models; Training example; Medical image processing,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85101798258
"Tang S., Ma R., Li Q., Bai Y., Chen S.",57218674353;57218143894;57222171722;57222168241;57222169415;,Classification of Benign and Malignant Pulmonary Nodules Based on the Multiresolution 3D DPSECN Model and Semisupervised Clustering,2021,IEEE Access,9,,9357428,43397,43410,,4,10.1109/ACCESS.2021.3060178,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101743287&doi=10.1109%2fACCESS.2021.3060178&partnerID=40&md5=58b5f8dc9d8cdc5993b28d520b3b9a83,"Baotou Medical College, Inner Mongolia University of Science and Technology, Baotou, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; Department of Respiratory, Zhuji People's Hospital of Zhejiang Province, Zhuji, China","Tang, S., Baotou Medical College, Inner Mongolia University of Science and Technology, Baotou, China; Ma, R., School of Artificial Intelligence, Beijing Normal University, Beijing, China; Li, Q., Baotou Medical College, Inner Mongolia University of Science and Technology, Baotou, China; Bai, Y., Baotou Medical College, Inner Mongolia University of Science and Technology, Baotou, China; Chen, S., Department of Respiratory, Zhuji People's Hospital of Zhejiang Province, Zhuji, China","Deep learning model training requires a large number of labeled samples, but the acquisition of labeled samples is time-consuming and laborious in the medical field. To solve this problem, a semisupervised clustering algorithm combined with a 3D convolutional neural network model is proposed to improve the classification performance for benign and malignant pulmonary nodules. The research contents are as follows: Firstly, a multiresolution 3D dual path squeeze excitation deep learning network model is constructed. Then, the feature extractor in the network model is used to extract the high-level features of the image, and semisupervised clustering is applied to the extracted image features. The corresponding pseudolabels can be obtained for the unlabeled samples, and the categories of unlabeled samples are determined and utilized. Finally, the oversampling algorithm is used to balance the data categories of different types of samples, and the benign and malignant pulmonary nodules are classified by a classifier constructed by a 3D dual path squeeze excitation network. The experimental results show that the proposed semisupervised clustering algorithm can label the categories of unlabeled samples. The proposed network model can learn more characteristics related to pulmonary nodules and can effectively improve the classification performance of pulmonary nodules. The proposed network model was tested using Lung Image Database Consortium (LIDC-IDRI) dataset, and an accuracy of 94.4% and an AUC of 0.931 were obtained. Compared with some existing classification models, the proposed method can achieve a better classification effect of pulmonary nodules. © 2013 IEEE.",benign and malignant classification of pulmonary nodules; Deep learning; LIDC-IDRI dataset; multiresolution 3D dual path squeeze excitation deep learning network model; semisupervised clustering algorithm,3D modeling; Convolutional neural networks; Deep learning; Learning systems; Three dimensional computer graphics; Classification models; Classification performance; Feature extractor; High-level features; Pulmonary nodules; Semi-supervised Clustering; Semi-supervised clustering algorithms; Unlabeled samples; Clustering algorithms,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85101743287
"Ye Y., Tian M., Liu Q., Tai H.-M.",57222473637;55918225100;57168976100;7201667648;,Pulmonary Nodule Detection Using V-Net and High-Level Descriptor Based SVM Classifier,2020,IEEE Access,8,,,176033,176041,,12,10.1109/ACCESS.2020.3026168,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102816148&doi=10.1109%2fACCESS.2020.3026168&partnerID=40&md5=7a847dff5e88573db277db402086300b,"Department of Electrical and Computer Engineering, University of Tulsa, Tulsa, OK  74104, United States; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, 611731, China; Department of Radiology, Mianyang Central Hospital, Mianyang, 621000, China","Ye, Y., Department of Electrical and Computer Engineering, University of Tulsa, Tulsa, OK  74104, United States; Tian, M., School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, 611731, China; Liu, Q., Department of Radiology, Mianyang Central Hospital, Mianyang, 621000, China; Tai, H.-M., Department of Electrical and Computer Engineering, University of Tulsa, Tulsa, OK  74104, United States","Early detection of the pulmonary nodule is critical to increase the five-year survival rate of lung cancer. Many computer-Aided diagnosis (CAD) systems have been proposed for nodule detection to assist radiologists in diagnosis. Along this direction, this paper proposes a novel automated pulmonary nodule detection model using the modified V-Nets and a high-level descriptor based support vector machine (SVM) classifier. The former is for nodule candidate detection and the latter is for false positive (FP) reduction. A hard mining scheme for retraining is devised to improve the FP reduction performance. The proposed SVM classifier, which employs more critical features of CT images, performs superior in FP reduction than other SVM based classifiers and CNN classifiers. Experimental results using the LIDC-IDRI dataset are presented to demonstrate the effectiveness of the proposed CAD model. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",,Computer aided diagnosis; Computerized tomography; Computer Aided Diagnosis(CAD); Critical features; High-level descriptor; Nodule detection; Pulmonary nodule detection; Pulmonary nodules; SVM classifiers; SVM-based classifiers; Support vector machines,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85102816148
"Hu X., Yang J., Yang J.",57213687124;8420664900;56080490800;,A CNN-Based Approach for Lung 3D-CT Registration,2020,IEEE Access,8,,9234532,192835,192843,,4,10.1109/ACCESS.2020.3032612,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096031294&doi=10.1109%2fACCESS.2020.3032612&partnerID=40&md5=94ebcaebcadc879695b878aae0965bc2,"School of Physics and Electronics, Shandong Normal University, Jinan, China","Hu, X., School of Physics and Electronics, Shandong Normal University, Jinan, China; Yang, J., School of Physics and Electronics, Shandong Normal University, Jinan, China; Yang, J., School of Physics and Electronics, Shandong Normal University, Jinan, China","Deep learning techniques have been applied to certain rigid or non-rigid medical image registration due to its potential advantages in meeting the clinical requirements of real-time and accuracy. Based on the deep learning model, this study aims to explore specific network models suitable for lung CT images. The proposed model took unlabeled 3D image pairs as input, and the convolutional neural network (CNN) was utilized and identified as a function with ability of sharing parameters to obtain displacement field. The image pair could be aligned by applying the acquired displacement field to the target image through spatial transformation. The similarity between the aligned image pair combined with the constraints on the displacement field was taken as the objective function to obtain the optimal parameters. Two models with different depths were designed and the consequent registration effects with different optimization methods and convolution kernel sizes were explored. The results proved that the designs with deeper level using Adam optimizer and smaller convolution kernels in obtaining displacement fields had higher accuracy and stronger robustness. The accuracy of the unsupervised model was comparable to state-of-the-art methods, while operating orders of magnitude faster. This study proposed a feasible registration method for lung 3D-CT, and its usefulness in aligning CT images has been demonstrated. © 2013 IEEE.",4D-CT; convolutional neural network; deformable registration; loss function; spatial transformation,3D modeling; Biological organs; Convolution; Convolutional neural networks; Deep learning; Image registration; Learning systems; Medical imaging; Displacement field; Learning techniques; Objective functions; Optimization method; Orders of magnitude; Registration methods; Spatial transformation; State-of-the-art methods; Computerized tomography,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85096031294
"Cao W., Wu R., Cao G., He Z.",7402082924;57693755700;35253286200;7403885484;,A Comprehensive Review of Computer-Aided Diagnosis of Pulmonary Nodules Based on Computed Tomography Scans,2020,IEEE Access,8,,9173767,154007,154023,,15,10.1109/ACCESS.2020.3018666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090549964&doi=10.1109%2fACCESS.2020.3018666&partnerID=40&md5=71d695b8a0a4c67a09d8d7f0400afdc8,"Guangdong Multimedia Information Service Engineering Technology Research Center, Shenzhen University, Shenzhen, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; Department of Electrical and Computer Engineering, Video Processing and Communication Laboratory, University of Missouri, Columbia, MO, United States","Cao, W., Guangdong Multimedia Information Service Engineering Technology Research Center, Shenzhen University, Shenzhen, China; Wu, R., Guangdong Multimedia Information Service Engineering Technology Research Center, Shenzhen University, Shenzhen, China; Cao, G., Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; He, Z., Department of Electrical and Computer Engineering, Video Processing and Communication Laboratory, University of Missouri, Columbia, MO, United States","Lung cancer is one of the malignant tumor diseases with the fastest increase in morbidity and mortality, which poses a great threat to human health. Low-Dose Computed Tomography (LDCT) screening has been proved as a practical technique for improving the accuracy of pulmonary nodule detection and classification at early cancer diagnosis, which helps to reduce mortality. Therefore, with the explosive growth of CT data, it is of great clinical significance to exploit an effective Computer-Aided Diagnosis (CAD) system for radiologists on automatic nodule analysis. In this article, a comprehensive review of the application and development of CAD systems is presented. The experimental benchmarks for nodule analysis are first described and summarized, covering public datasets of lung CT scans, commonly used evaluation metrics and various medical competitions. We then introduce the main structure of a CAD system and present some efficient methodologies. For the extensive use of Convolutional Neural Network (CNN) based methods in pulmonary nodule investigations recently, we summarized the advantages of CNNs over traditional image processing methods. Besides, we mainly select the CAD systems developed by state-of-the-art CNNs with excellent performance and analyze their objectives, algorithms as well as results. Finally, research trends, existing challenges, and future directions in this field are discussed. © 2013 IEEE.",CAD; classification; CNN; CT scans; lung cancer; pulmonary nodules detection,Biological organs; Computer aided analysis; Computerized tomography; Convolutional neural networks; Diseases; Health risks; Positron emission tomography; Computed tomography scan; Computer Aided Diagnosis(CAD); Evaluation metrics; Experimental benchmarks; Image processing - methods; Malignant tumors; Pulmonary nodule detection; Pulmonary nodules; Computer aided diagnosis,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85090549964
"Chen Y., Wang Y., Hu F., Wang D.",55870779500;57209144813;57211040846;57193736255;,A Lung Dense Deep Convolution Neural Network for Robust Lung Parenchyma Segmentation,2020,IEEE Access,8,,9091318,93527,93547,,13,10.1109/ACCESS.2020.2993953,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086023441&doi=10.1109%2fACCESS.2020.2993953&partnerID=40&md5=ec69b9b90ff3af2f4131035a7269820e,"School of Software, Nanchang Hangkong University, Nanchang, 330063, China","Chen, Y., School of Software, Nanchang Hangkong University, Nanchang, 330063, China; Wang, Y., School of Software, Nanchang Hangkong University, Nanchang, 330063, China; Hu, F., School of Software, Nanchang Hangkong University, Nanchang, 330063, China; Wang, D., School of Software, Nanchang Hangkong University, Nanchang, 330063, China","Lung parenchyma segmentation is the prerequisite for an automatic diagnosis system to analyze lung CT (computed tomography) images. However, traditional lung segmentation algorithms have poor adaptability and are not effectively robust regarding lung databases with blood vessels and small voids which can interfere the segmentation. The main work of this paper is as follows: Firstly, a lung dense deep convolutional neural network (LDDNet) is proposed, which adopts some popular optimizer methods, such as dense block, batch normalization (BN) and dropout. The performance of LDDNet is tested on the public lung database LIDC-IDRI which contains many cases of interference for segmentation. Secondly, the labeled with blood vessels and small voids are not contained by the public ground-truth masks of the LIDC-IDRI database, therefore these regions are labeled by us with LabelMe software. Thirdly, for the aim of exploring the effect of image preprocessing on segmenting lung CT images with deep neural network, contrast enhancing, median filtering and Laplacian filtering are used to preprocess the image as comparative experiments. Finally, dataset is classified into four classes by the geometrical shapes to test the performance of LDDNet. The accuracy of the segmentation experiment reaches over 99% and the four classes can all reach over 95%. Additionally, blood vessels and small voids are segmented out from the lung parenchyma which is not achieved by other methods. Experimental results confirm that the proposed LDDNet can segment the lung parenchymal area more accurately and has better robustness in comparison with other neural networks and most of the traditional methods. © 2013 IEEE.",Deep dense neural network; lung segmentation; robustness,Biological organs; Blood; Blood vessels; Computerized tomography; Convolution; Convolutional neural networks; Database systems; Deep neural networks; Image enhancement; Median filters; Statistical tests; Automatic diagnosis; Comparative experiments; Convolution neural network; Geometrical shapes; Image preprocessing; Lung parenchyma segmentation; Lung segmentation; Median filtering; Image segmentation,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85086023441
"Zhang Q., Kong X.",57216966168;57216963088;,Design of Automatic Lung Nodule Detection System Based on Multi-Scene Deep Learning Framework,2020,IEEE Access,8,,9091120,90380,90389,,14,10.1109/ACCESS.2020.2993872,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085557336&doi=10.1109%2fACCESS.2020.2993872&partnerID=40&md5=1e9e1d3b0917c4a3418bb777410cbddb,"Imaging Department, Third People's Hospital of Zibo, Zibo, 255000, China","Zhang, Q., Imaging Department, Third People's Hospital of Zibo, Zibo, 255000, China; Kong, X., Imaging Department, Third People's Hospital of Zibo, Zibo, 255000, China","Nowadays, the efficient identification of the lung nodule greatly leads to the chance of lung cancer risk assessment. Hence, the exact locations of lung nodules are a critical and complicated task. Researchers in this area have been working widely for almost two years. However, previous computer-aided detection (CAD) modules, such as transforming CT, segmenting the lung nodule and extracting the features are mostly complex and time-consuming, because more modules will require the creation of a complete image processing system. In addition, certain state-of-the-art deep learning systems are specified in the database standard. For this purpose, this paper suggests an efficient identification system for lung nodules based on Multi-Scene Deep Learning Framework (MSDLF) by the vesselness filter. A four-channel CNN model is designed to enhance the radiologist's knowledge in the detection of four-stage nodules by integrating two image Scenes. This model can be applied in two different classes. The results show that the Multi-Scene Deep Learning Framework (MSDLF) is efficient for increasing the accuracy and significantly reducing false positives in an enormous amount of image data in the detection of lung nodules. © 2013 IEEE.",convolutional neural network (CNN); lung nodules; Multi-scene deep learning framework; vesselness filter,Biological organs; Computerized tomography; Image enhancement; Learning systems; Risk assessment; Computer-aided detection; Detection of lung nodules; Different class; Image processing system; Learning frameworks; Lung cancer risks; Lung nodule detection; State of the art; Deep learning,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85085557336
"Yu H., Zhou Z., Wang Q.",57216896066;57216288100;57191226405;,Deep Learning Assisted Predict of Lung Cancer on Computed Tomography Images Using the Adaptive Hierarchical Heuristic Mathematical Model,2020,IEEE Access,8,,9086786,86400,86410,,24,10.1109/ACCESS.2020.2992645,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085177762&doi=10.1109%2fACCESS.2020.2992645&partnerID=40&md5=80ec325d1f74ddb30711403e605a06d9,"School of Information Engineering, Pingdingshan University, Pingdingshan, 467000, China","Yu, H., School of Information Engineering, Pingdingshan University, Pingdingshan, 467000, China; Zhou, Z., School of Information Engineering, Pingdingshan University, Pingdingshan, 467000, China; Wang, Q., School of Information Engineering, Pingdingshan University, Pingdingshan, 467000, China","Lung cancer is known to be one of the most dangerous diseases which are the main reason for disease and death when diagnosed in primitive stages. Since lung cancer can only be detected more broadly after it spread to lung parts and the occurrence of lung cancer in the earlier stage is very difficult to predict. It causes a greater risk as radiologists and specialist doctors assess the existence of lung cancer. For this reason, it is important to build a smart and automatic cancer prediction system that is accurate and at which stage of cancer or to improve the accuracy of the previous cancer prediction that will help determines the type of treatment and treatment depth depending on the severity of the disease. In this paper, the Adaptive Hierarchical Heuristic Mathematical Model (AHHMM) has been proposed for the deep learning approach. To analyze deep learning based on the historical therapy scheme in the development of Non-Small Cell Lung Cancers (NSCLC) automated radiation adaptation protocols that aim at optimizing local tumor regulation at lower rates of grade 2 RP2 radiation pneumonitis. Furthermore, the system proposed consists of several steps including acquiring the image, preprocessing, binarization, thresholding, and segmentation, extraction of features and detection of deep neural network (DNN). Segmentation of the lung CT image is carried out to extract any significant feature of a segmented image, and a specific feature extraction method is implemented. The test evaluation showed that the model proposed could detect 96.67 % accuracy of the absence or presence of lung cancer. © 2013 IEEE.",deep learning; deep neural network; Lung cancer detection; mathematical model,Biological organs; Computerized tomography; Deep neural networks; Diseases; Extraction; Feature extraction; Forecasting; Image segmentation; Learning systems; Radiotherapy; Risk assessment; Adaptation protocols; Cancer prediction; Computed tomography images; Feature extraction methods; Learning approach; Non small cell lung cancer; Radiation pneumonitis; Segmented images; Deep learning,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85085177762
