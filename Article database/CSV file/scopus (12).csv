Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
"Liu J., Wang Z., Zhang Y., Traverso A., Dekker A., Zhang Z., Chen Q.",57933845400;57208488517;57814816300;56769295400;57225379184;57443658100;56479518400;,CycleGAN Clinical Image Augmentation Based on Mask Self-Attention Mechanism,2022,IEEE Access,10,,,105942,105953,,,10.1109/ACCESS.2022.3211670,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140198208&doi=10.1109%2fACCESS.2022.3211670&partnerID=40&md5=aed8b02f8066993ffa7e8c2278fee921,"Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Key Laboratory of Cancer Prevention and Therapy, National Clinical Research Center for Cancer, Tianjin's Clinical Research Center for Cancer, Department of Radiation Oncology, Tianjin Medical University, Cancer Institute and Hospital, Tianjin, 300070, China","Liu, J., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Wang, Z., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Zhang, Y., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Traverso, A., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Dekker, A., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands; Zhang, Z., Department of Radiation Oncology (Maastro), GROW School for Oncology and Developmental Biology, Maastricht University Medical CentreC, Maastricht, 6229 HX, Netherlands, Key Laboratory of Cancer Prevention and Therapy, National Clinical Research Center for Cancer, Tianjin's Clinical Research Center for Cancer, Department of Radiation Oncology, Tianjin Medical University, Cancer Institute and Hospital, Tianjin, 300070, China; Chen, Q., Key Laboratory of Data Engineering and Visual Computing, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China","With the development of society and the advancement of science and technology, artificial intelligence has also emerged as the times require. In computer vision, deep learning based on convolutional neural networks(CNN) achieves state-of-the-art performance. However, the massive data requirements of deep learning have long been a pain point in the field, especially in the medical field, where it is often difficult (and sometimes impossible) to obtain enough training data for some specific tasks. To overcome insufficient and unbalanced data, in this paper, we focus on the generation and balance of data on radiation-induced pneumonia, an extremely rare disease with a low incidence. As a result, datasets on this disease are extremely sparse and unevenly distributed. To address the above problems, the predecessors' method is often to use generative models to generate data as a complement of the fewer samples to achieve a balanced distribution of data samples. Among various generative models, CycleGAN is widely used in medical image generation due to its cycle consistency to achieve style migration without changing the basic content. However, the original CycleGAN method has many shortcomings, especially in Few-shot and the data unevenly distributed, its performance will be greatly reduced. To make the generated data samples retain the original structure and have finer and clearer details, this paper proposes a mask-based self-attention CycleGAN data augmentation method. A self-attention branch is added to the generator and two different loss functions named Self-Attention Loss and Mask Loss are designed. To stabilize the training process, spectral normalization is introduced to improve the discriminator and MS-SSIM and L1 joint loss are used to improve the original identity loss. The ResNet18 is used to complete classification experiments on the radiation-induced pneumonia dataset and the COVID-19 dataset respectively. Four classification performance indicators: the area under the ROC curve (AUC), Accuracy (ACC), Sensitivity (SEN), and Specificity (SPE) are calculated to verify the effectiveness and generalization of our method. Compared with the original CycleGAN and traditional data augmentation, the classifier trained by data augmentation using our method has outstanding performance in multiple classification indicators and has better classification performance. Experimental results show that our method solves the problem of insufficient samples and data imbalance in the pneumonia dataset by generating high-quality pneumonia images. © 2013 IEEE.",Cycle generative adversarial networks; deep learning; medical data augmentation,Classification (of information); COVID-19; Deep learning; Diagnosis; Medical imaging; Neural networks; Biomedical monitoring; Cycle generative adversarial network; Data augmentation; Deep learning; Generator; Lung; Medical data; Medical data augmentation; Medical diagnostic imaging; Training data; Generative adversarial networks,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85140198208
"Xu B., Zhou F.",57735639500;57735475100;,The Roles of Cloud-Based Systems on the Cancer-Related Studies: A Systematic Literature Review,2022,IEEE Access,10,,,64126,64145,,1,10.1109/ACCESS.2022.3181147,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131745122&doi=10.1109%2fACCESS.2022.3181147&partnerID=40&md5=4ac0ad50f22d7faf80b3b28a31b61c43,"Library and Information Centre, Taizhou Vocational & Technical College, Taizhou, Zhejiang, 318000, China; Digital Office, Zhejiang Gongshang University, Hangzhou, Zhejiang, 310018, China","Xu, B., Library and Information Centre, Taizhou Vocational & Technical College, Taizhou, Zhejiang, 318000, China; Zhou, F., Digital Office, Zhejiang Gongshang University, Hangzhou, Zhejiang, 310018, China","The advances in wireless-based technologies and intelligent diagnostics and forecasting such as cloud computing have significantly affected our lifestyle, observed in many fields, especially healthcare. Also, since the number of new cases of cancer has become very high, there is a need to investigate this matter deeply. Still, there is no systematic review on the application or implementation of the cloud in cancer-care services. Hence, this paper has introduced a comprehensive review of a cloud-centered healthcare system that emphasizes treatment ways for different types of cancer until Sep 2021. The results have shown that the largest study was about the relationship between cancer and the cloud associated with breast cancer. Also, the results have shown that cloud computing eases data protection, privacy, and medical record access. Using cloud computing in hospitals, physicians will use advanced programs and tools, and nurses will quickly access patients- information with new Wireless-based technologies. A strong understanding of the practical features of cloud computing will help scientists navigate the massive data ecosystems in cancer research. So, by highlighting the advantages and drawbacks of analyzed articles, this study provides a comprehensive and up-to-date report on the field of cloud-based cancer studies to fill the previous gaps. © 2022 IEEE.",artificial intelligence; cancer; Cloud computing; intelligent diagnostics; wireless-based technologies,Cloud computing; Diagnosis; Health care; Medical imaging; Breast Cancer; Cloud-based; Cloud-computing; Colon; Intelligent diagnostics; Medical diagnostic imaging; Medical services; Systematic literature review; Wireless-based technology; Diseases,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85131745122
"Xu B., Zhou D., Li W.",57232013200;57559593400;57560695500;,Image Enhancement Algorithm Based on GAN Neural Network,2022,IEEE Access,10,,,36766,36777,,5,10.1109/ACCESS.2022.3163241,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127490368&doi=10.1109%2fACCESS.2022.3163241&partnerID=40&md5=c6c2d846fc81a5320cc2e0be3930f58b,"School of Electronic Computer Engineering, Hainan Vocational University of Science and Technology, Hainan, 570100, China; Library, China Jiliang University, Zhejiang, Hangzhou, 310018, China; Department of Electronic Science and Engineering, North China Electrical Power University, Beijing, 100096, China","Xu, B., School of Electronic Computer Engineering, Hainan Vocational University of Science and Technology, Hainan, 570100, China; Zhou, D., Library, China Jiliang University, Zhejiang, Hangzhou, 310018, China; Li, W., Department of Electronic Science and Engineering, North China Electrical Power University, Beijing, 100096, China","Deep underwater color images have problems such as low brightness, poor contrast, and loss of local details. In order to effectively enhance low-quality underwater images, this paper proposes an enhancement method based on GAN (Generative Adversarial Network). This paper studies low-light image enhancement algorithms, aiming to improve the quality of low-light images by studying some technical means and methods, and restore the original scene information of low-quality images, so as to obtain natural and clear images with complete details and structural information. In order to verify the effectiveness of this method, image databases such as DIARETDB0 and SID are used as the research object, combined with multi-scale Retinex color reproduction contrast-constrained adaptive histogram equalization to compare the performance of the enhanced algorithm. The results show that the processed image is better than other image enhancement methods in terms of color protection, contrast enhancement, and image detail enhancement. The proposed method significantly improves the indicators proposed in the article. © 2013 IEEE.",deep learning; GAN; image enhancement; Underwater image enhancement,Color; Deep neural networks; Image enhancement; Underwater imaging; Colour image; Convolutional neural network; Deep learning; Image color analysis; Image enhancement algorithm; Low qualities; Low-light images; Neural-networks; Quality image; Underwater image enhancements; Generative adversarial networks,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85127490368
"Lu Z., Zhao J., Sun Y., Xu F., Ma X.",16643517200;57551986100;57549646800;14919969100;57551986200;,A Multi-Feature Fusion Network for Pathological Identification of Tumor Cells,2022,IEEE Access,10,,,31145,31154,,,10.1109/ACCESS.2022.3160290,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127057431&doi=10.1109%2fACCESS.2022.3160290&partnerID=40&md5=35d3c3b4160a8390ee5ab934f23a2e5d,"College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; State Grid Heilongjiang Provincial Electric Power Company Ltd., Heilongjiang, Daqing, 163458, China","Lu, Z., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Zhao, J., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Sun, Y., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Xu, F., College of Electrical and Mechanical Engineering, Qiqihar University, Qiqihar, 161000, China; Ma, X., State Grid Heilongjiang Provincial Electric Power Company Ltd., Heilongjiang, Daqing, 163458, China","A novel multi-feature fusion neural network (MFNet) is proposed to address the lack of applicability of existing medical aid diagnostic methods for cross-site and cross-tissue cytopathic lesion screening. MFNet consists of a data-sharing layer, a detailed feature transfer branch, a microscopic identification branch, and an auxiliary loss function. The data-sharing layer converts data images into a feature matrix and extracts detailed elements such as cell morphology, contour, and texture. The microscopic recognition branch obtains multilevel elements by convolving the input elements in stages and fusing them, so that the network can focus on high-level semantic elements such as minor differences of cytopathy. The detail feature transfer branch transfers detail elements across layers and achieves cross-layer fusion with semantic elements. The auxiliary loss function enables the network feature classification capability to be enhanced. MFNet is experimentally compared with AlexNet, VGG-16, ResNet-50, and other models on the tumor cell datasets, and the results show that the proposed method can effectively improve the recognition accuracy. © 2013 IEEE.",convolutional neural network; multi-feature fusion; pathology recognition; Tumour cells,Cells; Convolution; Cytology; Data mining; Diagnosis; Neural networks; Tumors; Convolutional neural network; Data Sharing; Feature transfers; Features extraction; License; Loss functions; Multi-feature fusion; Neural-networks; Pathology recognition; Tumour cells; Semantics,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85127057431
"Iqbal T., Shaukat A., Akram M.U., Muzaffar A.W., Mustansar Z., Byun Y.-C.",57221870946;36634907200;24474159700;56809060000;25422450100;8897891700;,A Hybrid VDV Model for Automatic Diagnosis of Pneumothorax Using Class-Imbalanced Chest X-Rays Dataset,2022,IEEE Access,10,,,27670,27683,,1,10.1109/ACCESS.2022.3157316,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126313004&doi=10.1109%2fACCESS.2022.3157316&partnerID=40&md5=83381031e5f2fe33ce8ae79926fa3b2c,"Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; College of Computing and Informatics, Saudi Electronic University, Riyadh, 11673, Saudi Arabia; Research Centre for Modelling and Simulation (RCMS), National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Department of Computer Engineering, Jeju National University, Jeju, 690756, South Korea","Iqbal, T., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Shaukat, A., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Akram, M.U., Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Muzaffar, A.W., College of Computing and Informatics, Saudi Electronic University, Riyadh, 11673, Saudi Arabia; Mustansar, Z., Research Centre for Modelling and Simulation (RCMS), National University of Sciences and Technology (NUST), Islamabad, 44000, Pakistan; Byun, Y.-C., Department of Computer Engineering, Jeju National University, Jeju, 690756, South Korea","Pneumothorax, a life-threatening disease, needs to be diagnosed immediately and efficiently. The prognosis, in this case, is not only time-consuming but also prone to human errors. So, an automatic way of accurate diagnosis using chest X-rays is the utmost requirement. To date, most of the available medical image datasets have a class-imbalance (CI) issue. The main theme of this study is to solve this problem along with proposing an automated way of detecting pneumothorax. To find the optimal approach for CI problem, we first compare the existing approaches and find that under-bagging method (referred as data-level-ensemble formed by creating subsets of majority class and then combining each subset with all samples of minority class) outperforms other existing approaches. After selection of best approach for CI problem, we propose a novel framework, named as VDV model, for pneumothorax detection from highly imbalance dataset. The proposed VDV model is a complex model-level ensemble of data-level-ensembles and uses three convolutional neural networks (CNN) including VGG16, VGG-19, and DenseNet-121 as fixed feature extractors. In each data-level-ensemble, features extracted from one of the pre-defined CNN architectures are fed to support vector machine (SVM) classifier, and output is calculated using the voting method. Once outputs from the three data-level-ensembles (corresponding to three different CNN architectures as feature extractor) are obtained, then, again, the voting method is used to calculate the final prediction. Our proposed framework is tested on the SIIM ACR Pneumothorax dataset and Random Sample of NIH Chest X-ray dataset (RS-NIH). For the first dataset, 85.17% Recall with 86.0% Area under the Receiver Operating Characteristic curve (AUC) is attained. For the second dataset, 90.9% Recall with 95.0% AUC is achieved with a random split of data while 85.45% recall with 77.06% AUC is obtained with a patient-wise split of data. The comparison of our results for both the datasets with related work proves the effectiveness of proposed VDV model for pneumothorax detection. © 2013 IEEE.",chest X-rays; Class-imbalance; classification; deep learning; ensemble; machine learning; pneumothorax; under-bagging,Classification (of information); Convolution; Deep learning; Diagnosis; Medical imaging; Network architecture; Neural networks; Problem solving; Biomedical imaging; Chest X-ray; Class imbalance; Convolutional neural network; Deep learning; Ensemble; Features extraction; Machine-learning; Pneumothorax; Support vectors machine; Under-bagging; X-ray imaging; Support vector machines,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85126313004
"Mehmood S., Ghazal T.M., Khan M.A., Zubair M., Naseem M.T., Faiz T., Ahmad M.",57226140474;57224545303;57215096761;57215854699;54956353900;57217314048;57226132376;,Malignancy Detection in Lung and Colon Histopathology Images Using Transfer Learning with Class Selective Image Processing,2022,IEEE Access,10,,,25657,25668,,30,10.1109/ACCESS.2022.3150924,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124745643&doi=10.1109%2fACCESS.2022.3150924&partnerID=40&md5=059e4feb0ac3111cba8dc4edbf07eaec,"Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Selangor, Bangi, Malaysia; School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Pattern Recognition and Machine Learning Laboratory, Department of Software, Gachon University, Seongnam-si, 13557, South Korea; Faculty of Computing, Riphah International University, Islamabad, Pakistan; Human Ecology Research Center, Yeungnam University, Gyeongsan-si, 712-749, South Korea; School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan","Mehmood, S., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Ghazal, T.M., Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Selangor, Bangi, Malaysia, School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Khan, M.A., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan, Pattern Recognition and Machine Learning Laboratory, Department of Software, Gachon University, Seongnam-si, 13557, South Korea; Zubair, M., Faculty of Computing, Riphah International University, Islamabad, Pakistan; Naseem, M.T., Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan, Human Ecology Research Center, Yeungnam University, Gyeongsan-si, 712-749, South Korea; Faiz, T., School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; Ahmad, M., School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan","Cancer accounts for a huge mortality rate due to its aggressiveness, colossal potential of metastasis, and heterogeneity (causing resistance against chemotherapy). Lung and colon cancers are among the most prevalent types of cancer around the globe that can occur in both males and females. Early and accurate diagnosis of these cancers can substantially improve the quality of treatment as well as the survival rate of cancer patients. We propose a highly accurate and computationally efficient model for the swift and accurate diagnosis of lung and colon cancers as an alternative to current cancer detection methods. In this study, a large dataset of lung and colon histopathology images was employed for training and the validation process. The dataset is comprised of 25000 histopathology images of lung and colon tissues equally divided into 5 classes. A pretrained neural network (AlexNet) was tuned by modifying the four of its layers before training it on the dataset. Initial classification results were promising for all classes of images except for one class with an overall accuracy of 89%. To improve the overall accuracy and keep the model computationally efficient, instead of implementing image enhancement techniques on the entire dataset, the quality of images of the underperforming class was improved by applying a contrast enhancement technique which is fairly simple and efficient. The implementation of the proposed methodology has not only improved the overall accuracy from 89% to 98.4% but has also proved computationally efficient. © 2013 IEEE.",Colon cancer; convolutional neural networks; histopathology; image processing; lung cancer; transfer learning,Biological organs; Chemotherapy; Computational efficiency; Computerized tomography; Convolution; Diagnosis; Diseases; Image enhancement; Neural networks; Colon; Colon cancer; Convolutional neural network; Features extraction; Histopathology; Images processing; Lung Cancer; Transfer learning; Feature extraction,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124745643
"Khan M.Z., Gajendran M.K., Lee Y., Khan M.A.",57224310759;57224319816;57293981900;57202773102;,Deep Neural Architectures for Medical Image Semantic Segmentation: Review,2021,IEEE Access,9,,9447006,83002,83024,,30,10.1109/ACCESS.2021.3086530,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107324395&doi=10.1109%2fACCESS.2021.3086530&partnerID=40&md5=fb42cf670da714db9b4e293d888dc568,"School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Department of Computer Science, Quaid-i-Azam University, Islamabad, 44000, Pakistan","Khan, M.Z., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Gajendran, M.K., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Lee, Y., School of Computing and Engineering, University of Missouri - Kansas City, Kansas City, MO  64110, United States; Khan, M.A., Department of Computer Science, Quaid-i-Azam University, Islamabad, 44000, Pakistan","Deep learning has an enormous impact on medical image analysis. Many computer-aided diagnostic systems equipped with deep networks are rapidly reducing human intervention in healthcare. Among several applications, medical image semantic segmentation is one of the core areas of active research to delineate the anatomical structures and other regions of interest. It has a significant contribution to healthcare and provides guided interventions, radiotherapy, and improved radiological diagnostics. The underlying article provides a brief overview of deep convolutional neural architecture, the platforms and applications of deep neural networks, metrics used for empirical evaluation, state-of-the-art semantic segmentation architectures based on a foundational convolution concept, and a review of publicly available medical image datasets highlighting four distinct regions of interest. The article also analyzes the existing work and provides open-ended potential research directions in deep medical image semantic segmentation. © 2013 IEEE.",computer-aided diagnostics; convolution neural network; Deep learning; encoder-decoder; healthcare; medical image analysis; semantic segmentation; skip-connections,Convolution; Deep learning; Deep neural networks; Diagnosis; Health care; Image analysis; Image segmentation; Medical computing; Network architecture; Semantics; Anatomical structures; Computer aided diagnostics; Empirical evaluations; Human intervention; Neural architectures; Potential researches; Regions of interest; Semantic segmentation; Medical image processing,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85107324395
"Guo W., Zhou H., Gong Z., Zhang G.",57087666000;16834001800;56421223000;56906335400;,Double U-Nets for Image Segmentation by Integrating the Region and Boundary Information,2021,IEEE Access,9,,9416935,69382,69390,,4,10.1109/ACCESS.2021.3075294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105071675&doi=10.1109%2fACCESS.2021.3075294&partnerID=40&md5=7063b44cbd923860ad39af88740192c0,"School of Computer, Shenyang Aerospace University, Shenyang, China; Department of Information Science, Liaoning University, Shenyang, China","Guo, W., School of Computer, Shenyang Aerospace University, Shenyang, China; Zhou, H., Department of Information Science, Liaoning University, Shenyang, China; Gong, Z., School of Computer, Shenyang Aerospace University, Shenyang, China; Zhang, G., School of Computer, Shenyang Aerospace University, Shenyang, China","The existing CNN-based segmentation methods use the object regions alone as the labels to train their networks, and the potentially useful boundaries annotated by radiologists are not used directly during the training. Thus, we proposed a framework of double U-Nets to integrate object regions and boundaries for more accurate segmentation. The proposed network consisted of a down-sampling path followed by two symmetric up-sampling paths. The down-sampling path learned the low-level features of regions and boundaries, and two up-sampling paths learned the high-level features of regions and boundaries, respectively. The outputs from the down-sampling path were concatenated with the corresponding ones from two up-sampling paths by skip connections. The outputs of double U-Nets were the predicted probability images of object regions and boundaries, and they were integrated to calculate the dice loss with the corresponding labels. The proposed double U-Nets were evaluated on two datasets: 247 radiographs for the segmentation of lungs, hearts, and clavicles, and 284 radiographs for the segmentation of pelvises. Compared with the baseline U-Net, our double U-Nets improved the mean dices and reduced the 90% Hausdorff distances for the 'difficult' objects (lower lungs, clavicles, and pelvises), and the integration of 'difficult' object regions and boundaries can improve the segmentation results compared with the use of object regions alone. However, for the 'easy' objects (entire lungs and hearts) or 'very difficult' objects (pelvises in lateral and implanted images), the integration did not improve the segmentation performance. © 2013 IEEE.",double U-Nets; Image segmentation; integrate regions and boundaries,Image enhancement; Radiography; Signal sampling; Boundary information; Hausdorff distance; High-level features; Low-level features; Probability image; Segmentation methods; Segmentation performance; Segmentation results; Image segmentation,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85105071675
