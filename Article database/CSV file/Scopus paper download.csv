,,,,,,scopus papers,,,,,,,,,,,,,,,
Authors,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
"Liu S., Yao W.",Prediction of lung cancer using gene expression and deep learning with KL divergence gene selection,2022,BMC Bioinformatics,23,1,175,,,,10.1186/s12859-022-04689-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130053389&doi=10.1186%2fs12859-022-04689-9&partnerID=40&md5=e166b30cbf4a24e708fc92f4f6db7854,"College of Public Health, Zhengzhou University, Zhengzhou, 450001, China","Liu, S., College of Public Health, Zhengzhou University, Zhengzhou, 450001, China; Yao, W., College of Public Health, Zhengzhou University, Zhengzhou, 450001, China","Background: Lung cancer is one of the cancers with the highest mortality rate in China. With the rapid development of high-throughput sequencing technology and the research and application of deep learning methods in recent years, deep neural networks based on gene expression have become a hot research direction in lung cancer diagnosis in recent years, which provide an effective way of early diagnosis for lung cancer. Thus, building a deep neural network model is of great significance for the early diagnosis of lung cancer. However, the main challenges in mining gene expression datasets are the curse of dimensionality and imbalanced data. The existing methods proposed by some researchers can’t address the problems of high-dimensionality and imbalanced data, because of the overwhelming number of variables measured (genes) versus the small number of samples, which result in poor performance in early diagnosis for lung cancer. Method: Given the disadvantages of gene expression data sets with small datasets, high-dimensionality and imbalanced data, this paper proposes a gene selection method based on KL divergence, which selects some genes with higher KL divergence as model features. Then build a deep neural network model using Focal Loss as loss function, at the same time, we use k-fold cross validation method to verify and select the best model, we set the value of k is five in this paper. Result: The deep learning model method based on KL divergence gene selection proposed in this paper has an AUC of 0.99 on the validation set. The generalization performance of model is high. Conclusion: The deep neural network model based on KL divergence gene selection proposed in this paper is proved to be an accurate and effective method for lung cancer prediction. © 2022, The Author(s).",Deep learning; Focal loss; Gene selection; Imbalanced data; KL divergence; Lung cancer prediction,"Biological organs; Diagnosis; Diseases; Forecasting; Gene expression; Cancer prediction; Deep learning; Early diagnosis; Focal loss; Gene selection; Imbalanced data; KL-divergence; Lung Cancer; Lung cancer prediction; Neural network model; Deep neural networks; China; gene expression; genetics; human; lung tumor; China; Deep Learning; Gene Expression; Humans; Lung Neoplasms; Neural Networks, Computer",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85130053389
"Li Z., Huang K., Liu L., Zhang Z.",Early detection of COPD based on graph convolutional network and small and weakly labeled data,2022,Medical and Biological Engineering and Computing,60,8,,2321,2333,,10.1007/s11517-022-02589-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132794736&doi=10.1007%2fs11517-022-02589-x&partnerID=40&md5=f3a9b9a596fae170ae035625ef8a8c7f,"Department of Pulmonary and Critical Care Medicine, Beijing Chao-Yang Hospital, Capital Medical University, Beijing, 100020, China; Beijing Institute of Respiratory Medicine, Beijing, 100020, China; Department of Respiratory, Shijingshan Teaching Hospital of Capital Medical University, Beijing Shijingshan Hospital, Beijing, 100043, China; Department of Enterprise Management, China Energy Engineering Corporation Limited, Beijing, 100022, China","Li, Z., Department of Pulmonary and Critical Care Medicine, Beijing Chao-Yang Hospital, Capital Medical University, Beijing, 100020, China, Beijing Institute of Respiratory Medicine, Beijing, 100020, China, Department of Respiratory, Shijingshan Teaching Hospital of Capital Medical University, Beijing Shijingshan Hospital, Beijing, 100043, China; Huang, K., Department of Pulmonary and Critical Care Medicine, Beijing Chao-Yang Hospital, Capital Medical University, Beijing, 100020, China, Beijing Institute of Respiratory Medicine, Beijing, 100020, China; Liu, L., Department of Enterprise Management, China Energy Engineering Corporation Limited, Beijing, 100022, China; Zhang, Z., Department of Respiratory, Shijingshan Teaching Hospital of Capital Medical University, Beijing Shijingshan Hospital, Beijing, 100043, China","Chronic obstructive pulmonary disease (COPD) is a common disease with high morbidity and mortality, where early detection benefits the population. However, the early diagnosis rate of COPD is low due to the absence or slight early symptoms. In this paper, a novel method based on graph convolution network (GCN) for early detection of COPD is proposed, which uses small and weakly labeled chest computed tomography image data from the publicly available Danish Lung Cancer Screening Trial database. The key idea is to construct a graph using regions of interest randomly selected from the segmented lung parenchyma and then input it into the GCN model for COPD detection. In this way, the model can not only extract the feature information of each region of interest but also the topological structure information between regions of interest, that is, graph structure information. The proposed GCN model achieves an acceptable performance with an accuracy of 0.77 and an area under a curve of 0.81, which is higher than the previous studies on the same dataset. GCN model also outperforms several state-of-the-art methods trained at the same time. As far as we know, it is also the first time using the GCN model on this dataset for COPD detection. Graphical abstract: [Figure not available: see fulltext.]. © 2022, International Federation for Medical and Biological Engineering.",Chronic obstructive pulmonary disease; Deep learning; Early detection; Graph convolution network,Biological organs; Computerized tomography; Deep learning; Diagnosis; Graphic methods; Image segmentation; Pulmonary diseases; Topology; Chronic obstructive pulmonary disease; Convolutional networks; Deep learning; Disease detection; Early detection; Graph convolution network; Network models; Region-of-interest; Regions of interest; Structure information; Convolution,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85132794736
"Astaraki M., Smedby Ö., Wang C.",Prior-aware autoencoders for lung pathology segmentation,2022,Medical Image Analysis,80,,102491,,,,10.1016/j.media.2022.102491,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131059087&doi=10.1016%2fj.media.2022.102491&partnerID=40&md5=72368d4081795ff05768930d2e42d651,"Department of Biomedical Engineering and Healthy Systems, KTH Royal Institute of Technology, Huddinge, SE-14157, Sweden; Department of Oncology-Pathology, Karolinska Institutet, Karolinska Universitetssjukhuset, Stockholm, Solna, SE-17176, Sweden","Astaraki, M., Department of Biomedical Engineering and Healthy Systems, KTH Royal Institute of Technology, Huddinge, SE-14157, Sweden, Department of Oncology-Pathology, Karolinska Institutet, Karolinska Universitetssjukhuset, Stockholm, Solna, SE-17176, Sweden; Smedby, Ö., Department of Biomedical Engineering and Healthy Systems, KTH Royal Institute of Technology, Huddinge, SE-14157, Sweden; Wang, C., Department of Biomedical Engineering and Healthy Systems, KTH Royal Institute of Technology, Huddinge, SE-14157, Sweden","Segmentation of lung pathology in Computed Tomography (CT) images is of great importance for lung disease screening. However, the presence of different types of lung pathologies with a wide range of heterogeneities in size, shape, location, and texture, on one side, and their visual similarity with respect to surrounding tissues, on the other side, make it challenging to perform reliable automatic lesion segmentation. To leverage segmentation performance, we propose a deep learning framework comprising a Normal Appearance Autoencoder (NAA) model to learn the distribution of healthy lung regions and reconstruct pathology-free images from the corresponding pathological inputs by replacing the pathological regions with the characteristics of healthy tissues. Detected regions that represent prior information regarding the shape and location of pathologies are then integrated into a segmentation network to guide the attention of the model into more meaningful delineations. The proposed pipeline was tested on three types of lung pathologies, including pulmonary nodules, Non-Small Cell Lung Cancer (NSCLC), and Covid-19 lesion on five comprehensive datasets. The results show the superiority of the proposed prior model, which outperformed the baseline segmentation models in all the cases with significant margins. On average, adding the prior model improved the Dice coefficient for the segmentation of lung nodules by 0.038, NSCLCs by 0.101, and Covid-19 lesions by 0.041. We conclude that the proposed NAA model produces reliable prior knowledge regarding the lung pathologies, and integrating such knowledge into a prior segmentation network leads to more accurate delineations. © 2022 The Author(s)",Healthy image generation; Lung pathology segmentation; Prior-aware deep learning,Biological organs; Computerized tomography; Deep learning; Diagnosis; Histology; Image segmentation; Textures; Tissue; Auto encoders; Computed tomography images; Disease screening; Healthy image generation; Image generations; Lung pathology; Lung pathology segmentation; Prior modeling; Prior-aware deep learning; Visual similarity; Pathology; Article; autoencoder; computer assisted tomography; controlled study; coronavirus disease 2019; histopathology; human; image segmentation; lung disease; lung nodule; non small cell lung cancer; pilot study,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85131059087
"Fathalla K.M., Youssef S.M., Mohammed N.",DETECT-LC: A 3D Deep Learning and Textural Radiomics Computational Model for Lung Cancer Staging and Tumor Phenotyping Based on Computed Tomography Volumes,2022,Applied Sciences (Switzerland),12,13,6318,,,,10.3390/app12136318,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132992175&doi=10.3390%2fapp12136318&partnerID=40&md5=c44828ec7f99d402c0c5f9a6e64de788,"Computer Engineering Department, Arab Academy for Science and Technology, Abu Qir, Alexandria, 1029, Egypt","Fathalla, K.M., Computer Engineering Department, Arab Academy for Science and Technology, Abu Qir, Alexandria, 1029, Egypt; Youssef, S.M., Computer Engineering Department, Arab Academy for Science and Technology, Abu Qir, Alexandria, 1029, Egypt; Mohammed, N., Computer Engineering Department, Arab Academy for Science and Technology, Abu Qir, Alexandria, 1029, Egypt","Lung Cancer is one of the primary causes of cancer-related deaths worldwide. Timely diagnosis and precise staging are pivotal for treatment planning, and thus can lead to increased survival rates. The application of advanced machine learning techniques helps in effective diagnosis and staging. In this study, a multistage neurobased computational model is proposed, DETECT-LC learning. DETECT-LC handles the challenge of choosing discriminative CT slices for constructing 3D volumes, using Haralick, histogram-based radiomics, and unsupervised clustering. ALT-CNN-DENSE Net architecture is introduced as part of DETECT-LC for voxel-based classification. DETECT-LC offers an automatic threshold-based segmentation approach instead of the manual procedure, to help mitigate this burden for radiologists and clinicians. Also, DETECT-LC presents a slice selection approach and a newly proposed relatively light weight 3D CNN architecture to improve existing studies performance. The proposed pipeline is employed for tumor phenotyping and staging. DETECT-LC performance is assessed through a range of experiments, in which DETECT-LC attains outstanding performance surpassing its counterparts in terms of accuracy, sensitivity, F1-score and Area under Curve (AuC). For histopathology classification, DETECT-LC average performance achieved an improvement of 20% in overall accuracy, 0.19 in sensitivity, 0.16 in F1-Score and 0.16 in AuC over the state of the art. A similar enhancement is reached for staging, where higher overall accuracy, sensitivity and F1-score are attained with differences of 8%, 0.08 and 0.14. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",3D-CNN; computed tomography; deep learning; radiomics; staging; tumor phenotyping,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85132992175
"Vaiyapuri T., Liyakathunisa, Alaskar H., Parvathi R., Pattabiraman V., Hussain A.",Cat Swarm Optimization-Based Computer-Aided Diagnosis Model for Lung Cancer Classification in Computed Tomography Images,2022,Applied Sciences (Switzerland),12,11,5491,,,,10.3390/app12115491,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131563897&doi=10.3390%2fapp12115491&partnerID=40&md5=70d7de8eb5226b0cc7ed9b7b5bf92e9a,"Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al Kharj, 16278, Saudi Arabia; Department of Computer Science, College of Computer Science and Engineering, Taibah University, Madinah, 42353, Saudi Arabia; School of Computing Science and Engineering, Vellore Institute of Technology, Chennai, 600127, India; Department of Electrical Engineering, University of Sharjah, P.O. Box 27272, Sharjah, United Arab Emirates; Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom","Vaiyapuri, T., Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al Kharj, 16278, Saudi Arabia; Liyakathunisa, Department of Computer Science, College of Computer Science and Engineering, Taibah University, Madinah, 42353, Saudi Arabia; Alaskar, H., Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al Kharj, 16278, Saudi Arabia; Parvathi, R., School of Computing Science and Engineering, Vellore Institute of Technology, Chennai, 600127, India; Pattabiraman, V., School of Computing Science and Engineering, Vellore Institute of Technology, Chennai, 600127, India; Hussain, A., Department of Electrical Engineering, University of Sharjah, P.O. Box 27272, Sharjah, United Arab Emirates, Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom","Lung cancer is the most significant cancer that heavily contributes to cancer-related mortality rate, due to its violent nature and late diagnosis at advanced stages. Early identification of lung cancer is essential for improving the survival rate. Various imaging modalities, including X-rays and computed tomography (CT) scans, are employed to diagnose lung cancer. Computer-aided diagnosis (CAD) models are necessary for minimizing the burden upon radiologists and enhancing detection efficiency. Currently, computer vision (CV) and deep learning (DL) models are employed to detect and classify the lung cancer in a precise manner. In this background, the current study presents a cat swarm optimization-based computer-aided diagnosis model for lung cancer classification (CSO-CADLCC) model. The proposed CHO-CADLCC technique initially pre-process the data using the Gabor filtering-based noise removal technique. Furthermore, feature extraction of the pre-processed images is performed with the help of NASNetLarge model. This model is followed by the CSO algorithm with weighted extreme learning machine (WELM) model, which is exploited for lung nodule classification. Finally, the CSO algorithm is utilized for optimal parameter tuning of the WELM model, resulting in an improved classification performance. The experimental validation of the proposed CSO-CADLCC technique was conducted against a benchmark dataset, and the results were assessed under several aspects. The experimental outcomes established the promising performance of the CSO-CADLCC approach over recent approaches under different measures. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",cat swarm optimization; computer vision; computer-aided diagnosis; deep learning; healthcare; intelligent models,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85131563897
"Malik H., Anees T., Mui-zzud-din","BDCNet: multi-classification convolutional neural network model for classification of COVID-19, pneumonia, and lung cancer from chest radiographs",2022,Multimedia Systems,28,3,,815,829,1,10.1007/s00530-021-00878-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123105919&doi=10.1007%2fs00530-021-00878-3&partnerID=40&md5=4114b3b06b1a171065e53ca9af73892f,"Department of Computer Science, University of Management and Technology, Lahore, 54000, Pakistan; Department of Computer Science, National College of Business Administration & Economics Sub Campus Multan, Multan, 60000, Pakistan; Department of Software Engineering, University of Management and Technology, Lahore, 54000, Pakistan; Department of Computer Science, Khawaja Fareed University of Engineering & Information Technology, 64200, Rahim Yar Khan, Pakistan","Malik, H., Department of Computer Science, University of Management and Technology, Lahore, 54000, Pakistan, Department of Computer Science, National College of Business Administration & Economics Sub Campus Multan, Multan, 60000, Pakistan; Anees, T., Department of Software Engineering, University of Management and Technology, Lahore, 54000, Pakistan; Mui-zzud-din, Department of Computer Science, Khawaja Fareed University of Engineering & Information Technology, 64200, Rahim Yar Khan, Pakistan","Globally, coronavirus disease (COVID-19) has badly affected the medical system and economy. Sometimes, the deadly COVID-19 has the same symptoms as other chest diseases such as pneumonia and lungs cancer and can mislead the doctors in diagnosing coronavirus. Frontline doctors and researchers are working assiduously in finding the rapid and automatic process for the detection of COVID-19 at the initial stage, to save human lives. However, the clinical diagnosis of COVID-19 is highly subjective and variable. The objective of this study is to implement a multi-classification algorithm based on deep learning (DL) model for identifying the COVID-19, pneumonia, and lung cancer diseases from chest radiographs. In the present study, we have proposed a model with the combination of Vgg-19 and convolutional neural networks (CNN) named BDCNet and applied it on different publically available benchmark databases to diagnose the COVID-19 and other chest tract diseases. To the best of our knowledge, this is the first study to diagnose the three chest diseases in a single deep learning model. We also computed and compared the classification accuracy of our proposed model with four well-known pre-trained models such as ResNet-50, Vgg-16, Vgg-19, and inception v3. Our proposed model achieved an AUC of 0.9833 (with an accuracy of 99.10%, a recall of 98.31%, a precision of 99.9%, and an f1-score of 99.09%) in classifying the different chest diseases. Moreover, CNN-based pre-trained models VGG-16, VGG-19, ResNet-50, and Inception-v3 achieved an accuracy of classifying multi-diseases are 97.35%, 97.14%, 97.15%, and 95.10%, respectively. The results revealed that our proposed model produced a remarkable performance as compared to its competitor approaches, thus providing significant assistance to diagnostic radiographers and health experts. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Chest radiographs; Coronavirus; COVID-19; Deep learning,Biological organs; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Radiography; Chest radiographs; Convolutional neural network; Coronaviruses; COVID-19; Deep learning; Learning models; Lung Cancer; Medical systems; Multi-classification; Neural network model; Coronavirus,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85123105919
"Sousa J., Pereira T., Neves I., Silva F., Oliveira H.P.",The Influence of a Coherent Annotation and Synthetic Addition of Lung Nodules for Lung Segmentation in CT Scans,2022,Sensors,22,9,3443,,,,10.3390/s22093443,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129209996&doi=10.3390%2fs22093443&partnerID=40&md5=3f93ad1df484c2455afe34d791f9b54e,"INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal; FEUP—Faculty of Engineering, University of Porto, Porto, 4200-465, Portugal; ICBAS—Abel Salazar Biomedical Sciences Institute, University of Porto, Porto, 4050-313, Portugal; FCUP—Faculty of Science, University of Porto, Porto, 4169-007, Portugal","Sousa, J., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FEUP—Faculty of Engineering, University of Porto, Porto, 4200-465, Portugal; Pereira, T., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal; Neves, I., ICBAS—Abel Salazar Biomedical Sciences Institute, University of Porto, Porto, 4050-313, Portugal; Silva, F., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FCUP—Faculty of Science, University of Porto, Porto, 4169-007, Portugal; Oliveira, H.P., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FCUP—Faculty of Science, University of Porto, Porto, 4169-007, Portugal","Lung cancer is a highly prevalent pathology and a leading cause of cancer-related deaths. Most patients are diagnosed when the disease has manifested itself, which usually is a sign of lung cancer in an advanced stage and, as a consequence, the 5-year survival rates are low. To increase the chances of survival, improving the cancer early detection capacity is crucial, for which computed tomography (CT) scans represent a key role. The manual evaluation of the CTs is a time-consuming task and computer-aided diagnosis (CAD) systems can help relieve that burden. The segmentation of the lung is one of the first steps in these systems, yet it is very challenging given the heterogeneity of lung diseases usually present and associated with cancer development. In our previous work, a segmentation model based on a ResNet34 and U-Net combination was developed on a cross-cohort dataset that yielded good segmentation masks for multiple pathological conditions but misclassified some of the lung nodules. The multiple datasets used for the model development were originated from different annotation protocols, which generated inconsistencies for the learning process, and the annotations are usually not adequate for lung cancer studies since they did not comprise lung nodules. In addition, the initial datasets used for training presented a reduced number of nodules, which was showed not to be enough to allow the segmentation model to learn to include them as a lung part. In this work, an objective protocol for the lung mask’s segmentation was defined and the previous annotations were carefully reviewed and corrected to create consistent and adequate ground-truth masks for the development of the segmentation model. Data augmentation with domain knowledge was used to create lung nodules in the cases used to train the model. The model developed achieved a Dice similarity coefficient (DSC) above 0.9350 for all test datasets and it showed an ability to cope, not only with a variety of lung patterns, but also with the presence of lung nodules as well. This study shows the importance of using consistent annotations for the supervised learning process, which is a very time-consuming task, but that has great importance to healthcare applications. Due to the lack of massive datasets in the medical field, which consequently brings a lack of wide representativity, data augmentation with domain knowledge could represent a promising help to overcome this limitation for learning models development. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",annotation homogeneity; data augmentation; deep learning; lung diseases; lung segmentation,"Computer aided diagnosis; Computerized tomography; Deep learning; Diseases; Domain Knowledge; Annotation homogeneity; Computed tomography scan; Data augmentation; Deep learning; Lung Cancer; Lung nodule; Lung segmentation; Model development; Segmentation models; Time-consuming tasks; Biological organs; computer assisted diagnosis; diagnostic imaging; human; image processing; lung; lung tumor; thorax; x-ray computed tomography; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Lung; Lung Neoplasms; Thorax; Tomography, X-Ray Computed",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85129209996
"Mehrotra R., Agrawal R., Ansari M.A.",Diagnosis of hypercritical chronic pulmonary disorders using dense convolutional network through chest radiography,2022,Multimedia Tools and Applications,81,6,,7625,7649,,10.1007/s11042-021-11748-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123849496&doi=10.1007%2fs11042-021-11748-5&partnerID=40&md5=a5c3fd5cb0e5cfc234083b825830e829,"Department of Electrical & Electronics Engineering, GL Bajaj Institute of Technology & Management, Gr. Noida, India; Department of Electronics & Communication Engineering, GL Bajaj Institute of Technology & Management, Gr. Noida, India; Department of Electrical Engineering, School of Engineering, Gautam Buddha University, Gr. Noida, India","Mehrotra, R., Department of Electrical & Electronics Engineering, GL Bajaj Institute of Technology & Management, Gr. Noida, India; Agrawal, R., Department of Electronics & Communication Engineering, GL Bajaj Institute of Technology & Management, Gr. Noida, India; Ansari, M.A., Department of Electrical Engineering, School of Engineering, Gautam Buddha University, Gr. Noida, India","Lung-related ailments are prevalent all over the world which majorly includes asthma, chronic obstructive pulmonary disease (COPD), tuberculosis, pneumonia, fibrosis, etc. and now COVID-19 is added to this list. Infection of COVID-19 poses respirational complications with other indications like cough, high fever, and pneumonia. WHO had identified cancer in the lungs as a fatal cancer type amongst others and thus, the timely detection of such cancer is pivotal for an individual’s health. Since the elementary convolutional neural networks have not performed fairly well in identifying atypical image types hence, we recommend a novel and completely automated framework with a deep learning approach for the recognition and classification of chronic pulmonary disorders (CPD) and COVID-pneumonia using Thoracic or Chest X-Ray (CXR) images. A novel three-step, completely automated, approach is presented that first extracts the region of interest from CXR images for preprocessing, and they are then used to detects infected lungs X-rays from the Normal ones. Thereafter, the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD), which might be utilized in the current scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases. And finally, highlight the regions in the CXR which are indicative of severe chronic pulmonary disorders like COVID-19 and pneumonia. A detailed investigation of various pivotal parameters based on several experimental outcomes are made here. This paper presents an approach that detects the Normal lung X-rays from infected ones and the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders with an utmost accuracy of 96.8%. Several other collective performance measurements validate the superiority of the presented model. The proposed framework shows effective results in classifying lung images into Normal, COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD). This framework can be effectively utilized in this current pandemic scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Chest x-ray (CXR); Chronic pulmonary disorders; CNN; COVID-19; Deep learning; Pneumonia,Biological organs; Convolutional neural networks; Deep learning; Diagnosis; Image classification; Image segmentation; Pulmonary diseases; X ray radiography; 'current; Chest x-ray; Chest X-ray image; Chest x-rays; Chronic pulmonary disorder; Classifieds; CNN; COVID-19; Deep learning; Pneumonia; Convolution,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85123849496
"Kido S., Kidera S., Hirano Y., Mabu S., Kamiya T., Tanaka N., Suzuki Y., Yanagawa M., Tomiyama N.",Segmentation of Lung Nodules on CT Images Using a Nested Three-Dimensional Fully Connected Convolutional Network,2022,Frontiers in Artificial Intelligence,5,,782225,,,1,10.3389/frai.2022.782225,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125736621&doi=10.3389%2ffrai.2022.782225&partnerID=40&md5=ebd05535bde380c281e9999b012df33a,"Department of Artificial Intelligence Diagnostic Radiology, Osaka University Graduate School of Medicine, Suita, Japan; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Medical Informatics and Decision Sciences, Yamaguchi University Hospital, Ube, Japan; Department of Mechanical and Control Engineering, Faculty of Engineering, Kyushu Institute of Technology, Kitakyushu, Japan; Department of Radiology, National Hospital Organization, Yamaguchi-Ube Medical Center, Ube, Japan; Department of Radiology, Osaka University Graduate School of Medicine, Suita, Japan","Kido, S., Department of Artificial Intelligence Diagnostic Radiology, Osaka University Graduate School of Medicine, Suita, Japan; Kidera, S., Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Hirano, Y., Medical Informatics and Decision Sciences, Yamaguchi University Hospital, Ube, Japan; Mabu, S., Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Kamiya, T., Department of Mechanical and Control Engineering, Faculty of Engineering, Kyushu Institute of Technology, Kitakyushu, Japan; Tanaka, N., Department of Radiology, National Hospital Organization, Yamaguchi-Ube Medical Center, Ube, Japan; Suzuki, Y., Department of Artificial Intelligence Diagnostic Radiology, Osaka University Graduate School of Medicine, Suita, Japan; Yanagawa, M., Department of Radiology, Osaka University Graduate School of Medicine, Suita, Japan; Tomiyama, N., Department of Radiology, Osaka University Graduate School of Medicine, Suita, Japan","In computer-aided diagnosis systems for lung cancer, segmentation of lung nodules is important for analyzing image features of lung nodules on computed tomography (CT) images and distinguishing malignant nodules from benign ones. However, it is difficult to accurately and robustly segment lung nodules attached to the chest wall or with ground-glass opacities using conventional image processing methods. Therefore, this study aimed to develop a method for robust and accurate three-dimensional (3D) segmentation of lung nodule regions using deep learning. In this study, a nested 3D fully connected convolutional network with residual unit structures was proposed, and designed a new loss function. Compared with annotated images obtained under the guidance of a radiologist, the Dice similarity coefficient (DS) and intersection over union (IoU) were 0.845 ± 0.008 and 0.738 ± 0.011, respectively, for 332 lung nodules (lung adenocarcinoma) obtained from 332 patients. On the other hand, for 3D U-Net and 3D SegNet, the DS was 0.822 ± 0.009 and 0.786 ± 0.011, respectively, and the IoU was 0.711 ± 0.011 and 0.660 ± 0.012, respectively. These results indicate that the proposed method is significantly superior to well-known deep learning models. Moreover, we compared the results obtained from the proposed method with those obtained from conventional image processing methods, watersheds, and graph cuts. The DS and IoU results for the watershed method were 0.628 ± 0.027 and 0.494 ± 0.025, respectively, and those for the graph cut method were 0.566 ± 0.025 and 0.414 ± 0.021, respectively. These results indicate that the proposed method is significantly superior to conventional image processing methods. The proposed method may be useful for accurate and robust segmentation of lung nodules to assist radiologists in the diagnosis of lung nodules such as lung adenocarcinoma on CT images. Copyright © 2022 Kido, Kidera, Hirano, Mabu, Kamiya, Tanaka, Suzuki, Yanagawa and Tomiyama.",computer-aided diagnosis; deep learning; graph cut; lung nodule; segmentation; SegNet; U-Net; watershed,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85125736621
"Torres G., Baeza S., Sanchez C., Guasch I., Rosell A., Gil D.",An Intelligent Radiomic Approach for Lung Cancer Screening,2022,Applied Sciences (Switzerland),12,3,1568,,,,10.3390/app12031568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124995049&doi=10.3390%2fapp12031568&partnerID=40&md5=c421529c09cacbc89e3707c7fe1ec299,"Computer Vision Center (CVC) and Computer Science Department, Universitat Autònoma de Barcelona (UAB), Barcelona, 08193, Spain; Respiratory Medicine Department, Hospital Universitari Germans Trias i Pujol, Badalona, 08916, Spain; Germans Trias i Pujol Research Institute (IGTP), Badalona, 08916, Spain; Medicine Deptartment, Universitat Autònoma de Barcelona (UAB), Barcelona, 08035, Spain","Torres, G., Computer Vision Center (CVC) and Computer Science Department, Universitat Autònoma de Barcelona (UAB), Barcelona, 08193, Spain; Baeza, S., Respiratory Medicine Department, Hospital Universitari Germans Trias i Pujol, Badalona, 08916, Spain, Germans Trias i Pujol Research Institute (IGTP), Badalona, 08916, Spain, Medicine Deptartment, Universitat Autònoma de Barcelona (UAB), Barcelona, 08035, Spain; Sanchez, C., Computer Vision Center (CVC) and Computer Science Department, Universitat Autònoma de Barcelona (UAB), Barcelona, 08193, Spain; Guasch, I., Respiratory Medicine Department, Hospital Universitari Germans Trias i Pujol, Badalona, 08916, Spain, Germans Trias i Pujol Research Institute (IGTP), Badalona, 08916, Spain; Rosell, A., Respiratory Medicine Department, Hospital Universitari Germans Trias i Pujol, Badalona, 08916, Spain, Germans Trias i Pujol Research Institute (IGTP), Badalona, 08916, Spain, Medicine Deptartment, Universitat Autònoma de Barcelona (UAB), Barcelona, 08035, Spain; Gil, D., Computer Vision Center (CVC) and Computer Science Department, Universitat Autònoma de Barcelona (UAB), Barcelona, 08193, Spain","The efficiency of lung cancer screening for reducing mortality is hindered by the high rate of false positives. Artificial intelligence applied to radiomics could help to early discard benign cases from the analysis of CT scans. The available amount of data and the fact that benign cases are a minority, constitutes a main challenge for the successful use of state of the art methods (like deep learning), which can be biased, over-fitted and lack of clinical reproducibility. We present an hybrid approach combining the potential of radiomic features to characterize nodules in CT scans and the generalization of the feed forward networks. In order to obtain maximal reproducibility with minimal training data, we propose an embedding of nodules based on the statistical significance of radiomic features for malignancy detection. This representation space of lesions is the input to a feed forward network, which architecture and hyperparameters are optimized using own-defined metrics of the diagnostic power of the whole system. Results of the best model on an independent set of patients achieve 100% of sensitivity and 83% of specificity (AUC = 0.94) for malignancy detection. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Architecture optimization; Early diagnosis; Image embedding; Lung cancer; Neural networks; Screening,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124995049
"Sousa J., Pereira T., Silva F., Silva M.C., Vilares A.T., Cunha A., Oliveira H.P.",Lung Segmentation in CT Images: A Residual U-Net Approach on a Cross-Cohort Dataset,2022,Applied Sciences (Switzerland),12,4,1959,,,3,10.3390/app12041959,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124755898&doi=10.3390%2fapp12041959&partnerID=40&md5=4a5df61ae9f2f908d5e0f27242f633e5,"INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal; FEUP—Faculty of Engineering, University of Porto, Porto, 4200-465, Portugal; FCUP—Faculty of Science, University of Porto, Porto, 4200-465, Portugal; CHUSJ—Centro Hospitalar e Universitário de São João, Porto, 4200-319, Portugal; UTAD—Institute for Systems and Computer Engineering, University of Trás-os-Montes and Alto Douro, Vila Real, 5001-801, Portugal","Sousa, J., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FEUP—Faculty of Engineering, University of Porto, Porto, 4200-465, Portugal; Pereira, T., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal; Silva, F., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FCUP—Faculty of Science, University of Porto, Porto, 4200-465, Portugal; Silva, M.C., CHUSJ—Centro Hospitalar e Universitário de São João, Porto, 4200-319, Portugal; Vilares, A.T., CHUSJ—Centro Hospitalar e Universitário de São João, Porto, 4200-319, Portugal; Cunha, A., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, UTAD—Institute for Systems and Computer Engineering, University of Trás-os-Montes and Alto Douro, Vila Real, 5001-801, Portugal; Oliveira, H.P., INESC TEC—Institute for Systems and Computer Engineering, Technology and Science, Porto, 4200-465, Portugal, FCUP—Faculty of Science, University of Porto, Porto, 4200-465, Portugal","Lung cancer is one of the most common causes of cancer-related mortality, and since the majority of cases are diagnosed when the tumor is in an advanced stage, the 5-year survival rate is dismally low. Nevertheless, the chances of survival can increase if the tumor is identified early on, which can be achieved through screening with computed tomography (CT). The clinical evaluation of CT images is a very time-consuming task and computed-aided diagnosis systems can help reduce this burden. The segmentation of the lungs is usually the first step taken in image analysis automatic models of the thorax. However, this task is very challenging since the lungs present high variability in shape and size. Moreover, the co-occurrence of other respiratory comorbidities alongside lung cancer is frequent, and each pathology can present its own scope of CT imaging appearances. This work investigated the development of a deep learning model, whose architecture consists of the combination of two structures, a U-Net and a ResNet34. The proposed model was designed on a cross-cohort dataset and it achieved a mean dice similarity coefficient (DSC) higher than 0.93 for the 4 different cohorts tested. The segmentation masks were qualitatively evaluated by two experienced radiologists to identify the main limitations of the developed model, despite the good overall performance obtained. The performance per pathology was assessed, and the results confirmed a small degradation for consolidation and pneumocystis pneumonia cases, with a DSC of 0.9015 ± 0.2140 and 0.8750 ± 0.1290, respectively. This work represents a relevant assessment of the lung segmentation model, taking into consideration the pathological cases that can be found in the clinical routine, since a global assessment could not detail the fragilities of the model. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Clinical assessment; Cross-cohort; CT images; Deep learning; Lung segmentation,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124755898
"Gayathri J.L., Abraham B., Sujarani M.S., Nair M.S.",A computer-aided diagnosis system for the classification of COVID-19 and non-COVID-19 pneumonia on chest X-ray images by integrating CNN with sparse autoencoder and feed forward neural network,2022,Computers in Biology and Medicine,141,,105134,,,5,10.1016/j.compbiomed.2021.105134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122037236&doi=10.1016%2fj.compbiomed.2021.105134&partnerID=40&md5=a0acb32e62de566694c09e81b110fdd5,"Department of Computer Science and Engineering, College of Engineering Perumon, Kollam, Kerala  691 601, India; Artificial Intelligence & Computer Vision Lab, Department of Computer Science, Cochin University of Science and Technology, Kochi, Kerala  682 022, India","Gayathri, J.L., Department of Computer Science and Engineering, College of Engineering Perumon, Kollam, Kerala  691 601, India; Abraham, B., Department of Computer Science and Engineering, College of Engineering Perumon, Kollam, Kerala  691 601, India; Sujarani, M.S., Department of Computer Science and Engineering, College of Engineering Perumon, Kollam, Kerala  691 601, India; Nair, M.S., Artificial Intelligence & Computer Vision Lab, Department of Computer Science, Cochin University of Science and Technology, Kochi, Kerala  682 022, India","Several infectious diseases have affected the lives of many people and have caused great dilemmas all over the world. COVID-19 was declared a pandemic caused by a newly discovered virus named Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) by the World Health Organisation in 2019. RT-PCR is considered the golden standard for COVID-19 detection. Due to the limited RT-PCR resources, early diagnosis of the disease has become a challenge. Radiographic images such as Ultrasound, CT scans, X-rays can be used for the detection of the deathly disease. Developing deep learning models using radiographic images for detecting COVID-19 can assist in countering the outbreak of the virus. This paper presents a computer-aided detection model utilizing chest X-ray images for combating the pandemic. Several pre-trained networks and their combinations have been used for developing the model. The method uses features extracted from pre-trained networks along with Sparse autoencoder for dimensionality reduction and a Feed Forward Neural Network (FFNN) for the detection of COVID-19. Two publicly available chest X-ray image datasets, consisting of 504 COVID-19 images and 542 non-COVID-19 images, have been combined to train the model. The method was able to achieve an accuracy of 0.9578 and an AUC of 0.9821, using the combination of InceptionResnetV2 and Xception. Experiments have proved that the accuracy of the model improves with the usage of sparse autoencoder as the dimensionality reduction technique. © 2021 Elsevier Ltd",CNN; Computer-aided detection; COVID-19; Feed forward neural network; Sparse autoencoder,"Computer aided diagnosis; Computerized tomography; Deep learning; Feedforward neural networks; Ultrasonic applications; X ray radiography; Auto encoders; Chest X-ray image; CNN; Computer aided detection; Computer aided diagnosis systems; COVID-19; Feed forward neural net works; Infectious disease; Radiographic images; Sparse autoencoder; Diseases; Alzheimer disease; Article; chronic kidney failure; comparative study; computer assisted diagnosis; controlled study; convolutional neural network; coronavirus disease 2019; correlation coefficient; cross validation; diagnostic accuracy; diagnostic test accuracy study; dimensionality reduction; feature extraction; feed forward neural network; gold standard; human; lung cancer; major clinical study; random forest; real time polymerase chain reaction; sensitivity and specificity; Severe acute respiratory syndrome coronavirus 2; sparse autoencoder; thorax radiography; transfer of learning; algorithm; computer; X ray; Algorithms; Computers; COVID-19; Deep Learning; Humans; Neural Networks, Computer; SARS-CoV-2; X-Rays",Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85122037236
"Al-Shabi M., Shak K., Tan M.",ProCAN: Progressive growing channel attentive non-local network for lung nodule classification,2022,Pattern Recognition,122,,108309,,,,10.1016/j.patcog.2021.108309,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115363958&doi=10.1016%2fj.patcog.2021.108309&partnerID=40&md5=0bc31523d2b2cae60f9f5004eed3c559,"Electrical and Computer Systems Engineering Discipline, School of Engineering, Monash University Malaysia, Bandar, Sunway  47500, Malaysia; School of Electrical and Computer Engineering, The University of Oklahoma, Norman, OK  73019, United States","Al-Shabi, M., Electrical and Computer Systems Engineering Discipline, School of Engineering, Monash University Malaysia, Bandar, Sunway  47500, Malaysia; Shak, K., Electrical and Computer Systems Engineering Discipline, School of Engineering, Monash University Malaysia, Bandar, Sunway  47500, Malaysia; Tan, M., Electrical and Computer Systems Engineering Discipline, School of Engineering, Monash University Malaysia, Bandar, Sunway  47500, Malaysia, School of Electrical and Computer Engineering, The University of Oklahoma, Norman, OK  73019, United States","Lung cancer classification in screening computed tomography (CT) scans is one of the most crucial tasks for early detection of this disease. Many lives can be saved if we are able to accurately classify malignant/cancerous lung nodules. Consequently, several deep learning based models have been proposed recently to classify lung nodules as malignant or benign. Nevertheless, the large variation in the size and heterogeneous appearance of the nodules makes this task an extremely challenging one. We propose a new Progressive Growing Channel Attentive Non-Local (ProCAN) network for lung nodule classification. The proposed method addresses this challenge from three different aspects. First, we enrich the Non-Local network by adding channel-wise attention capability to it. Second, we apply Curriculum Learning principles, whereby we first train our model on easy examples before hard ones. Third, as the classification task gets harder during the Curriculum learning, our model is progressively grown to increase its capability of handling the task at hand. We examined our proposed method on two different public datasets and compared its performance with state-of-the-art methods in the literature. The results show that the ProCAN model outperforms state-of-the-art methods and achieves an AUC of 98.05% and an accuracy of 95.28% on the LIDC-IDRI dataset. Moreover, we conducted extensive ablation studies to analyze the contribution and effects of each new component of our proposed method. © 2021 Elsevier Ltd",Curriculum learning; Deep learning; Nodule classification; Non-local network; Self-Attention,Biological organs; Computerized tomography; Deep learning; Diagnosis; Curriculum learning; Deep learning; Local networks; Lung Cancer; Lung nodule; Nodule classification; Non-local network; Nonlocal; Self-attention; State-of-the-art methods; Curricula,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85115363958
"Ai D., Hu Q., Chao Y.-C., Fu C.-C., Yuan W., Lv L., Ye D., Li C., Ye M., Zhang Y., Hong Q., Hu J., Xu X., Zhang L., Jiang Q., Wang X., Fang Q., Wang B., Hou Y., Zhang X.",Artificial intelligence-based rapid on-site cytopathological evaluation for bronchoscopy examinations,2022,Intelligence-Based Medicine,6,,100069,,,,10.1016/j.ibmed.2022.100069,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133931772&doi=10.1016%2fj.ibmed.2022.100069&partnerID=40&md5=95366f9967ed95a0545b9895d3fa8b81,"Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Shanghai Aitrox Technology Corporation Limited, Shanghai, China","Ai, D., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Hu, Q., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Chao, Y.-C., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Fu, C.-C., Shanghai Aitrox Technology Corporation Limited, Shanghai, China; Yuan, W., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Lv, L., Shanghai Aitrox Technology Corporation Limited, Shanghai, China; Ye, D., Shanghai Aitrox Technology Corporation Limited, Shanghai, China; Li, C., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Ye, M., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Zhang, Y., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Hong, Q., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Hu, J., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Xu, X., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Zhang, L., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China; Jiang, Q., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Wang, X., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Fang, Q., Shanghai Aitrox Technology Corporation Limited, Shanghai, China; Wang, B., Shanghai Aitrox Technology Corporation Limited, Shanghai, China; Hou, Y., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, China; Zhang, X., Department of Respiratory, Zhongshan Hospital, Fudan University, Shanghai, China","Microscopy image analysis gives quantitative support for enhancing the characterizations of various diseases, including breast cancer, lung cancer, and brain tumors. As a result, it is crucial in computer-assisted diagnosis and prognosis. Understanding the biological principles underlying these dynamic image sequences often necessitates precise analysis and statistical quantification, a major discipline issue. Deep learning methods are increasingly used in bioimage processing as they grow rapidly. This research proposes novel biomedical microscopic image analysis techniques using deep learning architectures based on feature extraction and classification. Here, the input image has been taken as microscopic image, and it has been processed and analyzed for noise removal, edge smoothening, and normalization. The processed image has been extracted based on their features in microscopic image analysis using ConVol_NN architecture with AlexNet model. Then, the features have been classified using ensemble of Inception-ResNet and VGG-16 (EN_InResNet_VGG-16) architectures. The experimental results show various dataset analyses in terms of accuracy of 98%, precision of 90%, computational time of 79%, SNR of 89%, and MSE of 62%. © 2022 Tammineedi Venkata Satya Vivek et al.",Artificial intelligence; Convolutional neural network; Cytopathology; Lung cancer; Rapid on-site evaluation,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85133931772
"Venkata Satya Vivek T., Naureen A., Ashraf M.S., Manna S., Mateen Buttar A., Muneeshwari P., Wazih Ahmad M.",Biomedical Microscopic Imaging in Computational Intelligence Using Deep Learning Ensemble Convolution Learning-Based Feature Extraction and Classification,2022,Computational Intelligence and Neuroscience,2022,,3531308,,,,10.1155/2022/3531308,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133572476&doi=10.1155%2f2022%2f3531308&partnerID=40&md5=5ae32f306c30153a7a5ce6d95d6b63b9,"Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, Guntur, India; Department of Computer Science and Engineering, B v Raju Institute of Technology, Medak Dist, Telangana, Narsapur, 502313, India; Department of Botany, HKM Govt. Degree College Bandipora, Jammu and Kashmir, India; School of Technology, GITAM (Deemed to Be University), Karnataka, Bangalore, India; Department of Computer Science, University of Agriculture, Faisalabad, 38000, Pakistan; Institute of Artificial Intelligence and Machine Learning, Saveetha School of Engineering(SIMATS), Tamilnadu, Chennai, India; ASTU, Adama, Ethiopia","Venkata Satya Vivek, T., Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, Guntur, India; Naureen, A., Department of Computer Science and Engineering, B v Raju Institute of Technology, Medak Dist, Telangana, Narsapur, 502313, India; Ashraf, M.S., Department of Botany, HKM Govt. Degree College Bandipora, Jammu and Kashmir, India; Manna, S., School of Technology, GITAM (Deemed to Be University), Karnataka, Bangalore, India; Mateen Buttar, A., Department of Computer Science, University of Agriculture, Faisalabad, 38000, Pakistan; Muneeshwari, P., Institute of Artificial Intelligence and Machine Learning, Saveetha School of Engineering(SIMATS), Tamilnadu, Chennai, India; Wazih Ahmad, M., ASTU, Adama, Ethiopia","Accurate diagnosis of lung cancer has been critical, and image segmentation and deep learning (DL) techniques have made it easier for medical people. Yet, the concept's effectiveness is extremely limited due to a scarcity of skilled radiologists. Although emerging DL-based methods frequently necessitate accordance with the regulation, such as labelled feature map, to train such networks, which is difficult to terminate on a big scale. This study proposed a swarm intelligence based modified DL model called MSCOA-DSCN to classify and forecast various Lung Diseases through anterior X-rays. Image enhancement with a modified median filter and edge enhancement with statistical range applied for better image production. The disparity between min and max pixels focused on the Statistical range from each 3×3 input image cluster. Utilized Enriched Auto-Seed Fuzzy Means Morphological Clustering for segmentation (EASFMC); they could function together to identify edges in X-Ray imaging. Used A deep separable convolution network (DSCN) was in the created system to predict the class of lung cancer, and Modified Butterfly Optimization Algorithm (MBOA) applied for the feature selection procedure. This present study compared with various state-of-the-art classification algorithms using the NIH Chest-Xray-14 database. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.",,"Classification (of information); Computer aided analysis; Computer aided diagnosis; Diseases; Extraction; Feature extraction; Image analysis; Image enhancement; Learning systems; Medical imaging; Signal to noise ratio; Brain tumors; Breast Cancer; Cancer tumor; Computer assisted diagnosis; Feature extraction and classification; Learning-based feature extractions; Lung Cancer; Microscopic image analysis; Microscopic imaging; Microscopy image analysis; Deep learning; computer assisted diagnosis; diagnostic imaging; human; image processing; procedures; Deep Learning; Diagnosis, Computer-Assisted; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85133572476
"Geetha N., Joseph S.J.S.A.",Deep Separable Convolution Network for Prediction of Lung Diseases from X-rays,2022,International Journal of Advanced Computer Science and Applications,13,6,,509,518,,10.14569/IJACSA.2022.0130662,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133313795&doi=10.14569%2fIJACSA.2022.0130662&partnerID=40&md5=c55ceae1a6cc1a821173813648a64c5d,"Computer Science, J.J college of Arts and Science (Autonomous), Affiliated to Bharathidasan University, Sivapuram Post,Pudukkottai,Tamilnadu, Tiruchirapalli, India; P.G and Department of Computer Science, J.J.College of Arts and Science (Autonomous), Tamil Nadu, Sivapuram,Pudukkottai, India","Geetha, N., Computer Science, J.J college of Arts and Science (Autonomous), Affiliated to Bharathidasan University, Sivapuram Post,Pudukkottai,Tamilnadu, Tiruchirapalli, India; Joseph, S.J.S.A., P.G and Department of Computer Science, J.J.College of Arts and Science (Autonomous), Tamil Nadu, Sivapuram,Pudukkottai, India","Automatic detection of pulmonary nodules is critical for the early diagnosis and prevention of lung cancer. Computed tomography (CT) is an effective and economical lung cancer detection method. In CT images, the size and shape of pulmonary nodules appear different, and some nodules appear similar to the surrounding tissues. Therefore, the automatic localization of pulmonary nodules in CT images is a challenging task. An attention-embedded three-dimensional convolutional neural network is proposed for pulmonary nodule detection in the current study. Specifically, 1) channel-spatial attention guides 3D ResNet to down sample the input 3D CT patch. The channel pays attention to important features and the space to the region of interest. The two form a complementary feature extraction mechanism to effectively help the global flow of information in the network and refine the feature mapping to extract the nodule context features. 2) The channel-spatial attention module changes the fusion model of the feature pyramid, adaptively adjusts the pixel-level weight between features and extracts multi-scale representative node features. 3) The deep separable convolution is used to replace the standard convolution of ResNet, reducing the time cost and improving the efficiency of model training on the premise of ensuring the model's performance. 4) To adapt the distribution of nodule scale, different characteristic layers correspond to two sizes of anchors. Under the condition of ensuring the detection rate of nodules, the number of anchor frames is reduced, and the network sensitivity is improved. Finally, several ablation experiments are carried out using the LUNA16 dataset. The results revealed that the attention-guided network could extract the multi-scale representative features of nodules, and the average sensitivity was 97.7%. Additionally, the CMP score reached 0.912. The extensive experiments demonstrate that the proposed approach can effectively improve the detection sensitivity and control the number of false positive nodules, which has clinical application value and a certain reference value. © 2013 IEEE.",Deep learning; Edge detection; Filtering; Lung diseases; Segmentation and swarm intelligence; X-rays,Biological organs; Classification (of information); Deep learning; Diagnosis; Diseases; Edge detection; Forecasting; Image enhancement; Image segmentation; Median filters; Medical imaging; Deep learning; Diagnosis of lung cancer; Edge enhancements; Feature map; Images segmentations; Learning models; Learning techniques; Learning-based methods; Median-Filter; Segmentation and swarm intelligence; Swarm intelligence,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85133313795
"Vidhya R., Mirnalinee T.T.",Hybrid Optimized Learning for Lung Cancer Classification,2022,Intelligent Automation and Soft Computing,34,2,,911,925,,10.32604/iasc.2022.025060,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132658084&doi=10.32604%2fiasc.2022.025060&partnerID=40&md5=718879e768b1a1db55af70c974565cb8,"Agni College of Technology, Chennai, 600130, India; SSN College of Engineering, Chennai, 600004, India","Vidhya, R., Agni College of Technology, Chennai, 600130, India; Mirnalinee, T.T., SSN College of Engineering, Chennai, 600004, India","Lung cancer accounts for the greatest number of cancer-related mortality, while the accurate evaluation of pulmonary nodules in computed tomography (CT) images can significantly increase the 5-year relative survival rate. Despite deep learning methods that have recently been introduced to the identification of malignant nodules, a substantial challenge remains due to the limited datasets. In this study, we propose a cascaded-recalibrated multiple instance learning (MIL) model based on multiattribute features transfer for pathologic-level lung cancer prediction in CT images. This cascaded-recalibrated MIL deep model incorporates a cascaded recalibration mechanism at the nodule level and attribute level, which fuses the informative attribute features into nodule embeddings and then the key nodule features can be converged into the patient-level embedding to improve the performance of lung cancer prediction. We evaluated the proposed cascaded-recalibrated MIL model on the public Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) benchmark dataset and compared it to the latest approaches. The experimental results showed a significant performance boost by the cascaded-recalibrated MIL model over the higher-order transfer learning, instance-space MIL, and embedding-space MIL models and the radiologists. In addition, the recalibration coefficients of the nodule and attribute feature for the final decision were also analyzed to reveal the underlying relationship between the confirmed diagnosis and its highly-correlated attributes. The cascaded recalibration mechanism enables the MIL model to pay more attention to those important nodules and attributes while suppressing less-useful feature embeddings, and the cascaded-recalibrated MIL model provides substantial improvements for the pathologic-level lung cancer prediction by using the CT images. The identification of the important nodules and attributes also provides better interpretability for model decision-making, which is very important for medical applications. © 2022 Qingfeng Wang et al.",ant-lion optimization; Computer tomography scan images; convolutional neural networks; fused features; saliency maps,,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85132658084
"Jain D.K., Lakshmi K.M., Varma K.P., Ramachandran M., Bharati S.",Lung Cancer Detection Based on Kernel PCA-Convolution Neural Network Feature Extraction and Classification by Fast Deep Belief Neural Network in Disease Management Using Multimedia Data Sources,2022,Computational Intelligence and Neuroscience,2022,,3149406,,,,10.1155/2022/3149406,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131339058&doi=10.1155%2f2022%2f3149406&partnerID=40&md5=17fde65d7e5a9ba046ea9d14acdb5086,"Key Laboratory of Intelligent Air-Ground Cooperative Control for Universities in Chongqing, College of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; Department of Electronics and Communication Engineering, CMR Technical Campus, Secunderabad, 501401, India; Department of Electronics and Communication Engineering, Sagi Rama Krishnam Raju Engineering College, Bhimavaram, 534204, India; School of Computing, SASTRA Deemed University, Thanjavur, India; Institute of Information and Communication Technology, Bangladesh University of Engineering and Technology, Dhaka, 1205, Bangladesh","Jain, D.K., Key Laboratory of Intelligent Air-Ground Cooperative Control for Universities in Chongqing, College of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; Lakshmi, K.M., Department of Electronics and Communication Engineering, CMR Technical Campus, Secunderabad, 501401, India; Varma, K.P., Department of Electronics and Communication Engineering, Sagi Rama Krishnam Raju Engineering College, Bhimavaram, 534204, India; Ramachandran, M., School of Computing, SASTRA Deemed University, Thanjavur, India; Bharati, S., Institute of Information and Communication Technology, Bangladesh University of Engineering and Technology, Dhaka, 1205, Bangladesh","Pulmonary nodules are the early manifestation of lung cancer, which appear as circular shadow of no more than 3 cm on the computed tomography (CT) image. Accurate segmentation of the contours of pulmonary nodules can help doctors improve the efficiency of diagnosis. Deep learning has achieved great success in computer vision. In this study, we propose a novel network for pulmonary nodule segmentation from CT images based on U-NET. The proposed network has two merits: one is that it introduces dense connection to transfer and utilize features. Additionally, the problem of gradient disappearance can be avoided. The second is that it introduces a new loss function which is tolerance on the pixels near the borders of the nodule. Experimental results show that the proposed network at least achieves 1% improvement compared with other state-of-art networks in terms of different criteria. © 2022 Dechuan Lu et al.",,"Biological organs; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Diagnosis; Extraction; Feature extraction; Histology; Image analysis; Image enhancement; Information management; Medical imaging; Multilayer neural networks; Risk assessment; Tumors; Convolution neural network; Disease management; Feature extraction and classification; Histopathological images; Input image; Kernel PCA; Lung Cancer; Lung cancer detections; Neural network feature extractions; Neural-networks; Diseases; diagnostic imaging; disease management; human; information retrieval; lung; lung tumor; multimedia; Disease Management; Humans; Information Storage and Retrieval; Lung; Lung Neoplasms; Multimedia; Neural Networks, Computer",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85131339058
"Lu D., Chu J., Zhao R., Zhang Y., Tian G.",A Novel Deep Learning Network and Its Application for Pulmonary Nodule Segmentation,2022,Computational Intelligence and Neuroscience,2022,,7124902,,,,10.1155/2022/7124902,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130881764&doi=10.1155%2f2022%2f7124902&partnerID=40&md5=9b083893b45b487783eed8d074e966c7,"Cancer Center, Jiangdu People's Hospital, Jiangsu, Yangzhou, China; Department of Oncology, Jiangdu People's Hospital, Jiangsu, Yangzhou, China; Department of Medical Informatics, Nantong University, Jiangsu, Nantong, China","Lu, D., Cancer Center, Jiangdu People's Hospital, Jiangsu, Yangzhou, China; Chu, J., Cancer Center, Jiangdu People's Hospital, Jiangsu, Yangzhou, China; Zhao, R., Department of Oncology, Jiangdu People's Hospital, Jiangsu, Yangzhou, China; Zhang, Y., Department of Medical Informatics, Nantong University, Jiangsu, Nantong, China; Tian, G., Department of Oncology, Jiangdu People's Hospital, Jiangsu, Yangzhou, China","Lung cancer is one of the most dangerous deadly diseases for individuals worldwide. Thus, the survival rate is low due to the difficulty in detecting lung cancer at advanced stages like symptoms; thus, prominence for early diagnosis is important. The detection and treatment of lung cancer is having great importance for early diagnosis. The existing Convolution Neural Network (CNN) based deep learning methods showed tuning was the problem of choosing a set of hyperparameters for the learning algorithm and included outliers that affect the classification result. Therefore, the present research work aims to utilize Grasshopper Optimization Algorithm (GOA) effectively to solve global unconstrained and constrained optimization issues. Additionally, performing training using the Generative Adversarial Network (GAN) model that controlled the behavior of the classifier during training showed a significant impact. The results showed that the proposed method gives better results in terms of accuracy of 98.89% when compared to the existing models such as KNG-CNN of 87.3%, mask region-based CNN of 97.68%, Transferable Texture CNN of 96.69%, Fuzzy Particle Swarm Optimization (FPSO) CNN of 95.62% and E-CNN method of 97% © 2022 Sukruth Gowda and A. Jayachandran. This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license",,"Computerized tomography; Image segmentation; Positron emission tomography; ART networks; Computed tomography images; Image-based; ITS applications; Learning network; Loss functions; Lung Cancer; Network applications; Nodule segmentation; Pulmonary nodules; Deep learning; diagnostic imaging; human; lung tumor; multiple pulmonary nodules; procedures; x-ray computed tomography; Deep Learning; Humans; Lung Neoplasms; Multiple Pulmonary Nodules; Tomography, X-Ray Computed",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85130881764
"Gowda S., Jayachandran A.",Grasshopper Optimization Algorithm-Generative Adversarial Network for Lung Cancer Detection and Classification,2022,Journal of Computer Science,18,3,,227,232,,10.3844/jcssp.2022.227.232,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130856894&doi=10.3844%2fjcssp.2022.227.232&partnerID=40&md5=063efdb584b90792ae08c816d8fdfeec,"Department of Computer Science and Engineering, Presidency University, Bengaluru, India","Gowda, S., Department of Computer Science and Engineering, Presidency University, Bengaluru, India; Jayachandran, A., Department of Computer Science and Engineering, Presidency University, Bengaluru, India","Early detection of lung cancer can help for improving the survival rate of the patients. Biomedical imaging tools such as computed tomography (CT) image was utilized to the proper identification and positioning of lung cancer. The recently developed deep learning (DL) models can be employed for the effectual identification and classification of diseases. This article introduces novel deep learning enabled CAD technique for lung cancer using biomedical CT image, named DLCADLC-BCT technique. The proposed DLCADLC-BCT technique intends for detecting and classifying lung cancer using CT images. The proposed DLCADLC-BCT technique initially uses gray level co-occurrence matrix (GLCM) model for feature extraction. Also, long short term memory (LSTM) model was applied for classifying the existence of lung cancer in the CT images. Moreover, moth swarm optimization (MSO) algorithm is employed to optimally choose the hyperparameters of the LSTM model such as learning rate, batch size, and epoch count. For demonstrating the improved classifier results of the DLCADLC-BCT approach, a set of simulations were executed on benchmark dataset and the outcomes exhibited the supremacy of the DLCADLC-BCT technique over the recent approaches. © 2022 Tech Science Press. All rights reserved.",Convolution neural network; Generative adversarial network; Grasshopper optimization algorithm; Hyper parameters; Lung cancer; Outliers; Unconstrained and constrained optimization issues,,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85130856894
"Alamgeer M., Mengash H.A., Marzouk R., Nour M.K., Hilal A.M., Motwakel A., Zamani A.S., Rizwanullah M.",Deep Learning Enabled Computer Aided Diagnosis Model for Lung Cancer using Biomedical CT Images,2022,"Computers, Materials and Continua",73,1,,1437,1448,,10.32604/cmc.2022.027896,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130109881&doi=10.32604%2fcmc.2022.027896&partnerID=40&md5=4057387b79d9b3fd0fa5778f5a978507,"Department of Information Systems, College of Science & Art at Mahayil, King Khalid University, Saudi Arabia; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, 11671, Saudi Arabia; Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Saudi Arabia; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia","Alamgeer, M., Department of Information Systems, College of Science & Art at Mahayil, King Khalid University, Saudi Arabia; Mengash, H.A., Department of Information Systems, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, 11671, Saudi Arabia; Marzouk, R., Department of Information Systems, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, 11671, Saudi Arabia; Nour, M.K., Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Saudi Arabia; Hilal, A.M., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Motwakel, A., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Zamani, A.S., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Rizwanullah, M., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia","Lung cancer is the main cause of cancer related death owing to its destructive nature and postponed detection at advanced stages. Early recognition of lung cancer is essential to increase the survival rate of persons and it remains a crucial problem in the healthcare sector. Computer aided diagnosis (CAD) models can be designed to effectually identify and classify the existence of lung cancer using medical images. The recently developed deep learning (DL) models find a way for accurate lung nodule classification process. Therefore, this article presents a deer hunting optimization with deep convolutional neural network for lung cancer detection and classification (DHODCNN-LCC) model. The proposed DHODCNN-LCC technique initially undergoes pre-processing in two stages namely contrast enhancement and noise removal. Besides, the features extraction process on the pre-processed images takes place using the Nadam optimizer with RefineDet model. In addition, denoising stacked autoencoder (DSAE) model is employed for lung nodule classification. Finally, the deer hunting optimization algorithm (DHOA) is utilized for optimal hyper parameter tuning of the DSAE model and thereby results in improved classification performance. The experimental validation of the DHODCNN-LCC technique was implemented against benchmark dataset and the outcomes are assessed under various aspects. The experimental outcomes reported the superior outcomes of the DHODCNN-LCC technique over the recent approaches with respect to distinct measures. © 2022 Tech Science Press. All rights reserved.",Biomedical images; deep learning; hyperparameter tuning; lung cancer; machine learning; metaheuristics,Biological organs; Classification (of information); Computerized tomography; Diseases; Image classification; Long short-term memory; Medical imaging; Optimization; Biomedical images; Computed tomography images; Deep learning; Diagnosis model; Hyper-parameter; Hyperparameter tuning; Lung Cancer; Memory modeling; Metaheuristic; Survival rate; Computer aided diagnosis,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85130109881
"Ragab M., Abdushkour H.A., Nahhas A.F., Aljedaibi W.H.",Deer Hunting Optimization with Deep Learning Model for Lung Cancer Classification,2022,"Computers, Materials and Continua",73,1,,533,546,,10.32604/cmc.2022.028856,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130099693&doi=10.32604%2fcmc.2022.028856&partnerID=40&md5=ea11d6743823951490c303fc75354e29,"Information Technology Department, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Center of Artificial Intelligence for Precision Medicines, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Mathematics Department, Faculty of Science, Al-Azhar University, Naser City, Cairo, 11884, Egypt; Nautical Science Department, Faculty of Maritime Studies, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Biochemistry Department, Faculty of Science, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Computer Science Department, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","Ragab, M., Information Technology Department, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia, Center of Artificial Intelligence for Precision Medicines, King Abdulaziz University, Jeddah, 21589, Saudi Arabia, Mathematics Department, Faculty of Science, Al-Azhar University, Naser City, Cairo, 11884, Egypt; Abdushkour, H.A., Nautical Science Department, Faculty of Maritime Studies, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Nahhas, A.F., Biochemistry Department, Faculty of Science, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Aljedaibi, W.H., Computer Science Department, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","The well-established mortality rates due to lung cancers, scarcity of radiology experts and inter-observer variability underpin the dire need for robust and accurate computer aided diagnostics to provide a second opinion. To this end, we propose a feature grafting approach to classify lung cancer images from publicly available National Institute of Health (NIH) chest X-Ray dataset comprised of 30,805 unique patients. The performance of transfer learning with pre-trained VGG and Inception models is evaluated in comparison against manually extracted radiomics features added to convolutional neural network using custom layer. For classification with both approaches, Support VectorsMachines (SVM) are used. The results from the 5-fold cross validation report Area Under Curve (AUC) of 0.92 and accuracy of 96.87% in detecting lung nodules with the proposed method. This is a plausible improvement against the observed accuracy of transfer learning using Inception (79.87%). The specificity of allmethods is>99%, however, the sensitivity of the proposed method (97.24%) surpasses that of transfer learning approaches (<67%). Furthermore, it is observed that the true positive rate with SVM is highest at the same false-positive rate in experiments amongst Random Forests, Decision Trees, and K-Nearest Neighbor classifiers. Hence, the proposed approach can be used in clinical and research environments to provide second opinions very close to the experts' intuition. © 2022 Tech Science Press. All rights reserved.",computer aided diagnosis; deep learning; image classification; Lung cancer; medical imaging; parameter optimization,Biological organs; Computer aided diagnosis; Computer aided instruction; Convolutional neural networks; Diseases; Image classification; Medical imaging; Cancer classification; Classification technique; Deep learning; Deer hunting; Images classification; Learning models; Lung Cancer; Lung cancer detections; Optimisations; Parameter optimization; Deep neural networks,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85130099693
"Choudhry I.A., Qureshi A.N.",Detection of Lung Nodules on X-ray Using Transfer Learning and Manual Features,2022,"Computers, Materials and Continua",72,1,,1445,1463,,10.32604/cmc.2022.025208,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125405818&doi=10.32604%2fcmc.2022.025208&partnerID=40&md5=f38146408a0612ea144dea66fec1054c,"Faculty of Information Technology, University of Central Punjab, Lahore, Pakistan","Choudhry, I.A., Faculty of Information Technology, University of Central Punjab, Lahore, Pakistan; Qureshi, A.N., Faculty of Information Technology, University of Central Punjab, Lahore, Pakistan","This study aim was to explore the application effect of computed tomography (CT) image segmentation based on deep learning algorithm in the diagnosis of lung cancer. In this study, a two-dimensional (2D) convolutional neural network (CNN) and three-dimensional (3D) CNN fusion model was constructed firstly. Subsequently, 60 patients with lung cancer were randomly divided into a control group and an intervention group to receive perioperative routine nursing and rehabilitation nursing, respectively. The results revealed that the Dice value (0.876), sensitivity (0.849), and positive predictive value (PPV) (0.875) of the hybrid feature fusion model (HFFM) constructed in this study for lung cancer CT image segmentation were higher than those of other models, and the accuracy rate for lung cancer diagnosis was 96.7%. After nursing intervention, the partial arterial oxygen pressure (PaO2) and partial arterial carbon dioxide pressure (PaCO2) in the control group were 80.54 mmHg and 39.81 mmHg, respectively, while those in the intervention group were 83.09 mmHg and 36.75 mmHg, respectively. After intervention, the maximal voluntary ventilation (MVV) %, forced vital capacity (FVC) %, and forced expiratory volume in 1 sec (FEV1) %) in the intervention group were 76.03%, 82.14%, and 89.76%, respectively. It suggested that compared with the control group, the pulmonary function indexes of the intervention group improved significantly after nursing intervention (P < 0.05). In summary, the HFFM constructed in this study can be used for segmentation and classification of CT images of lung cancer patients, which can improve the accuracy of diagnosis and help improve the lung function and quality of life of patients. © 2022 Sha Yan et al.",Classification; Convolutional neural network; Deep learning; Hand-crafted feature extraction; Lungs cancer,Biological organs; Clinical research; Computer aided diagnosis; Convolution; Convolutional neural networks; Decision trees; Deep learning; Diseases; Feature extraction; Multilayer neural networks; Nearest neighbor search; Support vector machines; Convolutional neural network; Deep learning; Detection of lung nodules; Features extraction; Hand-crafted feature extraction; Interobserver variability; Lung Cancer; Mortality rate; Second opinions; Transfer learning; Classification (of information),Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85125405818
"Yan S., Huang Q., Yu S., Liu Z.",Computed Tomography Images under Deep Learning Algorithm in the Diagnosis of Perioperative Rehabilitation Nursing for Patients with Lung Cancer,2022,Scientific Programming,2022,,8685604,,,,10.1155/2022/8685604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124414838&doi=10.1155%2f2022%2f8685604&partnerID=40&md5=8c0152554f0a185c6cc1c2c5f841af38,"Department of Operating Room, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China; Department of Social Services, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China","Yan, S., Department of Operating Room, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China; Huang, Q., Department of Operating Room, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China; Yu, S., Department of Operating Room, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China; Liu, Z., Department of Social Services, No. 4 Hospital of Wuhan, Hubei, Wuhan, 430000, China","Cancer is a complex worldwide health concern that resulted in 10 million cancer deaths in 2018; hence, early cancer detection is crucial. Early detection involves developing more precise technology that offers information about the patient’s cancer, allowing clinicians to make better-informed treatment options. This study provides an in-depth analysis of multiple cancers. This study also exhibits a good survey of the machine or deep learning techniques used in cancer research. Also, the study proposed a stacking-based multi-neural ensemble learning method’s prediction performance on eight datasets, including the benchmark datasets like Wisconsin Breast cancer dataset, mesothelioma, cervical cancer, non-small cell lung cancer survival dataset, and prostate cancer dataset. This study also analyzes the three real-time cancer datasets (Lung, Ovarian & Leukemia) of the Jammu and Kashmir region. The simulation findings indicate that the methodology described in our study attained the highest level of prediction accuracy across all types of cancer data sets. Additionally, the proposed approach has been statistically validated. The purpose of this investigation was to develop and evaluate a prediction model that might be used as a biomarker for malignancy based on anthropometric, clinical, imaging, and gene data. © 2021 The Author(s). Published with license by Taylor & Francis Group, LLC.",,Biological organs; Computerized tomography; Convolutional neural networks; Deep learning; Diagnosis; Image enhancement; Image segmentation; Learning algorithms; Nursing; Patient rehabilitation; Patient treatment; Application effect; Computed tomography images; Control groups; Convolutional neural network; Features fusions; Fusion model; Hybrid features; Images segmentations; Lung Cancer; Nursing interventions; Diseases,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124414838
"Sitaula C., Aryal S.",New bag of deep visual words based features to classify chest x-ray images for COVID-19 diagnosis,2021,Health Information Science and Systems,9,1,24,,,9,10.1007/s13755-021-00152-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121294360&doi=10.1007%2fs13755-021-00152-w&partnerID=40&md5=a496f90c791124609a6a9dedeb773447,"School of Information Technology, Deakin University, 75 Pigdons Rd, Waurn Ponds, Melbourne, VIC  3216, Australia","Sitaula, C., School of Information Technology, Deakin University, 75 Pigdons Rd, Waurn Ponds, Melbourne, VIC  3216, Australia; Aryal, S., School of Information Technology, Deakin University, 75 Pigdons Rd, Waurn Ponds, Melbourne, VIC  3216, Australia","Background: Adenocarcinoma and squamous cell carcinoma are the two most prevalent lung cancer types, and their distinction requires different screenings, such as the visual inspection of histology slides by an expert pathologist, the analysis of gene expression or computer tomography scans, among others. In recent years, there has been an increasing gathering of biological data for decision support systems in the diagnosis (e.g. histology imaging, next-generation sequencing technologies data, clinical information, etc.). Using all these sources to design integrative classification approaches may improve the final diagnosis of a patient, in the same way that doctors can use multiple types of screenings to reach a final decision on the diagnosis. In this work, we present a late fusion classification model using histology and RNA-Seq data for adenocarcinoma, squamous-cell carcinoma and healthy lung tissue. Results: The classification model improves results over using each source of information separately, being able to reduce the diagnosis error rate up to a 64% over the isolate histology classifier and a 24% over the isolate gene expression classifier, reaching a mean F1-Score of 95.19% and a mean AUC of 0.991. Conclusions: These findings suggest that a classification model using a late fusion methodology can considerably help clinicians in the diagnosis between the aforementioned lung cancer cancer subtypes over using each source of information separately. This approach can also be applied to any cancer type or disease with heterogeneous sources of information. © 2021, The Author(s).",Bag of deep visual words (BoDVW); Bag of visual words (BoVW); Chest X-ray; COVID-19; Deep features; SARS-CoV-2,algorithm; area under the curve; Article; artificial neural network; bag of deep visual word; breast cancer; cardiomegaly; convolutional neural network; coronavirus disease 2019; human; image analysis; image segmentation; machine learning; mathematical analysis; performance; pneumonia; receiver operating characteristic; sensitivity analysis; sensitivity and specificity; spatial analysis; support vector machine; thorax radiography; training; tuberculosis; validation study; virus detection; X ray,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85121294360
"Carrillo-Perez F., Morales J.C., Castillo-Secilla D., Molina-Castro Y., Guillén A., Rojas I., Herrera L.J.",Non-small-cell lung cancer classification via RNA-Seq and histology imaging probability fusion,2021,BMC Bioinformatics,22,1,454,,,3,10.1186/s12859-021-04376-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115238423&doi=10.1186%2fs12859-021-04376-1&partnerID=40&md5=7b4470e10948693fa89a78af39cfd9b6,"Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain","Carrillo-Perez, F., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Morales, J.C., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Castillo-Secilla, D., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Molina-Castro, Y., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Guillén, A., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Rojas, I., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain; Herrera, L.J., Department of Computer Architecture and Technology, University of Granada. C.I.T.I.C., Periodista Rafael Gómez Montero, 2, Granada, 18014, Spain","Purpose: To determine whether deep learning algorithms developed in a public competition could identify lung cancer on low-dose CT scans with a performance similar to that of radiologists. Materials and Methods: In this retrospective study, a dataset consisting of 300 patient scans was used for model assessment; 150 patient scans were from the competition set and 150 were from an independent dataset. Both test datasets contained 50 cancer-positive scans and 100 cancer-negative scans. The reference standard was set by histopathologic examination for cancer-positive scans and imaging follow-up for at least 2 years for cancer-negative scans. The test datasets were applied to the three top-performing algorithms from the Kaggle Data Science Bowl 2017 public competition: grt123, Julian de Wit and Daniel Hammack (JWDH), and Aidence. Model outputs were compared with an observer study of 11 radiologists that assessed the same test datasets. Each scan was scored on a continuous scale by both the deep learning algorithms and the radiologists. Performance was measured using multireader, multicase receiver operating characteristic analysis. Results: The area under the receiver operating characteristic curve (AUC) was 0.877 (95% CI: 0.842, 0.910) for grt123, 0.902 (95% CI: 0.871, 0.932) for JWDH, and 0.900 (95% CI: 0.870, 0.928) for Aidence. The average AUC of the radiologists was 0.917 (95% CI: 0.889, 0.945), which was significantly higher than grt123 (P =.02); however, no significant difference was found between the raologists and JWDH (P =.29) or Aidence (P =.26). Conclusion: Deep learning algorithms developed in a public competition for lung cancer detection in low-dose CT scans reached performance close to that of radiologists. © RSNA, 2021.",Deep learning; Gene expression; Late fusion; NSCLC; Whole slide imaging,"Biological organs; Classification (of information); Computer aided diagnosis; Decision support systems; Deep learning; Diseases; Gene expression; Information use; RNA; Classification models; Deep learning; Genes expression; Late fusion; Lung Cancer; Non small cell lung cancer; NSCLC; Sources of informations; Squamous cell carcinoma; Whole slide imaging; Histology; adenocarcinoma; diagnostic imaging; genetics; human; lung tumor; non small cell lung cancer; probability; Adenocarcinoma; Carcinoma, Non-Small-Cell Lung; Humans; Lung Neoplasms; Probability; RNA-Seq",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85115238423
"Chaudhari A.S., Mittra E., Davidzon G.A., Gulaka P., Gandhi H., Brown A., Zhang T., Srinivas S., Gong E., Zaharchuk G., Jadvar H.",Low-count whole-body PET with deep learning in a multicenter and externally validated study,2021,npj Digital Medicine,4,1,127,,,7,10.1038/s41746-021-00497-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113724662&doi=10.1038%2fs41746-021-00497-2&partnerID=40&md5=61efbbe28f611ea5b1ff9d09a7496caf,"Department of Radiology, Stanford University, Palo Alto, CA, United States; Department of Biomedical Data Science, Stanford University, Stanford, CA, United States; Subtle Medical, Menlo Park, CA, United States; Division of Diagnostic Radiology, Oregon Health & Science University, Portland, OR, United States; Department of Radiology, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Department of Radiology, University of Southern California, Los Angeles, CA, United States","Chaudhari, A.S., Department of Radiology, Stanford University, Palo Alto, CA, United States, Department of Biomedical Data Science, Stanford University, Stanford, CA, United States, Subtle Medical, Menlo Park, CA, United States; Mittra, E., Division of Diagnostic Radiology, Oregon Health & Science University, Portland, OR, United States; Davidzon, G.A., Department of Radiology, Stanford University, Palo Alto, CA, United States; Gulaka, P., Subtle Medical, Menlo Park, CA, United States; Gandhi, H., Subtle Medical, Menlo Park, CA, United States; Brown, A., Division of Diagnostic Radiology, Oregon Health & Science University, Portland, OR, United States; Zhang, T., Subtle Medical, Menlo Park, CA, United States; Srinivas, S., Department of Radiology, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Gong, E., Subtle Medical, Menlo Park, CA, United States; Zaharchuk, G., Department of Radiology, Stanford University, Palo Alto, CA, United States, Subtle Medical, Menlo Park, CA, United States; Jadvar, H., Department of Radiology, University of Southern California, Los Angeles, CA, United States","Background: Accurate segmentation and recognition algorithm of lung nodules has great important value of reference for early diagnosis of lung cancer. An algorithm is proposed for 3D CT sequence images in this paper based on 3D Res U-Net segmentation network and 3D ResNet50 classification network. The common convolutional layers in encoding and decoding paths of U-Net are replaced by residual units while the loss function is changed to Dice loss after using cross entropy loss to accelerate network convergence. Since the lung nodules are small and rich in 3D information, the ResNet50 is improved by replacing the 2D convolutional layers with 3D convolutional layers and reducing the sizes of some convolution kernels, 3D ResNet50 network is obtained for the diagnosis of benign and malignant lung nodules. Results: 3D Res U-Net was trained and tested on 1044 CT subcases in the LIDC-IDRI database. The segmentation result shows that the Dice coefficient of 3D Res U-Net is above 0.8 for the segmentation of lung nodules larger than 10 mm in diameter. 3D ResNet50 was trained and tested on 2960 lung nodules in the LIDC-IDRI database. The classification result shows that the diagnostic accuracy of 3D ResNet50 is 87.3% and AUC is 0.907. Conclusion: The 3D Res U-Net module improves segmentation performance significantly with the comparison of 3D U-Net model based on residual learning mechanism. 3D Res U-Net can identify small nodules more effectively and improve its segmentation accuracy for large nodules. Compared with the original network, the classification performance of 3D ResNet50 is significantly improved, especially for small benign nodules. © 2021, The Author(s).",,fluorodeoxyglucose f 18; adult; aged; aorta; Article; bile duct carcinoma; body mass; breast cancer; cancer diagnosis; cancer patient; chondrosarcoma; chronic lymphatic leukemia; clinical article; clinical evaluation; colon cancer; comparative study; computer assisted diagnosis; computer assisted tomography; convolutional neural network; deep learning; diagnostic accuracy; distant metastasis; esophagus cancer; false negative result; false positive result; female; gluteus muscle; head and neck carcinoma; human; hypermetabolism; image artifact; image quality; imaging algorithm; interrater reliability; intrarater reliability; kidney cancer; leiomyosarcoma; liver; lung cancer; lung metastasis; lymph node metastasis; lymphoma; male; maximum standardized uptake value; measurement repeatability; melanoma; middle aged; multicenter study; ordered subset expectation maximization; oropharynx cancer; pancreas islet cell tumor; positron emission tomography; positron emission tomography-computed tomography; prospective study; qualitative diagnosis; quantitative diagnosis; sarcoma; sensitivity and specificity; standardized uptake value; stomach cancer; urethra cancer; whole body PET,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85113724662
"Jacobs C., Setio A.A.A., Scholten E.T., Gerke P.K., Bhattacharya H., Hoesein F.A.M., Brink M., Ranschaert E., de Jong P.A., Silva M., Geurts B., Chung K., Schalekamp S., Meersschaert J., Devaraj A., Pinsky P.F., Lam S.C., van Ginneken B., Farahani K.",Deep learning for lung cancer detection on screening ct scans: Results of a large-scale public competition and an observer study with 11 radiologists,2021,Radiology: Artificial Intelligence,3,6,e210027,,,1,10.1148/ryai.2021210027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120541797&doi=10.1148%2fryai.2021210027&partnerID=40&md5=dd4145c084b9893d7c3c5b09e615b847,"Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Department of Digital Technology & Innovation, Siemens Healthineers, Erlangen, Germany; Department of Radiology, University Medical Center Utrecht, Utrecht, Netherlands; ETZ (Elisabeth-TweeSteden Ziekenhuis), Tilburg, Netherlands; Section of Radiology, Department of Medicine and Surgery (DiMeC), University of Parma, Parma, Italy; Department of Radiology, Meander Medical Center, Amersfoort, Netherlands; Department of Radiology, AZ Zeno, Knokke-Heist, Belgium; Department of Imaging, Royal Brompton Hospital, London, United Kingdom; Division of Cancer Prevention, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States; Center for Biomedical Informatics & Information Technology, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States; British Columbia Cancer Agency and the University of British Columbia, Vancouver, Canada; Fraunhofer MEVIS, Bremen, Germany","Jacobs, C., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Setio, A.A.A., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands, Department of Digital Technology & Innovation, Siemens Healthineers, Erlangen, Germany; Scholten, E.T., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Gerke, P.K., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Bhattacharya, H., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Hoesein, F.A.M., Department of Radiology, University Medical Center Utrecht, Utrecht, Netherlands; Brink, M., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Ranschaert, E., ETZ (Elisabeth-TweeSteden Ziekenhuis), Tilburg, Netherlands; de Jong, P.A., Department of Radiology, University Medical Center Utrecht, Utrecht, Netherlands; Silva, M., Section of Radiology, Department of Medicine and Surgery (DiMeC), University of Parma, Parma, Italy; Geurts, B., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Chung, K., Department of Radiology, Meander Medical Center, Amersfoort, Netherlands; Schalekamp, S., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands, Department of Radiology, Meander Medical Center, Amersfoort, Netherlands; Meersschaert, J., Department of Radiology, AZ Zeno, Knokke-Heist, Belgium; Devaraj, A., Department of Imaging, Royal Brompton Hospital, London, United Kingdom; Pinsky, P.F., Division of Cancer Prevention, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States, Center for Biomedical Informatics & Information Technology, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States; Lam, S.C., British Columbia Cancer Agency and the University of British Columbia, Vancouver, Canada; van Ginneken, B., Department of Radiology, Nuclear Medicine and Anatomy, Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands, Fraunhofer MEVIS, Bremen, Germany; Farahani, K., Division of Cancer Prevention, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States, Center for Biomedical Informatics & Information Technology, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States","Lung cancer is a deadly cancer that causes millions of deaths every year around the world. Accurate lung nodule detection and segmentation in computed tomography (CT) images is a vital step for diagnosing lung cancer early. Most existing systems face several challenges, such as the heterogeneity in CT images and variation in nodule size, shape, and location, which limit their accuracy. In an attempt to handle these challenges, this article proposes a fully automated deep learning framework that consists of lung nodule detection and segmentation models. Our proposed system comprises two cascaded stages: (1) nodule detection based on fine-tuned Faster R-CNN to localize the nodules in CT images, and (2) nodule segmentation based on the U-Net architecture with two effective blocks, namely position attention-aware weight excitation (PAWE) and channel attention-aware weight excitation (CAWE), to enhance the ability to discriminate between nodule and non-nodule feature representations. The experimental results demonstrate that the proposed system yields a Dice score of 89.79% and 90.35%, and an intersection over union (IoU) of 82.34% and 83.21% on the publicly available LUNA16 and LIDC-IDRI datasets, respectively. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",,algorithm; Article; cancer diagnosis; clinical trial (topic); deep learning; follow up; histopathology; human; lung cancer; observer bias; questionnaire; radiologist; receiver operating characteristic; x-ray computed tomography,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85120541797
"Banu S.F., Sarker M.M.K., Abdel-Nasser M., Puig D., Raswan H.A.",Aweu-net: An attention-aware weight excitation u-net for lung nodule segmentation,2021,Applied Sciences (Switzerland),11,21,10132,,,2,10.3390/app112110132,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118102665&doi=10.3390%2fapp112110132&partnerID=40&md5=623ddf7b8ec25fc8d545f0377bf7e694,"Departament d’Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, 43007, Spain; National Subsea Centre, Robert Gordon University, Aberdeen, AB10 7GJ, United Kingdom; Department of Electrical Engineering, Aswan University, Aswan, 81542, Egypt","Banu, S.F., Departament d’Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, 43007, Spain; Sarker, M.M.K., National Subsea Centre, Robert Gordon University, Aberdeen, AB10 7GJ, United Kingdom; Abdel-Nasser, M., Departament d’Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, 43007, Spain, Department of Electrical Engineering, Aswan University, Aswan, 81542, Egypt; Puig, D., Departament d’Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, 43007, Spain; Raswan, H.A., Departament d’Enginyeria Informàtica i Matemàtiques, Universitat Rovira i Virgili, Tarragona, 43007, Spain","Background and Objective: Computer-aided diagnosis (CAD) systems promote accurate diagnosis and reduce the burden of radiologists. A CAD system for lung cancer diagnosis includes nodule candidate detection and nodule malignancy evaluation. Recently, deep learning-based pulmonary nodule detection has reached satisfactory performance ready for clinical application. However, deep learning-based nodule malignancy evaluation depends on heuristic inference from low-dose computed tomography (LDCT) volume to malignant probability, and lacks clinical cognition. Methods: In this paper, we propose a joint radiology analysis and malignancy evaluation network called R2MNet to evaluate pulmonary nodule malignancy via the analysis of radiological characteristics. Radiological features are extracted as channel descriptor to highlight specific regions of the input volume that are critical for nodule malignancy evaluation. In addition, for model explanations, we propose channel-dependent activation mapping (CDAM) to visualize features and shed light on the decision process of deep neural networks (DNNs). Results: Experimental results on the lung image database consortium image collection (LIDC-IDRI) dataset demonstrate that the proposed method achieved an area under curve (AUC) of 96.27% and 97.52% on nodule radiology analysis and nodule malignancy evaluation, respectively. In addition, explanations of CDAM features proved that the shape and density of nodule regions are two critical factors that influence a nodule to be inferred as malignant. This process conforms to the diagnosis cognition of experienced radiologists. Conclusion: The network inference process conforms to the diagnostic procedure of radiologists and increases the confidence of evaluation results by incorporating radiology analysis with nodule malignancy evaluation. Besides, model interpretation with CDAM features shed light on the focus regions of DNNs during the estimation of nodule malignancy probabilities. © 2021 Elsevier B.V.",Artificial intelligence; Computed tomography; Computer-aided diagnosis; Deep learning; Lung cancer; Lung nodule detection; Lung nodule segmentation,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85118102665
"Ma H., Sheng W., Li J., Hou L., Yang J., Cai J., Xu W., Zhang S.",A novel hierarchical machine learning model for hospital-acquired venous thromboembolism risk assessment among multiple-departments,2021,Journal of Biomedical Informatics,122,,103892,,,,10.1016/j.jbi.2021.103892,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114800202&doi=10.1016%2fj.jbi.2021.103892&partnerID=40&md5=af55172ebbc132407f236c9267be440e,"Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China; Shanghai Tenth People's Hospital, Shanghai, China; Shanghai Synyi Medical Technology Co., Ltd, Shanghai, China","Ma, H., Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China; Sheng, W., Shanghai Synyi Medical Technology Co., Ltd, Shanghai, China; Li, J., Shanghai Tenth People's Hospital, Shanghai, China; Hou, L., Shanghai Tenth People's Hospital, Shanghai, China; Yang, J., Shanghai Tenth People's Hospital, Shanghai, China; Cai, J., Shanghai Synyi Medical Technology Co., Ltd, Shanghai, China; Xu, W., Shanghai Synyi Medical Technology Co., Ltd, Shanghai, China; Zhang, S., Shanghai Tenth People's Hospital, Shanghai, China","Screening via low-dose Computer Tomography (CT) has been shown to reduce lung cancer mortality rates by at least 20%. However, the assessment of large numbers of CT scans by radiologists is cost intensive, and potentially produces varying and inconsistent results for differing radiologists (and also for temporally-separated assessments by the same radiologist). To overcome these challenges, computer aided diagnosis systems based on deep learning methods have proved effective in automatic detection and classification of lung cancer. Latterly, interest has focused on the full utilization of the 3D information in CT scans using 3D-CNNs and related approaches. However, such approaches do not intrinsically correlate size and shape information between slices. In this work, an innovative approach Multi-view Convolutional Recurrent Neural Network (MV-CRecNet) is proposed that exploits shape, size and cross-slice variations while learning to identify lung cancer nodules from CT scans. The multiple-views that are passed to the model ensure better generalization and the learning of robust features. We evaluate the proposed MV-CRecNet model on the reference Lung Image Database Consortium and Image Database Resource Initiative and Early Lung Cancer Action Program datasets; six evaluation metrics are applied to eleven comparison models for testing. Results demonstrate that proposed methodology outperforms all of the models against all of the evaluation metrics. © 2021 Elsevier B.V.",Machine learning; Risk assessment model; Venous thromboembolism (VTE),Decision support systems; Diagnosis; Forecasting; Hospitals; Image enhancement; Machine learning; Medical imaging; Risk assessment; Risk management; Turing machines; Decision supports; Initial assessment; Machine learning methods; Machine learning models; Medical intervention; Potentially fatal; Risk predictions; Venous thromboembolism; Predictive analytics; C reactive protein; D dimer; accuracy; activated partial thromboplastin time; adult; algorithm; Article; artificial neural network; body mass; cancer model; classification algorithm; cohort analysis; computer assisted tomography; data base; decision support system; decision tree; deep vein thrombosis; emergency ward; follow up; hospital patient; hospitalization; human; human experiment; learning; learning algorithm; length of stay; lung embolism; machine learning; mean arterial pressure; natural language processing; prothrombin time; quality control; receiver operating characteristic; risk assessment; risk factor; sample size; sensitivity and specificity; support vector machine; training; venous thromboembolism,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85114800202
"Pastor-Serrano O., Lathouwers D., Perkó Z.",A semi-supervised autoencoder framework for joint generation and classification of breathing,2021,Computer Methods and Programs in Biomedicine,209,,106312,,,3,10.1016/j.cmpb.2021.106312,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112415900&doi=10.1016%2fj.cmpb.2021.106312&partnerID=40&md5=1ae7bb01abd19d7a445bab702677f08b,"Delft University of Technology, Department of Radiation Science and Technology, Mekelweg 15, Delft, 2629JB, Netherlands","Pastor-Serrano, O., Delft University of Technology, Department of Radiation Science and Technology, Mekelweg 15, Delft, 2629JB, Netherlands; Lathouwers, D., Delft University of Technology, Department of Radiation Science and Technology, Mekelweg 15, Delft, 2629JB, Netherlands; Perkó, Z., Delft University of Technology, Department of Radiation Science and Technology, Mekelweg 15, Delft, 2629JB, Netherlands","Lung cancer is among the most common and deadliest cancers with a low 5-year survival rate. Timely diagnosis of lung cancer is, therefore, of paramount importance as it can save countless lives. In this regard, Computed Tomography (CT) scan is widely used for early detection of lung cancer, where human judgment is currently considered as the gold standard approach. Recently, there has been a surge of interest on development of automatic solutions via radiomics, as human-centered diagnosis is subject to inter-observer variability and is highly burdensome. Hand-crafted radiomics, serving as a radiologist assistant, requires fine annotations and pre-defined features. Deep learning radiomics solutions, however, have the promise of extracting the most useful features on their own in an end-to-end fashion without having access to the annotated boundaries. Among different deep learning models, Capsule Networks are proposed to overcome shortcomings of the Convolutional Neural Networks (CNNs) such as their inability to recognize detailed spatial relations. Capsule networks have so far shown satisfying performance in medical imaging problems. Capitalizing on their success, in this study, we propose a novel capsule network-based mixture of experts, referred to as the MIXCAPS. The proposed MIXCAPS architecture takes advantage of not only the capsule network's capabilities to handle small datasets, but also automatically splitting dataset through a convolutional gating network. MIXCAPS enables capsule network experts to specialize on different subsets of the data. Our results show that MIXCAPS outperforms a single capsule network, a single CNN, a mixture of CNNs, and an ensemble of capsule networks, with an average accuracy of 90.7%, average sensitivity of 89.5%, average specificity of 93.4% and average area under the curve of 0.956. Our experiments also show that there is a relation between the gate outputs and a couple of hand-crafted features, illustrating explainable nature of the proposed MIXCAPS. To further evaluate generalization capabilities of the proposed MIXCAPS architecture, additional experiments on a brain tumor dataset are performed showing potentials of MIXCAPS for detection of tumors related to other organs. © 2021 Elsevier Ltd",Breathing signals; Convolutional neural network; Deep learning; Probabilistic autoencoder; Respiratory motion; Semi-supervised learning,"Biomedical signal processing; Classification (of information); Computer aided diagnosis; Convolution; Deep learning; Neural networks; Patient treatment; Supervised learning; Autoencoders; Breathing signals; Convolutional neural network; Deep learning; Joint generations; Probabilistic autoencoder; Respiratory motions; Semi-supervised; Semi-supervised learning; Times series; Time series; adversarial autoencoder algorithm; Article; autoencoder; breathing mechanics; cancer radiotherapy; classification algorithm; classifier; clinical article; comparative study; convolutional neural network; deep learning; feed forward neural network; human; lung cancer; population model; semi supervised machine learning; signal processing; stereotactic radiosurgery; time series analysis; variational autoencoder algorithm; algorithm; computer assisted diagnosis; Algorithms; Diagnosis, Computer-Assisted; Humans; Neural Networks, Computer",Article,Final,"All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85112415900
"Fan J., Lee J., Lee Y.",A transfer learning architecture based on a support vector machine for histopathology image classification,2021,Applied Sciences (Switzerland),11,14,6380,,,7,10.3390/app11146380,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111938635&doi=10.3390%2fapp11146380&partnerID=40&md5=e2e3ca8ba8b54466ba222f41905f2526,"Graduate School of Nano IT Design Fusion, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Department of Materials Science and Engineering, Korea University, Seoul, 02841, South Korea","Fan, J., Graduate School of Nano IT Design Fusion, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Lee, J., Department of Materials Science and Engineering, Korea University, Seoul, 02841, South Korea; Lee, Y., Graduate School of Nano IT Design Fusion, Seoul National University of Science and Technology, Seoul, 01811, South Korea","Purpose: Lung cancer is the leading cause of cancer mortality in the US, responsible for more deaths than breast, prostate, colon and pancreas cancer combined and large population studies have indicated that low-dose computed tomography (CT) screening of the chest can significantly reduce this death rate. Recently, the usefulness of Deep Learning (DL) models for lung cancer risk assessment has been demonstrated. However, in many cases model performances are evaluated on small/medium size test sets, thus not providing strong model generalization and stability guarantees which are necessary for clinical adoption. In this work, our goal is to contribute towards clinical adoption by investigating a deep learning framework on larger and heterogeneous datasets while also comparing to state-of-the-art models. Methods: Three low-dose CT lung cancer screening datasets were used: National Lung Screening Trial (NLST, n = 3410), Lahey Hospital and Medical Center (LHMC, n = 3154) data, Kaggle competition data (from both stages, n = 1397 + 505) and the University of Chicago data (UCM, a subset of NLST, annotated by radiologists, n = 132). At the first stage, our framework employs a nodule detector; while in the second stage, we use both the image context around the nodules and nodule features as inputs to a neural network that estimates the malignancy risk for the entire CT scan. We trained our algorithm on a part of the NLST dataset, and validated it on the other datasets. Special care was taken to ensure there was no patient overlap between the train and validation sets. Results and conclusions: The proposed deep learning model is shown to: (a) generalize well across all three data sets, achieving AUC between 86% to 94%, with our external test-set (LHMC) being at least twice as large compared to other works; (b) have better performance than the widely accepted PanCan Risk Model, achieving 6 and 9% better AUC score in our two test sets; (c) have improved performance compared to the state-of-the-art represented by the winners of the Kaggle Data Science Bowl 2017 competition on lung cancer screening; (d) have comparable performance to radiologists in estimating cancer risk at a patient level. © 2021",Image classification; Support vector machine; Transfer learning,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85111938635
"Trajanovski S., Mavroeidis D., Swisher C.L., Gebre B.G., Veeling B.S., Wiemker R., Klinder T., Tahmasebi A., Regis S.M., Wald C., McKee B.J., Flacke S., MacMahon H., Pien H.",Towards radiologist-level cancer risk assessment in CT lung screening using deep learning,2021,Computerized Medical Imaging and Graphics,90,,101883,,,3,10.1016/j.compmedimag.2021.101883,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104756617&doi=10.1016%2fj.compmedimag.2021.101883&partnerID=40&md5=b6e43f3475630ba94170d8795685c2cd,"Philips Research, Eindhoven, 5656 AE, Netherlands; Human Longevity, Inc., San Diego, CA  92121, United States; Machine Learning lab, University of Amsterdam, 1090 GH Amsterdam and, Philips Research, Eindhoven, 5656 AE, Netherlands; Philips Research, Hamburg, 22335, Germany; Philips Research North America, Cambridge, MA  02141, United States; Lahey Hospital & Medical Center, Burlington, MA  01805, United States; Department of Radiology, University of Chicago, Chicago, IL  60637, United States","Trajanovski, S., Philips Research, Eindhoven, 5656 AE, Netherlands; Mavroeidis, D., Philips Research, Eindhoven, 5656 AE, Netherlands; Swisher, C.L., Human Longevity, Inc., San Diego, CA  92121, United States; Gebre, B.G., Philips Research, Eindhoven, 5656 AE, Netherlands; Veeling, B.S., Machine Learning lab, University of Amsterdam, 1090 GH Amsterdam and, Philips Research, Eindhoven, 5656 AE, Netherlands; Wiemker, R., Philips Research, Hamburg, 22335, Germany; Klinder, T., Philips Research, Hamburg, 22335, Germany; Tahmasebi, A., Philips Research North America, Cambridge, MA  02141, United States; Regis, S.M., Lahey Hospital & Medical Center, Burlington, MA  01805, United States; Wald, C., Lahey Hospital & Medical Center, Burlington, MA  01805, United States; McKee, B.J., Lahey Hospital & Medical Center, Burlington, MA  01805, United States; Flacke, S., Lahey Hospital & Medical Center, Burlington, MA  01805, United States; MacMahon, H., Department of Radiology, University of Chicago, Chicago, IL  60637, United States; Pien, H., Philips Research North America, Cambridge, MA  02141, United States","Chest radiography is one of the most common types of diagnostic radiology exams, which is critical for screening and diagnosis of many different thoracic diseases. Specialized algorithms have been developed to detect several specific pathologies such as lung nodules or lung cancer. However, accurately detecting the presence of multiple diseases from chest X-rays (CXRs) is still a challenging task. This paper presents a supervised multi-label classification framework based on deep convolutional neural networks (CNNs) for predicting the presence of 14 common thoracic diseases and observations. We tackle this problem by training state-of-the-art CNNs that exploit hierarchical dependencies among abnormality labels. We also propose to use the label smoothing technique for a better handling of uncertain samples, which occupy a significant portion of almost every CXR dataset. Our model is trained on over 200,000 CXRs of the recently released CheXpert dataset and achieves a mean area under the curve (AUC) of 0.940 in predicting 5 selected pathologies from the validation set. This is the highest AUC score yet reported to date. The proposed method is also evaluated on the independent test set of the CheXpert competition, which is composed of 500 CXR studies annotated by a panel of 5 experienced radiologists. The performance is on average better than 2.6 out of 3 other individual radiologists with a mean AUC of 0.930, which ranks first on the CheXpert leaderboard at the time of writing this paper. © 2021 Elsevier B.V.",Deep learning; Low-dose computed tomography screening; Lung cancer screening,"Biological organs; Computerized tomography; Data Science; Diagnosis; Diseases; Hospitals; Learning systems; Risk assessment; Risk perception; Cancer risk assessments; Heterogeneous datasets; Learning frameworks; Lung cancer risks; Lung cancer screening; Model generalization; Model performance; University of Chicago; Deep learning; adult; Article; cancer risk; cancer screening; controlled study; deep learning; family history; female; follow up; human; image quality; lung cancer; lung imaging reporting and data system; machine learning; major clinical study; male; middle aged; priority journal; risk assessment; sensitivity and specificity; support vector machine; x-ray computed tomography; diagnostic imaging; early cancer diagnosis; lung; lung tumor; radiologist; risk assessment; x-ray computed tomography; Deep Learning; Early Detection of Cancer; Humans; Lung; Lung Neoplasms; Male; Radiologists; Risk Assessment; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85104756617
"Pham H.H., Le T.T., Tran D.Q., Ngo D.T., Nguyen H.Q.",Interpreting chest X-rays via CNNs that exploit hierarchical disease dependencies and uncertainty labels,2021,Neurocomputing,437,,,186,194,19,10.1016/j.neucom.2020.03.127,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100402162&doi=10.1016%2fj.neucom.2020.03.127&partnerID=40&md5=7f8c6797ec98f812971834223dc27da9,"Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam; College of Engineering and Computer Science, VinUniversity, Vinhomes Ocean Park, Gia Lam District, Hanoi, Viet Nam","Pham, H.H., Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam, College of Engineering and Computer Science, VinUniversity, Vinhomes Ocean Park, Gia Lam District, Hanoi, Viet Nam; Le, T.T., Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam; Tran, D.Q., Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam; Ngo, D.T., Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam; Nguyen, H.Q., Department of Medical Imaging, Vingroup Big Data Institute (VinBigdata), Minh Khai street, Hai Ba Trung, Hanoi, Viet Nam","Lung cancer is the deadliest type of cancer worldwide and late detection is the major factor for the low survival rate of patients. Low dose computed tomography has been suggested as a potential screening tool but manual screening is costly and time-consuming. This has fuelled the development of automatic methods for the detection, segmentation and characterisation of pulmonary nodules. In spite of promising results, the application of automatic methods to clinical routine is not straightforward and only a limited number of studies have addressed the problem in a holistic way. With the goal of advancing the state of the art, the Lung Nodule Database (LNDb) Challenge on automatic lung cancer patient management was organized. The LNDb Challenge addressed lung nodule detection, segmentation and characterization as well as prediction of patient follow-up according to the 2017 Fleischner society pulmonary nodule guidelines. 294 CT scans were thus collected retrospectively at the Centro Hospitalar e Universitrio de So Joo in Porto, Portugal and each CT was annotated by at least one radiologist. Annotations comprised nodule centroids, segmentations and subjective characterization. 58 CTs and the corresponding annotations were withheld as a separate test set. A total of 947 users registered for the challenge and 11 successful submissions for at least one of the sub-challenges were received. For patient follow-up prediction, a maximum quadratic weighted Cohen's kappa of 0.580 was obtained. In terms of nodule detection, a sensitivity below 0.4 (and 0.7) at 1 false positive per scan was obtained for nodules identified by at least one (and two) radiologist(s). For nodule segmentation, a maximum Jaccard score of 0.567 was obtained, surpassing the interobserver variability. In terms of nodule texture characterization, a maximum quadratic weighted Cohen's kappa of 0.733 was obtained, with part solid nodules being particularly challenging to classify correctly. Detailed analysis of the proposed methods and the differences in performance allow to identify the major challenges remaining and future directions - data collection, augmentation/generation and evaluation of under-represented classes, the incorporation of scan-level information for better decision-making and the development of tools and challenges with clinical-oriented goals. The LNDb Challenge and associated data remain publicly available so that future methods can be tested and benchmarked, promoting the development of new algorithms in lung cancer medical image analysis and patient follow-up recommendation. © 2021 Elsevier B.V.",Chest X-ray; CheXpert; Hierarchical learning; Label dependency; Label smoothing; Multi-label classification; Uncertainty label,Biological organs; Classification (of information); Convolutional neural networks; Deep neural networks; Diagnostic radiography; Pathology; Area under the curves; Chest radiography; Chest x-rays; Diagnostic radiology; Lung nodule; Multi label classification; Smoothing techniques; State of the art; X rays; area under the curve; Article; CheXpert database; conceptual framework; controlled study; convolutional neural network; data base; deep learning; diagnostic imaging; disease classification; human; machine learning; major clinical study; mathematical analysis; pleura effusion; recurrent neural network; thorax disease; thorax radiography,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85100402162
"Ibrahim D.M., Elshennawy N.M., Sarhan A.M.","Deep-chest: Multi-classification deep learning model for diagnosing COVID-19, pneumonia, and lung cancer chest diseases",2021,Computers in Biology and Medicine,132,,104348,,,46,10.1016/j.compbiomed.2021.104348,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103317465&doi=10.1016%2fj.compbiomed.2021.104348&partnerID=40&md5=ab31b04575d754e39f051d33a314b288,"Department of Computers and Control Engineering, Faculty of Engineering, Tanta University, Tanta, 31733, Egypt; Department of Information Technology, College of Computer, Qassim University, Buraydah, 51452, Saudi Arabia","Ibrahim, D.M., Department of Computers and Control Engineering, Faculty of Engineering, Tanta University, Tanta, 31733, Egypt, Department of Information Technology, College of Computer, Qassim University, Buraydah, 51452, Saudi Arabia; Elshennawy, N.M., Department of Computers and Control Engineering, Faculty of Engineering, Tanta University, Tanta, 31733, Egypt; Sarhan, A.M., Department of Computers and Control Engineering, Faculty of Engineering, Tanta University, Tanta, 31733, Egypt","Automatic pulmonary nodules classification is significant for early diagnosis of lung cancers. Recently, deep learning techniques have enabled remarkable progress in this field. However, these deep models are typically of high computational complexity and work in a black-box manner. To combat these challenges, in this work, we aim to build an efficient and (partially) explainable classification model. Specially, we use neural architecture search (NAS) to automatically search 3D network architectures with excellent accuracy/speed trade-off. Besides, we use the convolutional block attention module (CBAM) in the networks, which helps us understand the reasoning process. During training, we use A-Softmax loss to learn angularly discriminative representations. In the inference stage, we employ an ensemble of diverse neural networks to improve the prediction accuracy and robustness. We conduct extensive experiments on the LIDC-IDRI database. Compared with previous state-of-the-art, our model shows highly comparable performance by using less than 1/40 parameters. Besides, empirical study shows that the reasoning process of learned networks is in conformity with physicians’ diagnosis. Related code and results have been released at: https://github.com/fei-hdu/NAS-Lung. © 2021",Chest X-ray; COVID-19 detection; CT images; Deep learning; Lung cancer; Pneumonia,Biological organs; Classification (of information); Computerized tomography; Deep learning; Diagnosis; Viruses; Chest X-ray; Chest x-rays; CNN models; Computed tomography images; COVID-19 detection; Deep learning; Learning models; Lung Cancer; Multi-classification; Pneumonia; Diseases; area under the curve; Article; cancer recurrence; cancer staging; cellular neural network; computer assisted tomography; coronavirus disease 2019; correlation coefficient; deep learning; human; information processing; lung cancer; pneumonia; predictive value; priority journal; residual neural network; thorax radiography; algorithm; diagnostic imaging; early cancer diagnosis; lung tumor; pneumonia; Algorithms; COVID-19; Deep Learning; Early Detection of Cancer; Humans; Lung Neoplasms; Pneumonia; SARS-CoV-2,Article,Final,"All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85103317465
"Jiang H., Shen F., Gao F., Han W.","Learning efficient, explainable and discriminative representations for pulmonary nodules classification",2021,Pattern Recognition,113,,107825,,,16,10.1016/j.patcog.2021.107825,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100008806&doi=10.1016%2fj.patcog.2021.107825&partnerID=40&md5=7f67a74080c536cb7b7ed98194f26571,"Pulmonary and Critical Care Medicine, Sir Run Run Shaw Hospital, School of Medicine, Zhejiang University, Hangzhou, 310020, China; Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China; Department of Medical Oncology, Sir Run Run Shaw Hospital, College of Medicine, Zhejiang University, Hangzhou, Zhejiang  310016, China","Jiang, H., Pulmonary and Critical Care Medicine, Sir Run Run Shaw Hospital, School of Medicine, Zhejiang University, Hangzhou, 310020, China; Shen, F., Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China; Gao, F., Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China; Han, W., Department of Medical Oncology, Sir Run Run Shaw Hospital, College of Medicine, Zhejiang University, Hangzhou, Zhejiang  310016, China","When dealing with computed tomography volume data, the accurate segmentation of lung nodules is of great importance to lung cancer analysis and diagnosis, being a vital part of computer-aided diagnosis systems. However, due to the variety of lung nodules and the similarity of visual characteristics for nodules and their surroundings, robust segmentation of nodules becomes a challenging problem. A segmentation algorithm based on the fast marching method is proposed that separates the image into regions with similar features, which are then merged by combining regions growing with k-means. An evaluation was performed with two distinct methods (objective and subjective) that were applied on two different datasets, containing simulation data generated for this study and real patient data, respectively. The objective experimental results show that the proposed technique can accurately segment nodules, especially in solid cases, given the mean Dice scores of 0.933 and 0.901 for round and irregular nodules. For non-solid and cavitary nodules the performance dropped—0.799 and 0.614 mean Dice scores, respectively. The proposed method was compared to active contour models and to two modern deep learning networks. It reached better overall accuracy than active contour models, having comparable results to DBResNet but lesser accuracy than 3D-UNet. The results show promise for the proposed method in computer-aided diagnosis applications. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Computer-aided diagnoses; Convolutional block attention module; Convolutional neural network; Neural architecture search; Pulmonary nodule classification,Computer aided diagnosis; Deep learning; Economic and social effects; Classification models; Empirical studies; Inference stages; Learning techniques; Neural architectures; Prediction accuracy; Pulmonary nodules; Reasoning process; Network architecture,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85100008806
"Dong H., Suárez-Paniagua V., Whiteley W., Wu H.",Explainable automated coding of clinical notes using hierarchical label-wise attention networks and label embedding initialisation,2021,Journal of Biomedical Informatics,116,,103728,,,6,10.1016/j.jbi.2021.103728,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104899646&doi=10.1016%2fj.jbi.2021.103728&partnerID=40&md5=dc04f50538a0efd0e47e20dc5b277284,"Centre for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, Edinburgh, United Kingdom; Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom; Institute of Health Informatics, University College London, London, United Kingdom; Health Data Research UK, London, United Kingdom","Dong, H., Centre for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, Edinburgh, United Kingdom, Health Data Research UK, London, United Kingdom; Suárez-Paniagua, V., Centre for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, Edinburgh, United Kingdom, Health Data Research UK, London, United Kingdom; Whiteley, W., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom, Health Data Research UK, London, United Kingdom; Wu, H., Institute of Health Informatics, University College London, London, United Kingdom, Health Data Research UK, London, United Kingdom","Classifying ground-glass lung nodules (GGNs) into atypical adenomatous hyperplasia (AAH), adenocarcinoma in situ (AIS), minimally invasive adenocarcinoma (MIA), and invasive adenocarcinoma (IAC) on diagnostic CT images is important to evaluate the therapy options for lung cancer patients. In this paper, we propose a joint deep learning model where the segmentation can better facilitate the classification of pulmonary GGNs. Based on our observation that masking the nodule to train the model results in better lesion classification, we propose to build a cascade architecture with both segmentation and classification networks. The segmentation model works as a trainable preprocessing module to provide the classification-guided ‘attention’ weight map to the raw CT data to achieve better diagnosis performance. We evaluate our proposed model and compare with other baseline models for 4 clinically significant nodule classification tasks, defined by a combination of pathology types, using 4 classification metrics: Accuracy, Average F1 Score, Matthews Correlation Coefficient (MCC), and Area Under the Receiver Operating Characteristic Curve (AUC). Experimental results show that the proposed method outperforms other baseline models on all the diagnostic classification tasks. © 2020 Elsevier Ltd",Attention Mechanisms; Automated medical coding; Deep learning; Explainability; Label correlation; Multi-label classification; Natural Language Processing,"Automation; Classification (of information); Convolutional neural networks; Diagnosis; Embeddings; Forecasting; Hospitals; Network coding; Predictive analytics; Shielding; Attention mechanisms; Clinical practices; Complex correlation; Comprehensive model; Multi label classification; National health services; Recurrent neural network (RNNs); Vector representations; Recurrent neural networks; adult; Article; artificial neural network; atrial fibrillation; automation; coding; congestive heart failure; controlled study; convolutional neural network; coronavirus disease 2019; deep learning; entropy; essential hypertension; false positive result; female; hierarchical label wise attention network; high risk patient; hospital discharge; human; hypercalcemia; ICD-9; infection risk; lung cancer; major clinical study; male; measurement precision; neutropenia; pandemic; prediction; process optimization; pulmonary hypertension; receiver operating characteristic; recurrent neural network; coding; electronic health record; epidemiology; medical informatics; procedures; United Kingdom; Clinical Coding; COVID-19; Deep Learning; Electronic Health Records; Humans; Medical Informatics; Neural Networks, Computer; Pandemics; SARS-CoV-2; United Kingdom",Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85104899646
"Savic M., Ma Y., Ramponi G., Du W., Peng Y.",Lung nodule segmentation with a region-based fast marching method,2021,Sensors,21,5,1908,1,32,7,10.3390/s21051908,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102103493&doi=10.3390%2fs21051908&partnerID=40&md5=72af0c77b179436744db6097bdf0fa02,"Department of Engineering and Architecture, University of Trieste, Piazzale Europa 1, Trieste, 34127, Italy; Information and Human Science, Kyoto Institute of Technology, Hachigami-cho, Sakyo-ku, Kyoto, 6068585, Japan; Tianjin Chest Hospital, Tianjin, 300051, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, 100044, China","Savic, M., Department of Engineering and Architecture, University of Trieste, Piazzale Europa 1, Trieste, 34127, Italy, Information and Human Science, Kyoto Institute of Technology, Hachigami-cho, Sakyo-ku, Kyoto, 6068585, Japan; Ma, Y., Tianjin Chest Hospital, Tianjin, 300051, China; Ramponi, G., Department of Engineering and Architecture, University of Trieste, Piazzale Europa 1, Trieste, 34127, Italy; Du, W., Information and Human Science, Kyoto Institute of Technology, Hachigami-cho, Sakyo-ku, Kyoto, 6068585, Japan; Peng, Y., School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, 100044, China","Spiculations are important predictors of lung cancer malignancy, which are spikes on the surface of the pulmonary nodules. In this study, we proposed an interpretable and parameter-free technique to quantify the spiculation using area distortion metric obtained by the conformal (angle-preserving) spherical parameterization. We exploit the insight that for an angle-preserved spherical mapping of a given nodule, the corresponding negative area distortion precisely characterizes the spiculations on that nodule. We introduced novel spiculation scores based on the area distortion metric and spiculation measures. We also semi-automatically segment lung nodule (for reproducibility) as well as vessel and wall attachment to differentiate the real spiculations from lobulation and attachment. A simple pathological malignancy prediction model is also introduced. We used the publicly-available LIDC-IDRI dataset pathologists (strong-label) and radiologists (weak-label) ratings to train and test radiomics models containing this feature, and then externally validate the models. We achieved AUC = 0.80 and 0.76, respectively, with the models trained on the 811 weakly-labeled LIDC datasets and tested on the 72 strongly-labeled LIDC and 73 LUNGx datasets; the previous best model for LUNGx had AUC = 0.68. The number-of-spiculations feature was found to be highly correlated (Spearman's rank correlation coefficient ρ=0.44) with the radiologists’ spiculation score. We developed a reproducible and interpretable, parameter-free technique for quantifying spiculations on nodules. The spiculation quantification measures was then applied to the radiomics framework for pathological malignancy prediction with reproducible semi-automatic segmentation of nodule. Using our interpretable features (size, attachment, spiculation, lobulation), we were able to achieve higher performance than previous models. In the future, we will exhaustively test our model for lung cancer screening in the clinic. © 2020 Elsevier B.V.",Computed tomography; Fast marching method; Lung nodules; Lung phantom; Segmentation,Biological organs; Computer aided analysis; Computer aided diagnosis; Computerized tomography; Deep learning; Hospital data processing; K-means clustering; Learning systems; Active contour model; Computer aided diagnosis systems; Fast marching methods; Learning network; Lung nodule segmentation; Overall accuracies; Robust segmentation; Segmentation algorithms; Image segmentation,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85102103493
"Wang D., Zhang T., Li M., Bueno R., Jayender J.",3D deep learning based classification of pulmonary ground glass opacity nodules with automatic segmentation,2021,Computerized Medical Imaging and Graphics,88,,101814,,,7,10.1016/j.compmedimag.2020.101814,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099627807&doi=10.1016%2fj.compmedimag.2020.101814&partnerID=40&md5=6cb913f3e29165c10a218ef31859c181,"Department of Automation, Tsinghua University, Beijing, 100084, China; Department of Radiology, Brigham and Women's Hospital, Boston, 02115, United States; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, 100084, China; Department of Radiology, Huadong Hospital affiliated to Fudan University, Shanghai, 200040, China; Department of Thoracic Surgery, Brigham and Women's Hospital, Boston, 02115, United States; Harvard Medical School, Boston, 02115, United States","Wang, D., Department of Automation, Tsinghua University, Beijing, 100084, China, Department of Radiology, Brigham and Women's Hospital, Boston, 02115, United States; Zhang, T., Department of Automation, Tsinghua University, Beijing, 100084, China, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, 100084, China; Li, M., Department of Radiology, Huadong Hospital affiliated to Fudan University, Shanghai, 200040, China; Bueno, R., Department of Thoracic Surgery, Brigham and Women's Hospital, Boston, 02115, United States, Harvard Medical School, Boston, 02115, United States; Jayender, J., Department of Radiology, Brigham and Women's Hospital, Boston, 02115, United States, Harvard Medical School, Boston, 02115, United States","Deep learning is becoming an indispensable tool for various tasks in science and engineering. A critical step in constructing a reliable deep learning model is the selection of a loss function, which measures the discrepancy between the network prediction and the ground truth. While a variety of loss functions have been proposed in the literature, a truly optimal loss function that maximally utilizes the capacity of neural networks for deep learning-based decision-making has yet to be established. Here, we devise a generalized loss function with functional parameters determined adaptively during model training to provide a versatile framework for optimal neural network-based decision-making in small target segmentation. The method is showcased by more accurate detection and segmentation of lung and liver cancer tumors as compared with the current state-of-The-Art. The proposed formalism opens new opportunities for numerous practical applications such as disease diagnosis, treatment planning, and prognosis. © 1982-2012 IEEE.",Automatic segmentation; Classification; Deep learning; Joint training; Pulmonary ground glass opacity nodules,"Automatic identification; Biological organs; Classification (of information); Computer aided diagnosis; Computerized tomography; Glass; Patient treatment; Automatic segmentations; Cascade architecture; Classification networks; Correlation coefficient; Diagnosis performance; Lesion classification; Preprocessing modules; Receiver operating characteristic curves; Deep learning; Article; classification algorithm; comparative study; correlation coefficient; deep learning; diagnostic value; disease classification; evaluation study; ground glass opacity; image segmentation; lung nodule; priority journal; receiver operating characteristic; segmentation algorithm; three-dimensional imaging; adenocarcinoma; diagnostic imaging; human; lung tumor; retrospective study; tumor invasion; x-ray computed tomography; Adenocarcinoma; Deep Learning; Humans; Lung Neoplasms; Neoplasm Invasiveness; Retrospective Studies; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85099627807
"Masud M., Sikder N., Nahid A.-A., Bairagi A.K., Alzain M.A.",A machine learning approach to diagnosing lung and colon cancer using a deep learning‐based classification framework,2021,Sensors (Switzerland),21,3,748,1,21,29,10.3390/s21030748,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099707000&doi=10.3390%2fs21030748&partnerID=40&md5=063dd739168ecb0da0c76a9c778f2f05,"Department of Computer Science, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Computer Science and Engineering Discipline, Khulna University, Khulna, 9208, Bangladesh; Electronics and Communication Engineering Discipline, Khulna University, Khulna, 9208, Bangladesh; Department of Information Technology, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia","Masud, M., Department of Computer Science, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Sikder, N., Computer Science and Engineering Discipline, Khulna University, Khulna, 9208, Bangladesh; Nahid, A.-A., Electronics and Communication Engineering Discipline, Khulna University, Khulna, 9208, Bangladesh; Bairagi, A.K., Computer Science and Engineering Discipline, Khulna University, Khulna, 9208, Bangladesh; Alzain, M.A., Department of Information Technology, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia","Accurate segmentation of lung cancer in pathology slides is a critical step in improving patient care. We proposed the ACDC@LungHP (Automatic Cancer Detection and Classification in Whole-slide Lung Histopathology) challenge for evaluating different computer-aided diagnosis (CADs) methods on the automatic diagnosis of lung cancer. The ACDC@LungHP 2019 focused on segmentation (pixel-wise detection) of cancer tissue in whole slide imaging (WSI), using an annotated dataset of 150 training images and 50 test images from 200 patients. This paper reviews this challenge and summarizes the top 10 submitted methods for lung cancer segmentation. All methods were evaluated using metrics using the precision, accuracy, sensitivity, specificity, and DICE coefficient (DC). The DC ranged from 0.7354pm0.1149 to 0.8372pm0.0858. The DC of the best method was close to the inter-observer agreement (0.8398pm0.0890). All methods were based on deep learning and categorized into two groups: multi-model method and single model method. In general, multi-model methods were significantly better (p< 0.01) than single model methods, with mean DC of 0.7966 and 0.7544, respectively. Deep learning based methods could potentially help pathologists find suspicious regions for further analysis of lung cancer in WSI. © 2013 IEEE.",Colon cancer detection; Deep learning; Histopathological image analysis; Image classification; Lung cancer detection,Biological organs; Diagnosis; Diseases; Histology; Image processing; Tissue; Turing machines; Cancer diagnosis; Classification framework; Digital image processing (DIP); Histopathological images; Machine learning approaches; Medical professionals; Novel diagnostics; Reliable systems; Deep learning; artificial intelligence; colon tumor; human; lung; lung tumor; machine learning; Artificial Intelligence; Colonic Neoplasms; Deep Learning; Humans; Lung; Lung Neoplasms; Machine Learning,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85099707000
"Lu C., Koyuncu C., Corredor G., Prasanna P., Leo P., Wang X., Janowczyk A., Bera K., Lewis J., Jr., Velcheti V., Madabhushi A.",Feature-driven local cell graph (FLocK): New computational pathology-based descriptors for prognosis of lung cancer and HPV status of oropharyngeal cancers,2021,Medical Image Analysis,68,,101903,,,15,10.1016/j.media.2020.101903,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098464999&doi=10.1016%2fj.media.2020.101903&partnerID=40&md5=c0f21cc36ea7e950839d7f1a6fbb275c,"Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Department of Biomedical Informatics, Stony Brook University, New York, NY, United States; Precision Oncology Center, Lausanne University Hospital, Switzerland; Department of Pathology, Microbiology, and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States; Perlmutter Cancer Center, New York UniversityNY, United States; Louis Stokes Cleveland Veterans Administration Medical Center, Cleveland, OH, United States","Lu, C., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Koyuncu, C., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Corredor, G., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Prasanna, P., Department of Biomedical Informatics, Stony Brook University, New York, NY, United States; Leo, P., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Wang, X., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Janowczyk, A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States, Precision Oncology Center, Lausanne University Hospital, Switzerland; Bera, K., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Lewis, J., Jr., Department of Pathology, Microbiology, and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States; Velcheti, V., Perlmutter Cancer Center, New York UniversityNY, United States; Madabhushi, A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States, Louis Stokes Cleveland Veterans Administration Medical Center, Cleveland, OH, United States","Pulmonary cancer is one of the most dangerous cancers with a high incidence and mortality. An early accurate diagnosis and treatment of pulmonary cancer can observably increase the survival rates, where computer-aided diagnosis systems can largely improve the efficiency of radiologists. In this article, we propose a deep automated lung nodule diagnosis system based on three-dimensional convolutional neural network (3D-CNN) and support vector machine (SVM) with multiple kernel learning (MKL) algorithms. The system not only explores the computed tomography (CT) scans, but also the clinical information of patients like age, smoking history and cancer history. To extract deeper image features, a 34-layers 3D Residual Network (3D-ResNet) is employed. Heterogeneous features including the extracted image features and the clinical data are learned with MKL. The experimental results prove the effectiveness of the proposed image feature extractor and the combination of heterogeneous features in the task of lung nodule diagnosis. © 1983-2012 IEEE.",Feature extraction; Histology image analysis; Lung cancer; Oropharyngeal cancer,"Biological organs; Clustering algorithms; Cytology; Deep learning; Diagnosis; Diseases; Graphic methods; Textures; Tumors; 10-fold cross-validation; Human papillomavirus; Learning classifiers; Linear discriminant classifier; Non small cell lung cancer; Oropharyngeal cancer; Spatial arrangements; Squamous cell carcinoma; Cells; area under the curve; Article; cancer prognosis; cancer survival; computer analysis; controlled study; cross validation; deep learning; feature driven local cell graph; feature extraction; human; long term survival; major clinical study; measurement accuracy; metric system; morphometry; non small cell lung cancer; nuclear shape; oropharynx squamous cell carcinoma; overall survival; priority journal; sensitivity and specificity; short term survival; treatment outcome; Wart virus; Alphapapillomavirus; diagnostic imaging; lung tumor; oropharynx tumor; Papillomaviridae; papillomavirus infection; prognosis; Alphapapillomavirus; Carcinoma, Non-Small-Cell Lung; Humans; Lung Neoplasms; Oropharyngeal Neoplasms; Papillomaviridae; Papillomavirus Infections; Prognosis",Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85098464999
"Pabón O.S., Torrente M., Provencio M., Rodríguez-Gonzalez A., Menasalvas E.",Integrating speculation detection and deep learning to extract lung cancer diagnosis from clinical notes,2021,Applied Sciences (Switzerland),11,2,865,1,21,4,10.3390/app11020865,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099855164&doi=10.3390%2fapp11020865&partnerID=40&md5=322febd63241cd49d0b05fa489f49517,"Centro de Tecnología Biomédica, Universidad Politécnica de Madrid, Pozuelo de Alarcón, Madrid, 28223, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, 28660, Spain; Hospital Universitario Puerta de Hierro, Majadahonda, Madrid, 28222, Spain","Pabón, O.S., Centro de Tecnología Biomédica, Universidad Politécnica de Madrid, Pozuelo de Alarcón, Madrid, 28223, Spain, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, 28660, Spain; Torrente, M., Hospital Universitario Puerta de Hierro, Majadahonda, Madrid, 28222, Spain; Provencio, M., Hospital Universitario Puerta de Hierro, Majadahonda, Madrid, 28222, Spain; Rodríguez-Gonzalez, A., Centro de Tecnología Biomédica, Universidad Politécnica de Madrid, Pozuelo de Alarcón, Madrid, 28223, Spain, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, 28660, Spain; Menasalvas, E., Centro de Tecnología Biomédica, Universidad Politécnica de Madrid, Pozuelo de Alarcón, Madrid, 28223, Spain, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, 28660, Spain","Cancer is the leading cause of death worldwide. Lung cancer, especially, caused the most death in 2018 according to the World Health Organization. Early diagnosis and treatment can considerably reduce mortality. To provide an efficient diagnosis, deep learning is overtaking conventional machine learning techniques and is increasingly being used in computer-aided design systems. However, a sparse medical data set and network parameter tuning process cause network training difficulty and cost longer experimental time. In the present study, the generative adversarial network was proposed to generate computed tomography images of lung tumors for alleviating the problem of sparse data. Furthermore, a parameter optimization method was proposed not only to improve the accuracy of lung tumor classification, but also reduce the experimental time. The experimental results revealed that the average accuracy can reach 99.86% after image augmentation and parameter optimization. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Diagnosis extraction; Information extraction; Lung cancer; Natural Language Processing (NLP); Negation detection; Speculation detection,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85099855164
"Jang H.-J., Song I.H., Lee S.H.",Generalizability of deep learning system for the pathologic diagnosis of various cancers,2021,Applied Sciences (Switzerland),11,2,808,1,11,6,10.3390/app11020808,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099822099&doi=10.3390%2fapp11020808&partnerID=40&md5=55ba8f9aa36ad029ae6abc0ab2be9022,"Catholic Big Data Integration Center, Department of Physiology, College of Medicine, The Catholic University of Korea, 222 Banpodae-ro, Seocho-gu, Seoul, 06591, South Korea; Department of Hospital Pathology, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, 222 Banpodae-ro, Seocho-gu, Seoul, 06591, South Korea","Jang, H.-J., Catholic Big Data Integration Center, Department of Physiology, College of Medicine, The Catholic University of Korea, 222 Banpodae-ro, Seocho-gu, Seoul, 06591, South Korea; Song, I.H., Department of Hospital Pathology, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, 222 Banpodae-ro, Seocho-gu, Seoul, 06591, South Korea; Lee, S.H., Department of Hospital Pathology, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, 222 Banpodae-ro, Seocho-gu, Seoul, 06591, South Korea","Lung cancer has one of the highest cancer mortality rates in the world and threatens people’s health. Timely and accurate diagnosis can greatly reduce the number of deaths. Therefore, an accurate diagnosis system is extremely important. The existing methods have achieved significant performances on lung cancer diagnosis, but they are insufficient in fine-grained representations. In this paper, we propose a novel attentive method to differentiate malignant and benign pulmonary nodules. Firstly, the residual attention network (RAN) and squeeze-and-excitation network (SEN) were utilized to extract spatial and contextual features. Secondly, a novel multi-scale attention network (MSAN) was proposed to capture multi-scale attention features automatically, and the MSAN integrated the advantages of the spatial attention mechanism and contextual attention mechanism, which are very important for capturing the salient features of nodules. Finally, the gradient boosting machine (GBM) algorithm was used to differentiate malignant and benign nodules. We conducted a series of experiments on the Lung Image Database Consortium image collection (LIDC-IDRI) database, achieving an accuracy of 91.9%, a sensitivity of 91.3%, a false positive rate of 8.0%, and an F1-score of 91.0%. The experimental results demonstrate that our proposed method outperforms the state-of-the-art methods with respect to accuracy, false positive rate, and F1-Score. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Computational pathology; Computer-aided diagnosis; Convolutional neural network; Digital pathology,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85099822099
"Lin C.-H., Lin C.-J., Li Y.-C., Wang S.-H.",Using generative adversarial networks and parameter optimization of convolutional neural networks for lung tumor classification,2021,Applied Sciences (Switzerland),11,2,480,1,17,6,10.3390/app11020480,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099218394&doi=10.3390%2fapp11020480&partnerID=40&md5=bad116c59b9eda039eb1e84949793af1,"Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, 701, Taiwan; Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, 411, Taiwan; College of Intelligence, National Taichung University of Science and Technology, Taichung, 404, Taiwan; Intelligent Manufacturing Research Center, National Cheng Kung University, Tainan, 701, Taiwan","Lin, C.-H., Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, 701, Taiwan; Lin, C.-J., Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, 411, Taiwan, College of Intelligence, National Taichung University of Science and Technology, Taichung, 404, Taiwan; Li, Y.-C., Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, 411, Taiwan; Wang, S.-H., Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, 701, Taiwan, Intelligent Manufacturing Research Center, National Cheng Kung University, Tainan, 701, Taiwan","Chest imaging diagnostics is crucial in the medical area due to many serious lung diseases like cancers and nodules and particularly with the current pandemic of Covid-19. Machine learning approaches yield prominent results toward the task of diagnosis. Recently, deep learning methods are utilized and recommended by many studies in this domain. The research aims to critically examine the newest lung disease detection procedures using deep learning algorithms that use X-ray and CT scan datasets. Here, the most recent studies in this area (2015-2021) have been reviewed and summarized to provide an overview of the most appropriate methods that should be used or developed in future works, what limitations should be considered, and at what level these techniques help physicians in identifying the disease with better accuracy. The lack of various standard datasets, the huge training set, the high dimensionality of data, and the independence of features have been the main limitations based on the literature. However, different architectures of deep learning are used by many researchers but, Convolutional Neural Networks (CNN) are still state-of-art techniques in dealing with image datasets. © 2021. All Rights Reserved.",Convolutional neural network; Generative adversarial network; Image augmentation; Lung cancer; Parameter optimization,,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85099218394
"Xia K., Chi J., Gao Y., Jiang Y., Wu C.",Adaptive aggregated attention network for pulmonary nodule classification,2021,Applied Sciences (Switzerland),11,2,610,1,15,4,10.3390/app11020610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099212062&doi=10.3390%2fapp11020610&partnerID=40&md5=227ccdadd43663f60e8693d479a2a713,"Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China","Xia, K., Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China; Chi, J., Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China; Gao, Y., Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China; Jiang, Y., Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China; Wu, C., Faculty of Robot Science and Engineering, Northeastern University, No. 195, Chuangxin Road, Shenyang, 110169, China","Early pulmonary nodule detection is very important in lung cancer diagnosis and screening. Most state-of-the-art lung nodule detection models are based on Faster Region-based Convolutional Neural Network (Faster R-CNN) due to its superior performance. However, this object detection approach faces difficulties with the variety of nodule sizes in training datasets. In this paper, we propose a novel Computer-Aided Detection (CAD) system based on Faster R-CNN model with adaptive anchor box for lung nodule detection. Our method employs ground-truth nodule sizes in the training dataset to generate adaptive anchor box sizes of Faster R-CNN. Learned anchors are used as hyper-parameter to boost Faster R-CNN's detection performance. A residual convolutional neural network is proposed to reduce false positives from Faster R-CNN's output. Our method is trained and tested on the largest publicly available LUNA16 dataset. Experiments show that our proposed system achieves a high sensitivity of 95.64% at 1.72 false positives per scan, and a Competition Performance Metric (CPM) score of 88.2%, which outperforms other recent state-of-the-art detection methods. The false positive reduction network achieves a sensitivity of 93.8%, specificity of 97.6% and accuracy of 95.7%. An additional evaluation on a completely independent SPIE-AAPM dataset demonstrates the generalization of our proposed model with 89.3% sensitivity. © 2013 IEEE.",3D dual path network; Attention network; Deep learning; Lung cancer diagnosis,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85099212062
"Saturi R., Premchand P.",Multi-Objective Feature Selection Method by Using ACO with PSO Algorithm for Breast Cancer Detection,2021,International Journal of Intelligent Engineering and Systems,14,5,,359,368,1,10.22266/ijies2021.1031.32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114715180&doi=10.22266%2fijies2021.1031.32&partnerID=40&md5=b07665aeaed5349d31030a4657a13613,"Department of Computer Science and Engineering, University College of Engineering, Osmania University, Hyderabad, India","Saturi, R., Department of Computer Science and Engineering, University College of Engineering, Osmania University, Hyderabad, India; Premchand, P., Department of Computer Science and Engineering, University College of Engineering, Osmania University, Hyderabad, India","The Pulmonary nodule indicates the presence of lung cancer. The deep convolutional neural networks (DCNNs) have been widely used to classify the pulmonary nodule as benign or malignant. However, an individual learner usually performs unsatisfactorily due to limited response space, incorrect selection of hypothesis space, or falling into local minimums. To investigate these issues, we propose ensemble learners fusion techniques based on averaging of prediction score and maximum vote score (MAX-VOTE). First, the support vector machine (SVM) and AdaBoostM2 machine learning algorithms are trained on the deep features from DCNNs. The results of both classifiers are fused separately based on averaging of the prediction score. Secondly, the feature fusion technique is developed by fusing the feature of three DCNNs (AlexNet, VGG-16 and VGG-19) through predefined rules. After that, the SVM and AdaBoostM2 are trained on fused features independently to build ensemble learners by fusing the multiple DCNN learners. The predictions of all DCNN learners are fused based on the MAX-VOTE. The results show that the ensemble learners based MAX-VOTE technique yields better performance out of twelve single learners for binary class classification of pulmonary nodules. The proposed fusion techniques are also tested for multi-class classification problem. The SVM based feature fusion technique performs better as compared to all the implemented and the state-of-the-art techniques. The achieved maximum accuracy, AUC and specificity scores are 96.89%±0.25, 99.21%±0.10 and 97.70%±0.21, respectively. © 2013 IEEE.",Ant colony optimization; Breast cancer; Computer-aided-diagnosis; Convolutional neural network; Histogram of gradients,,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85114715180
"Siddalingappa R., Kanagaraj S.",Anomaly Detection on Medical Images using Autoencoder and Convolutional Neural Network,2021,International Journal of Advanced Computer Science and Applications,12,7,,148,156,2,10.14569/IJACSA.2021.0120717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112244855&doi=10.14569%2fIJACSA.2021.0120717&partnerID=40&md5=246bca0bec4d7b7ee1cfaaf40b65bdc1,"Department of Computational and Data Science, Indian Institute of Science, C V Raman Road, Bangalore, 560012, India","Siddalingappa, R., Department of Computational and Data Science, Indian Institute of Science, C V Raman Road, Bangalore, 560012, India; Kanagaraj, S., Department of Computational and Data Science, Indian Institute of Science, C V Raman Road, Bangalore, 560012, India","Lung cancer causes the most cancer deaths worldwide and has one of the lowest five-year survival rates of all cancer types. It is reported that more than half of patients with lung cancer die within one year of being diagnosed. Because mediastinal lymph node status is the most important factor for the treatment and prognosis of lung cancer, the aim of this study is to improve the predictive value in assessing the computed tomography (CT) of mediastinal lymph-node malignancy in patients with primary lung cancer. This paper introduces a new method for creating pseudo-labeled images of CT regions of mediastinal lymph nodes by using the concept of recurrence analysis in nonlinear dynamics for the transfer learning. Pseudo-labeled images of original CT images are used as input into deep-learning models. Three popular pretrained convolutional neural networks (AlexNet, SqueezeNet, and DenseNet-201) were used for the implementation of the proposed concept for the classification of benign and malignant mediastinal lymph nodes using a public CT database. In comparison with the use of the original CT data, the results show the high performance of the transformed images for the task of classification. Three pretrained convolutional neural networks that are AlexNet, SqueezeNet, and DenseNet201 were trained and tested with the transformed images. Classification accuracies and areas under the receiver operating characteristic curve obtained from the ten-fold cross-validation are 93% and 0.97, 96% and 0.99, and 100% and 1 for the SqueezeNet, AlexNet, and DenseNet201, respectively. The proposed method has the potential for differentiating benign from malignant mediastinal lymph nodes on CT, and may provide a new way for studying lung cancer using radiology imaging. © 2013 IEEE.",Anomalies; autoencoder; convolutional neural networks (CNN) (ConvNets); deep neural network architecture; regularization,Anomaly detection; Biological organs; Computerized tomography; Convolution; Deep neural networks; Diagnosis; Diseases; Image enhancement; Mean square error; Medical imaging; Network architecture; Statistical tests; Anomaly; Anomaly detection; Auto encoders; Convnet; Convolutional neural network; Convolutional neural network (convnet); Deep neural network architecture; Mean squared error; Neural network architecture; Regularisation; Convolutional neural networks,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85112244855
"Jiang H., Tang S., Liu W., Zhang Y.",Deep learning for COVID-19 chest CT (computed tomography) image analysis: A lesson from lung cancer,2021,Computational and Structural Biotechnology Journal,19,,,1391,1399,7,10.1016/j.csbj.2021.02.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102363403&doi=10.1016%2fj.csbj.2021.02.016&partnerID=40&md5=7427e3ada96d4bfbd6da0373f19079cd,"College of Science, Harbin Institute of Technology (Shenzhen), Shenzhen, Guangdong  518055, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan  610054, China; School of Computing and Engineering, University of Missouri-Kansas CityMO, United States; Department of Computer and Information Science, University of Macau, Macau, China","Jiang, H., College of Science, Harbin Institute of Technology (Shenzhen), Shenzhen, Guangdong  518055, China, School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan  610054, China; Tang, S., School of Computing and Engineering, University of Missouri-Kansas CityMO, United States; Liu, W., College of Science, Harbin Institute of Technology (Shenzhen), Shenzhen, Guangdong  518055, China, Department of Computer and Information Science, University of Macau, Macau, China; Zhang, Y., College of Science, Harbin Institute of Technology (Shenzhen), Shenzhen, Guangdong  518055, China","Detecting malignant pulmonary nodules at an early stage can allow medical interventions which may increase the survival rate of lung cancer patients. Using computer vision techniques to detect nodules can improve the sensitivity and the speed of interpreting chest CT for lung cancer screening. Many studies have used CNNs to detect nodule candidates. Though such approaches have been shown to outperform the conventional image processing based methods regarding the detection accuracy, CNNs are also known to be limited to generalize on under-represented samples in the training set and prone to imperceptible noise perturbations. Such limitations can not be easily addressed by scaling up the dataset or the models. In this work, we propose to add adversarial synthetic nodules and adversarial attack samples to the training data to improve the generalization and the robustness of the lung nodule detection systems. To generate hard examples of nodules from a differentiable nodule synthesizer, we use projected gradient descent (PGD) to search the latent code within a bounded neighbourhood that would generate nodules to decrease the detector response. To make the network more robust to unanticipated noise perturbations, we use PGD to search for noise patterns that can trigger the network to give over-confident mistakes. By evaluating on two different benchmark datasets containing consensus annotations from three radiologists, we show that the proposed techniques can improve the detection performance on real CT data. To understand the limitations of both the conventional networks and the proposed augmented networks, we also perform stress-tests on the false positive reduction networks by feeding different types of artificially produced patches. We show that the augmented networks are more robust to both under-represented nodules as well as resistant to noise perturbations. © 1982-2012 IEEE.",Chest CT image; Classification; COVID-19; CycleGAN; Image synthesis; Lung cancer; Style transfer,Biological organs; Computerized tomography; Deep neural networks; Image analysis; Image classification; Medical imaging; Statistical tests; Chest computed tomography image; Computed tomography images; COVID-19; Cyclegan; Images synthesis; Learning models; Lung Cancer; Style transfer; Synthesised; Tomography image analysis; Diseases; Article; computer assisted tomography; controlled study; coronavirus disease 2019; data base; data synthesis; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; image analysis; lung cancer; lung nodule; model; priority journal; scoring system,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85102363403
"Ashhar S.M., Mokri S.S., Rahni A.A.A., Huddin A.B., Zulkarnain N., Azmi N.A., Mahaletchumy T.",Comparison of deep learning convolutional neural network (CNN) architectures for CT lung cancer classification,2021,International Journal of Advanced Technology and Engineering Exploration,8,74,,126,134,7,10.19101/IJATEE.2020.S1762126,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101873065&doi=10.19101%2fIJATEE.2020.S1762126&partnerID=40&md5=e60ff0727ab9440e729093d9e94f535f,"Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Center of Diagnostic, Therapeutic and Investigation Studies (CODTIS), Faculty of Health Science, Universiti Kebangsaan Malaysia, Jalan Raja Muda Abdul Aziz, Kuala Lumpur, 50300, Malaysia; Center of Nuclear Imaging and Nuclear Medicine, UKM Medical Center, Jalan Ya'acob Latif, Bandar Tun Razak, Cheras Kuala Lumpur, 56000, Malaysia","Ashhar, S.M., Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Mokri, S.S., Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Rahni, A.A.A., Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Huddin, A.B., Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Zulkarnain, N., Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering & Built Environment, Universiti Kebangsaan Malaysia UKM, Bangi, Selangor, 43600, Malaysia; Azmi, N.A., Center of Diagnostic, Therapeutic and Investigation Studies (CODTIS), Faculty of Health Science, Universiti Kebangsaan Malaysia, Jalan Raja Muda Abdul Aziz, Kuala Lumpur, 50300, Malaysia; Mahaletchumy, T., Center of Nuclear Imaging and Nuclear Medicine, UKM Medical Center, Jalan Ya'acob Latif, Bandar Tun Razak, Cheras Kuala Lumpur, 56000, Malaysia","Lung cancer follow-up is a complex, error prone, and time consuming task for clinical radiologists. Several lung CT scan images taken at different time points of a given patient need to be individually inspected, looking for possible cancerogenous nodules. Radiologists mainly focus their attention in nodule size, density, and growth to assess the existence of malignancy. In this study, we present a novel method based on a 3D siamese neural network, for the re-identification of nodules in a pair of CT scans of the same patient without the need for image registration. The network was integrated into a two-stage automatic pipeline to detect, match, and predict nodule growth given pairs of CT scans. Results on an independent test set reported a nodule detection sensitivity of 94.7%, an accuracy for temporal nodule matching of 88.8%, and a sensitivity of 92.0% with a precision of 88.4% for nodule growth detection. © 2020 Elsevier B.V.",Computed tomography; Convolution neural network; Deep learning; Lung cancer,,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85101873065
"Rafael-Palou X., Aubanell A., Bonavita I., Ceresa M., Piella G., Ribas V., González Ballester M.A.",Re-Identification and growth detection of pulmonary nodules without image registration using 3D siamese neural networks,2021,Medical Image Analysis,67,,101823,,,5,10.1016/j.media.2020.101823,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733789&doi=10.1016%2fj.media.2020.101823&partnerID=40&md5=59eef938927ced5f1638ac5c2ce604b7,"Eurecat, Centre Tecnològic de Catalunya, eHealth Unit, Barcelona, Spain; BCN MedTech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Vall d'Hebron University Hospital, Barcelona, Spain; ICREA, Barcelona, Spain","Rafael-Palou, X., Eurecat, Centre Tecnològic de Catalunya, eHealth Unit, Barcelona, Spain, BCN MedTech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Aubanell, A., Vall d'Hebron University Hospital, Barcelona, Spain; Bonavita, I., Eurecat, Centre Tecnològic de Catalunya, eHealth Unit, Barcelona, Spain; Ceresa, M., BCN MedTech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Piella, G., BCN MedTech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Ribas, V., Eurecat, Centre Tecnològic de Catalunya, eHealth Unit, Barcelona, Spain; González Ballester, M.A., BCN MedTech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain, ICREA, Barcelona, Spain","Lung cancer late diagnosis has a large impact on the mortality rate numbers, leading to a very low five-year survival rate of 5%. This issue emphasises the importance of developing systems to support a diagnostic at earlier stages. Clinicians use Computed Tomography (CT) scans to assess the nodules and the likelihood of malignancy. Automatic solutions can help to make a faster and more accurate diagnosis, which is crucial for the early detection of lung cancer. Convolutional neural networks (CNN) based approaches have shown to provide a reliable feature extraction ability to detect the malignancy risk associated with pulmonary nodules. This type of approach requires a massive amount of data to model training, which usually represents a limitation in the biomedical field due to medical data privacy and security issues. Transfer learning (TL) methods have been widely explored in medical imaging applications, offering a solution to overcome problems related to the lack of training data publicly available. For the clinical annotations experts with a deep understanding of the complex physiological phenomena represented in the data are required, which represents a huge investment. In this direction, this work explored a TL method based on unsupervised learning achieved when training a Convolutional Autoencoder (CAE) using images in the same domain. For this, lung nodules from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) were extracted and used to train a CAE. Then, the encoder part was transferred, and the malignancy risk was assessed in a binary classification—benign and malignant lung nodules, achieving an Area Under the Curve (AUC) value of 0.936. To evaluate the reliability of this TL approach, the same architecture was trained from scratch and achieved an AUC value of 0.928. The results reported in this comparison suggested that the feature learning achieved when reconstructing the input with an encoder-decoder based architecture can be considered an useful knowledge that might allow overcoming labelling constraints. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",,"Biological organs; Image registration; Neural networks; Error prones; Lung Cancer; Nodule detection; Nodule growth; Pulmonary nodules; Re identifications; Time points; Time-consuming tasks; Computerized tomography; Article; automation; cross validation; deep learning; deep neural network; human; image registration; lung nodule; major clinical study; priority journal; sensitivity and specificity; siamese neural network; three-dimensional imaging; transfer of learning; x-ray computed tomography; computer assisted diagnosis; diagnostic imaging; lung tumor; three-dimensional imaging; x-ray computed tomography; Humans; Imaging, Three-Dimensional; Lung Neoplasms; Neural Networks, Computer; Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85092733789
"Li G., Luo J., Wang D., Liang C., Xiao Q., Ding P., Chen H.",Potential circRNA-disease association prediction using DeepWalk and network consistency projection,2020,Journal of Biomedical Informatics,112,,103624,,,10,10.1016/j.jbi.2020.103624,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096698238&doi=10.1016%2fj.jbi.2020.103624&partnerID=40&md5=e7855aed3e01828256f4128d4c4ec8bc,"School of Information Engineering, East China Jiaotong University, Nanchang, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Information Science and Engineering, Shandong Normal University, Jinan, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; School of Computer Science, University of South China, Hengyang, China; School of Software, East China Jiaotong University, Nanchang, China","Li, G., School of Information Engineering, East China Jiaotong University, Nanchang, China; Luo, J., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Wang, D., School of Information Engineering, East China Jiaotong University, Nanchang, China; Liang, C., College of Information Science and Engineering, Shandong Normal University, Jinan, China; Xiao, Q., College of Information Science and Engineering, Hunan Normal University, Changsha, China; Ding, P., School of Computer Science, University of South China, Hengyang, China; Chen, H., School of Software, East China Jiaotong University, Nanchang, China","Lung cancer has one of the highest morbidity and mortality rates in the world. Lung nodules are an early indicator of lung cancer. Therefore, accurate detection and image segmentation of lung nodules is of great significance to the early diagnosis of lung cancer. This paper proposes a CT (Computed Tomography) image lung nodule segmentation method based on 3D-UNet and Res2Net, and establishes a new convolutional neural network called 3D-Res2UNet. 3D-Res2Net has a symmetrical hierarchical connection network with strong multi-scale feature extraction capabilities. It enables the network to express multi-scale features with a finer granularity, while increasing the receptive field of each layer of the network. This structure solves the deep level problem. The network is not prone to gradient disappearance and gradient explosion problems, which improves the accuracy of detection and segmentation. The U-shaped network ensures the size of the feature map while effectively repairing the lost features. The method in this paper was tested on the LUNA16 public dataset, where the dice coefficient index reached 95.30% and the recall rate reached 99.1%, indicating that this method has good performance in lung nodule image segmentation. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",circRNA-disease association; DeepWalk; Network consistency projection; Similarity learning,"Association reactions; Deep learning; Forecasting; Learning systems; Statistical methods; Biological features; Diagnostic biomarkers; Disease associations; Disease similarities; Experimental techniques; Interaction prediction; Leave-one-out cross validations; Network consistencies; Diagnosis; circular ribonucleic acid; Article; controlled study; deep learning; DeepWalk; disease association; false positive result; intermethod comparison; liver cell carcinoma; lung cancer; mathematical model; measurement accuracy; network consistency projection; prediction; priority journal; receiver operating characteristic; forecasting; human; methodology; Forecasting; Humans; Research Design; RNA, Circular",Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85096698238
"Xiao Z., Liu B., Geng L., Zhang F., Liu Y.",Segmentation of lung nodules using improved 3D-UNet neural network,2020,Symmetry,12,11,1787,1,15,11,10.3390/sym12111787,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094674578&doi=10.3390%2fsym12111787&partnerID=40&md5=2df8e4666c65e88aba1ef1c095f5d4c9,"School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China; Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China","Xiao, Z., School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China, Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China; Liu, B., School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China, Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China; Geng, L., School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China, Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China; Zhang, F., School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China, Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China; Liu, Y., School of Electronics and Information Engineering, Tiangong University, Tianjin, 300387, China, Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tiangong University, Tianjin, 300387, China","The early stage lung cancer often appears as ground-glass nodules (GGNs). The diagnosis of GGN as preinvasive lesion (PIL) or invasive adenocarcinoma (IA) is very important for further treatment planning. This paper proposes an automatic GGNs’ invasiveness classification algorithm for the adenocarcinoma. 1431 clinical cases and a total of 1624 GGNs (3–30 mm) were collected from Shanghai Cancer Center for the study. The data is in high-resolution computed tomography (HRCT) format. Firstly, the automatic GGN detector which is composed by a 3D U-Net and a 3D multi-receptive field (multi-RF) network detects the location of GGNs. Then, a deep 3D convolutional neural network (3D-CNN) called Attention-v1 is used to identify the GGNs’ invasiveness. The attention mechanism was introduced to the 3D-CNN. This paper conducted a contract experiment to compare the performance of Attention-v1, ResNet, and random forest algorithm. ResNet is one of the most advanced convolutional neural network structures. The competition performance metrics (CPM) of automatic GGN detector reached 0.896. The accuracy, sensitivity, specificity, and area under curve (AUC) value of Attention-v1 structure are 85.2%, 83.7%, 86.3%, and 92.6%. The algorithm proposed in this paper outperforms ResNet and random forest in sensitivity, accuracy, and AUC value. The deep 3D-CNN’s classification result is better than traditional machine learning method. Attention mechanism improves 3D-CNN’s performance compared with the residual block. The automatic GGN detector with the addition of Attention-v1 can be used to construct the GGN invasiveness classification algorithm to help the patients and doctors in treatment. © 2020, Society for Imaging Informatics in Medicine.",3D-Res2UNet; 3D-UNet; Deep learning; Lung nodule segmentation; Multi-scale features,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85094674578
"Amyar A., Modzelewski R., Li H., Ruan S.",Multi-task deep learning based CT imaging analysis for COVID-19 pneumonia: Classification and segmentation,2020,Computers in Biology and Medicine,126,,104037,,,156,10.1016/j.compbiomed.2020.104037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092429045&doi=10.1016%2fj.compbiomed.2020.104037&partnerID=40&md5=b0d9564532d5f1706827a4f0817439d0,"General Electric Healthcare, Buc, France; LITIS - EA4108 - Quantif, University of Rouen, Rouen, France; Nuclear Medicine Department, Henri Becquerel Center, Rouen, France; Department of Bioengineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States","Amyar, A., General Electric Healthcare, Buc, France, LITIS - EA4108 - Quantif, University of Rouen, Rouen, France; Modzelewski, R., LITIS - EA4108 - Quantif, University of Rouen, Rouen, France, Nuclear Medicine Department, Henri Becquerel Center, Rouen, France; Li, H., Department of Bioengineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Ruan, S., LITIS - EA4108 - Quantif, University of Rouen, Rouen, France","Classification of benign and malignant in lung nodules using chest CT images is a key step in the diagnosis of early-stage lung cancer, as well as an effective way to improve the patients’ survival rate. However, due to the diversity of lung nodules and the visual similarity of lung nodules to their surrounding tissues, it is difficult to construct a robust classification model with conventional deep learning–based diagnostic methods. To address this problem, we propose a multi-model ensemble learning architecture based on 3D convolutional neural network (MMEL-3DCNN). This approach incorporates three key ideas: (1) Constructed multi-model network architecture can be well adapted to the heterogeneity of lung nodules. (2) The input that concatenated of the intensity image corresponding to the nodule mask, the original image, and the enhanced image corresponding to which can help training model to extract advanced feature with more discriminative capacity. (3) Select the corresponding model to different nodule size dynamically for prediction, which can improve the generalization ability of the model effectively. In addition, ensemble learning is applied in this paper to further improve the robustness of the nodule classification model. The proposed method has been experimentally verified on the public dataset, LIDC-IDRI. The experimental results show that the proposed MMEL-3DCNN architecture can obtain satisfactory classification results. © 2020, Society for Imaging Informatics in Medicine.",Computed tomography images; Coronavirus (COVID-19); Deep learning; Image classification; Image segmentation; Multitask learning,"Classification (of information); Computerized tomography; Diagnosis; Image segmentation; Multi-task learning; Multilayer neural networks; Area under the ROC curve; Automatic classification; Classification performance; Dice coefficient; Feature representation; Multi layer perceptron; Segmentation techniques; Segmentation tool; Deep learning; Article; computer assisted tomography; controlled study; coronavirus disease 2019; deep learning; disease classification; disease severity assessment; follow up; human; image reconstruction; image segmentation; lung cancer; major clinical study; multilayer perceptron; pneumonia; priority journal; receiver operating characteristic; thorax radiography; Betacoronavirus; Coronavirus infection; diagnostic imaging; female; lung; male; pandemic; virus pneumonia; x-ray computed tomography; Betacoronavirus; Coronavirus Infections; Deep Learning; Female; Humans; Lung; Male; Pandemics; Pneumonia, Viral; Tomography, X-Ray Computed",Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85092429045
"Ni Y., Yang Y., Zheng D., Xie Z., Huang H., Wang W.",The Invasiveness Classification of Ground-Glass Nodules Using 3D Attention Network and HRCT,2020,Journal of Digital Imaging,33,5,,1144,1154,3,10.1007/s10278-020-00355-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088514278&doi=10.1007%2fs10278-020-00355-9&partnerID=40&md5=7d0a491bf4b6f9d74bf718d404d639ed,"Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai, 200083, China; University of Chinese Academy of Sciences, Beijing, 100049, China; Department of Interventional Radiology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China; The General Hospital of the People’s Liberation Army, No. 28 Fuxing Road, Haidian District, Beijing, 100039, China","Ni, Y., Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai, 200083, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Yang, Y., Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai, 200083, China; Zheng, D., Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai, 200083, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Xie, Z., Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai, 200083, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Huang, H., Department of Interventional Radiology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China; Wang, W., The General Hospital of the People’s Liberation Army, No. 28 Fuxing Road, Haidian District, Beijing, 100039, China","To evaluate the application of machine learning for the detection of subpleural pulmonary lesions (SPLs) in ultrasound (US) scans, we propose a novel boundary-restored network (BRN) for automated SPL segmentation to avoid issues associated with manual SPL segmentation (subjectivity, manual segmentation errors, and high time consumption). In total, 1612 ultrasound slices from 255 patients in which SPLs were visually present were exported. The segmentation performance of the neural network based on the Dice similarity coefficient (DSC), Matthews correlation coefficient (MCC), Jaccard similarity metric (Jaccard), Average Symmetric Surface Distance (ASSD), and Maximum symmetric surface distance (MSSD) was assessed. Our dual-stage boundary-restored network (BRN) outperformed existing segmentation methods (U-Net and a fully convolutional network (FCN)) for the segmentation accuracy parameters including DSC (83.45 ± 16.60%), MCC (0.8330 ± 0.1626), Jaccard (0.7391 ± 0.1770), ASSD (5.68 ± 2.70 mm), and MSSD (15.61 ± 6.07 mm). It also outperformed the original BRN in terms of the DSC by almost 5%. Our results suggest that deep learning algorithms aid fully automated SPL segmentation in patients with SPLs. Further improvement of this technology might improve the specificity of lung cancer screening efforts and could lead to new applications of lung US imaging. © 2020, Society for Imaging Informatics in Medicine.",3D-CNN; Attention mechanism; HRCT; Invasiveness,"Computerized tomography; Convolution; Decision trees; Diagnosis; Diseases; Glass; Learning systems; Patient treatment; Random forests; Attention mechanisms; Classification algorithm; Classification results; Early-stage lung cancers; Ground glass nodules; High-resolution computed tomography; Machine learning methods; Random forest algorithm; Convolutional neural networks; China; diagnostic imaging; human; lung; lung tumor; tumor invasion; x-ray computed tomography; China; Humans; Lung; Lung Neoplasms; Neoplasm Invasiveness; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85088514278
"Liu H., Cao H., Song E., Ma G., Xu X., Jin R., Liu C., Hung C.-C.",Multi-model Ensemble Learning Architecture Based on 3D CNN for Lung Nodule Malignancy Suspiciousness Classification,2020,Journal of Digital Imaging,33,5,,1242,1256,8,10.1007/s10278-020-00372-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087401185&doi=10.1007%2fs10278-020-00372-8&partnerID=40&md5=c951fa3e8f113c3bb27864c300779852,"School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Laboratory for Machine Vision and Security Research, Kennesaw State University, Kennesaw, GA, United States","Liu, H., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Cao, H., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Song, E., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Ma, G., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Xu, X., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Jin, R., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Liu, C., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China; Hung, C.-C., Laboratory for Machine Vision and Security Research, Kennesaw State University, Kennesaw, GA, United States","Pulmonary nodule detection in chest computed tomography (CT) is of great significance for the early diagnosis of lung cancer. Therefore, it has attracted more and more researchers to propose various computer-assisted pulmonary nodule detection methods. However, these methods still could not provide convincing results because the nodules are easily confused with calcifications, vessels, or other benign lumps. In this paper, we propose a novel deep convolutional neural network (DCNN) framework for detecting pulmonary nodules in the chest CT image. The framework consists of three cascaded networks: First, a U-net network integrating inception structure and dense skip connection is proposed to segment the region of lung parenchyma from the chest CT image. The inception structure is used to replace the first convolution layer for better feature extraction with respect to multiple receptive fields, while the dense skip connection could reuse these features and transfer them through the network. Secondly, a modified U-net network where all the convolution layers are replaced by dilated convolution is proposed to detect the “suspicious nodules” in the image. The dilated convolution can increase the receptive fields to improve the ability of the network in learning global information of the image. Thirdly, a modified U-net adapting multi-scale pooling and multi-resolution convolution connection is proposed to find the true pulmonary nodule in the image with multiple candidate regions. During the detection, the result of the former step is used as the input of the latter step to follow the “coarse-to-fine” detection process. Moreover, the focal loss, perceptual loss and dice loss were used together to replace the cross-entropy loss to solve the problem of imbalance distribution of positive and negative samples. We apply our method on two public datasets to evaluate its ability in pulmonary nodule detection. Experimental results illustrate that the proposed method outperform the state-of-the-art methods with respect to accuracy, sensitivity and specificity. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",3D CNN; Benign and malignant classification; Computer-aided diagnosis; Image enhancement; Multi-model ensemble architecture,"Biological organs; Computer aided diagnosis; Computerized tomography; Convolutional neural networks; Deep learning; Image enhancement; Network architecture; Classification models; Classification results; Diagnostic methods; Early-stage lung cancers; Generalization ability; Multi-model ensemble; Robust classification; Visual similarity; Learning systems; computer assisted diagnosis; diagnostic imaging; human; lung; lung nodule; lung tumor; machine learning; x-ray computed tomography; Humans; Lung; Lung Neoplasms; Machine Learning; Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85087401185
"Chi J., Zhang S., Yu X., Wu C., Jiang Y.",A novel pulmonary nodule detection model based on multi-step cascaded networks,2020,Sensors (Switzerland),20,15,4301,1,26,2,10.3390/s20154301,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088995808&doi=10.3390%2fs20154301&partnerID=40&md5=b2dcc493a8c02172d40fe70d390dc8fd,"Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China","Chi, J., Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China; Zhang, S., Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China; Yu, X., Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China; Wu, C., Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China; Jiang, Y., Faculty of Robot Science and Engineering, Northeastern University, Shenyang, 110169, China","Pulmonary nodules risk classification in adenocarcinoma is essential for early detection of lung cancer and clinical treatment decision. Improving the level of early diagnosis and the identification of small lung adenocarcinoma has been always an important topic for imaging studies. In this study, the authors propose a deep convolutional neural network (CNN) with scaletransfer module (STM) and incorporate multi-feature fusion operation, named STM-Net. This network can amplify small targets and adapt to different resolution images. The evaluation data were obtained from the computed tomography (CT) database provided by Zhongshan Hospital Fudan University (ZSDB). All data have a pathological label and their lung adenocarcinomas risk are classified into four categories: atypical adenomatous hyperplasia, adenocarcinoma in situ, minimally invasive adenocarcinoma, and invasive adenocarcinoma. The authors' deep learning network STM-Net was trained and tested for the risk stage prediction. The accuracy and the average area under the receiver operating characteristic curve achieved by their method are 95.455% and 0.987 for the ZSDB dataset. The experimental results show that STM-Net largely boosts classification accuracy on the pulmonary nodules classification compared with state-of-the-art approaches. The proposed method will be an effective auxiliary to help physicians diagnosis pulmonary nodules risk classification in adenocarcinoma in early-stage. © 2020 The Institution of Engineering and Technology.",Deep neural convolutional network; Dense connection; Dilated convolution; Inception structure; Multi-resolution convolution; Pulmonary nodule detection,Biological organs; Biomineralization; Convolution; Convolutional neural networks; Deep neural networks; Diagnosis; Image enhancement; Image segmentation; Positron emission tomography; Cascaded networks; Computer assisted; Global informations; Imbalance distributions; Pulmonary nodule detection; Pulmonary nodules; Sensitivity and specificity; State-of-the-art methods; Computerized tomography,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85088995808
"Moitra D., Mandal R.K.",Prediction of Non-small Cell Lung Cancer Histology by a Deep Ensemble of Convolutional and Bidirectional Recurrent Neural Network,2020,Journal of Digital Imaging,33,4,,895,902,7,10.1007/s10278-020-00337-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084128248&doi=10.1007%2fs10278-020-00337-x&partnerID=40&md5=d68812120c08f303a4a29a4d573328cb,"University of North Bengal, Siliguri, India","Moitra, D., University of North Bengal, Siliguri, India; Mandal, R.K., University of North Bengal, Siliguri, India","With the increasing incidence rate of lung cancer patients, early diagnosis could help in reducing the mortality rate. However, accurate recognition of cancerous lesions is immensely challenging owing to factors such as low contrast variation, heterogeneity and visual similarity between benign and malignant nodules. Deep learning techniques have been very effective in performing natural image segmentation with robustness to previously unseen situations, reasonable scale invariance and the ability to detect even minute differences. However, they usually fail to learn domain-specific features due to the limited amount of available data and domain agnostic nature of these techniques. This work presents an ensemble framework Deep3DSCan for lung cancer segmentation and classification. The deep 3D segmentation network generates the 3D volume of interest from computed tomography scans of patients. The deep features and handcrafted descriptors are extracted using a fine-tuned residual network and morphological techniques, respectively. Finally, the fused features are used for cancer classification. The experiments were conducted on the publicly available LUNA16 dataset. For the segmentation, the authors achieved an accuracy of 0.927, significant improvement over the template matching technique, which had achieved an accuracy of 0.927. For the detection, previous state-of-the-art is 0.866, while ours is 0.883. © The Institution of Engineering and Technology 2020.",Bidirectional; Histology; Lung cancer; Neural network; Recurrent,"Biological organs; Convolution; Convolutional neural networks; Diagnosis; Diseases; Forecasting; Grading; Histology; Learning systems; Medical imaging; Noninvasive medical procedures; Tumors; Bidirectional recurrent neural networks; Cross validation; Ensemble modeling; Invasive methods; Learning models; Model ensembles; Non small cell lung cancer; Noninvasive methods; Recurrent neural networks; diagnostic imaging; histology; human; lung tumor; machine learning; non small cell lung cancer; Carcinoma, Non-Small-Cell Lung; Histological Techniques; Humans; Lung Neoplasms; Machine Learning; Neural Networks, Computer",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85084128248
"Zheng J., Yang D., Zhu Y., Gu W., Zheng B., Bai C., Zhao L., Shi H., Hu J., Lu S., Shi W., Wang N.",Pulmonary nodule risk classification in adenocarcinoma from CT images using deep CNN with scale transfer module,2020,IET Image Processing,14,8,,1481,1489,6,10.1049/iet-ipr.2019.0248,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086141826&doi=10.1049%2fiet-ipr.2019.0248&partnerID=40&md5=d14e68ac032ac22c80e202e6a28ab86c,"School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Department of Pulmonary Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Shanghai Respiratory Research Institute, Shanghai, 200032, China; Department of Respiratory and Critical Care Medicine, Rizhao People's Hospital, Jining Medical University, Rizhao, Shandong, 276800, China; Department of Nuclear Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Medical Examination Center, Zhongshan Hospital, Fudan University, Shanghai, 200032, China","Zheng, J., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Yang, D., Department of Pulmonary Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China, Shanghai Respiratory Research Institute, Shanghai, 200032, China; Zhu, Y., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Gu, W., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Zheng, B., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Bai, C., Department of Pulmonary Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China, Shanghai Respiratory Research Institute, Shanghai, 200032, China; Zhao, L., Department of Respiratory and Critical Care Medicine, Rizhao People's Hospital, Jining Medical University, Rizhao, Shandong, 276800, China; Shi, H., Department of Nuclear Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Hu, J., Department of Pulmonary Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China, Shanghai Respiratory Research Institute, Shanghai, 200032, China; Lu, S., Department of Pathology, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Shi, W., Medical Examination Center, Zhongshan Hospital, Fudan University, Shanghai, 200032, China; Wang, N., Department of Pulmonary Medicine, Zhongshan Hospital, Fudan University, Shanghai, 200032, China","At present, the rate of missed diagnosis of lung cancer is high. The reason is that the pulmonary nodule phenomenon cannot be effectively monitored due to various interference factors in the actual detection process. In order to improve the detection accuracy, this study combined with the actual situation to analyse the diversity of nodular shape and constructed a deep belief network-based diagnosis model for pulmonary nodules. At the same time, in order to improve the detection effect, this study sets the model to have multi-layer non-linear structure and analyses the previous clinical data to improve the model learning rate and training effect. In addition, in order to verify the performance of the model, the diagnostic effect of the model is studied by comparative experiments. The research shows that the model proposed in this study is higher than the traditional algorithm in detection accuracy, which can provide theoretical reference for subsequent related research. © The Institution of Engineering and Technology 2020.",,Biological organs; Computer aided diagnosis; Convolutional neural networks; Deep learning; Deep neural networks; Image classification; Positron emission tomography; Classification accuracy; Clinical treatments; Different resolutions; Minimally invasive; Multi-feature fusion; Receiver operating characteristic curves; Risk classification; State-of-the-art approach; Computerized tomography,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85086141826
"Bansal G., Chamola V., Narang P., Kumar S., Raman S.",Deep3DScan: Deep residual network and morphological descriptor based framework for lung cancer classification and 3D segmentation,2020,IET Image Processing,14,7,,1316,1326,23,10.1049/iet-ipr.2019.1164,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084956005&doi=10.1049%2fiet-ipr.2019.1164&partnerID=40&md5=9a9a41b262c67a1f5fee1533f11a8445,"Department of Computer Science, BITS Pilani, Pilani, India; EEE Department, BITS Pilani, Pilani, India","Bansal, G., Department of Computer Science, BITS Pilani, Pilani, India; Chamola, V., EEE Department, BITS Pilani, Pilani, India; Narang, P., Department of Computer Science, BITS Pilani, Pilani, India; Kumar, S., Department of Computer Science, BITS Pilani, Pilani, India; Raman, S., Department of Computer Science, BITS Pilani, Pilani, India","We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results. © 1982-2012 IEEE.",,Biological organs; Computerized tomography; Deep learning; Diagnosis; Diseases; Template matching; Cancer classification; Cancerous lesions; Computed tomography scan; Learning techniques; Natural image segmentations; Template matching technique; Visual similarity; Volume of interest; Image segmentation,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85084956005
"Yang W., Xia W., Xie Y., Mao S., Li R.",Optimisation analysis of pulmonary nodule diagnostic test based on deep belief nets,2020,IET Image Processing,14,7,,1347,1353,,10.1049/iet-ipr.2019.1022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084948874&doi=10.1049%2fiet-ipr.2019.1022&partnerID=40&md5=389a46cc53002075785aba458c2a8bcf,"Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China; Department of Pediatrics, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China","Yang, W., Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China; Xia, W., Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China; Xie, Y., Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China; Mao, S., Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China; Li, R., Department of Radiology and Imaging, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China, Department of Pediatrics, Central Hospital of Wuhan, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, 430014, China","Background: Lung cancer is the leading cause of cancer-related deaths in both men and women in the United States, and it has a much lower five-year survival rate than many other cancers. Accurate survival analysis is urgently needed for better disease diagnosis and treatment management. Results: In this work, we propose a survival analysis system that takes advantage of recently emerging deep learning techniques. The proposed system consists of three major components. 1) The first component is an end-to-end cellular feature learning module using a deep neural network with global average pooling. The learned cellular representations encode high-level biologically relevant information without requiring individual cell segmentation, which is aggregated into patient-level feature vectors by using a locality-constrained linear coding (LLC)-based bag of words (BoW) encoding algorithm. 2) The second component is a Cox proportional hazards model with an elastic net penalty for robust feature selection and survival analysis. 3) The third commponent is a biomarker interpretation module that can help localize the image regions that contribute to the survival model's decision. Extensive experiments show that the proposed survival model has excellent predictive power for a public (i.e., The Cancer Genome Atlas) lung cancer dataset in terms of two commonly used metrics: Log-rank test (p-value) of the Kaplan-Meier estimate and concordance index (c-index). Conclusions: In this work, we have proposed a segmentation-free survival analysis system that takes advantage of the recently emerging deep learning framework and well-studied survival analysis methods such as the Cox proportional hazards model. In addition, we provide an approach to visualize the discovered biomarkers, which can serve as concrete evidence supporting the survival model's decision. © 2020 The Author(s).",,Image processing; Signal processing; Comparative experiments; Deep belief networks; Detection accuracy; Detection process; Diagnosis of lung cancer; Interference factor; Nonlinear structure; Pulmonary nodules; Positron emission tomography,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85084948874
"Bonavita I., Rafael-Palou X., Ceresa M., Piella G., Ribas V., González Ballester M.A.",Integration of convolutional neural networks for pulmonary nodule malignancy assessment in a lung cancer classification pipeline,2020,Computer Methods and Programs in Biomedicine,185,,105172,,,24,10.1016/j.cmpb.2019.105172,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074637539&doi=10.1016%2fj.cmpb.2019.105172&partnerID=40&md5=a786bdbf9252a9d0a7e55699582c6ef6,"Eurecat, centre TecnolÃgic de Catalunya, eHealth Unit, Barcelona, Spain; BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; ICREA, Barcelona, Spain","Bonavita, I., Eurecat, centre TecnolÃgic de Catalunya, eHealth Unit, Barcelona, Spain; Rafael-Palou, X., Eurecat, centre TecnolÃgic de Catalunya, eHealth Unit, Barcelona, Spain, BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Ceresa, M., BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Piella, G., BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Ribas, V., Eurecat, centre TecnolÃgic de Catalunya, eHealth Unit, Barcelona, Spain; González Ballester, M.A., BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain, ICREA, Barcelona, Spain","Low-Dose CT (LDCT) can significantly improve the accuracy of lung cancer diagnosis and thus reduce cancer deaths compared to chest X-ray. The lung cancer risk population is also at high risk of other deadly diseases, for instance, cardiovascular diseases. Therefore, predicting the all-cause mortality risks of this population is of great importance. This paper introduces a knowledge-based analytical method using deep convolutional neural network (CNN) for all-cause mortality prediction. The underlying approach combines structural image features extracted from CNNs, based on LDCT volume at different scales, and clinical knowledge obtained from quantitative measurements, to predict the mortality risk of lung cancer screening subjects. The proposed method is referred as Knowledge-based Analysis of Mortality Prediction Network (KAMP-Net). It constitutes a collaborative framework that utilizes both imaging features and anatomical information, instead of completely relying on automatic feature extraction. Our work demonstrates the feasibility of incorporating quantitative clinical measurements to assist CNNs in all-cause mortality prediction from chest LDCT images. The results of this study confirm that radiologist defined features can complement CNNs in performance improvement. The experiments demonstrate that KAMP-Net can achieve a superior performance when compared to other methods. © 2013 IEEE.",Deep learning; Lung cancer; Machine learning; Nodule malignancy,"Biological organs; Convolution; Deep learning; Diseases; Integration testing; Large dataset; Learning systems; Neural networks; Positron emission tomography; Statistical tests; Baseline predictions; Convolutional neural network; Error prone tasks; Lung Cancer; Lung cancer detections; Nodule malignancy; Predictive models; Training and testing; Pipelines; Article; cancer classification; cancer diagnosis; classification algorithm; clinical evaluation; computer assisted tomography; convolutional neural network; diagnostic radiologist; human; intermethod comparison; lung cancer; lung nodule; prediction; three dimensional imaging; transfer of learning; diagnostic imaging; information processing; lung nodule; lung tumor; Datasets as Topic; Deep Learning; Humans; Lung Neoplasms; Neural Networks, Computer; Solitary Pulmonary Nodule",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85074637539
"Papandrianos N., Papageorgiou E., Anagnostis A., Feleki A.",A deep-learning approach for diagnosis of metastatic breast cancer in bones from whole-body scans,2020,Applied Sciences (Switzerland),10,3,997,,,24,10.3390/app10030997,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081541686&doi=10.3390%2fapp10030997&partnerID=40&md5=a210e862db6ab6e4302df81543a56e37,"Former Nursing Department, University of Thessaly, Lamia, 35100, Greece; Faculty of Technology, University of Thessaly, Geopolis Campus, Larissa-Trikala Ring Road, Larissa, 41500, Greece; Institute for Bio-economy and Agri-technology (iBO), Center for Research and Technology-Hellas (CERTH), Thessaloniki, 57001, Greece; Department of Computer Science, University of Thessaly, Lamia, 35131, Greece; Faculty of Technology, Geopolis Campus, University of Thessaly, Larissa, 41500, Greece","Papandrianos, N., Former Nursing Department, University of Thessaly, Lamia, 35100, Greece; Papageorgiou, E., Faculty of Technology, University of Thessaly, Geopolis Campus, Larissa-Trikala Ring Road, Larissa, 41500, Greece; Anagnostis, A., Institute for Bio-economy and Agri-technology (iBO), Center for Research and Technology-Hellas (CERTH), Thessaloniki, 57001, Greece, Department of Computer Science, University of Thessaly, Lamia, 35131, Greece; Feleki, A., Faculty of Technology, Geopolis Campus, University of Thessaly, Larissa, 41500, Greece","Lung cancer is the second most common form of cancer in both men and women. It is responsible for at least 25% of all cancer-related deaths in the United States alone. Accurate and early diagnosis of this form of cancer can increase the rate of survival. Computed tomography (CT) imaging is one of the most accurate techniques for diagnosing the disease. In order to improve the classification accuracy of pulmonary lesions indicating lung cancer, this paper presents an improved method for training a densely connected convolutional network (DenseNet). The optimized setting ensures that code prediction error and reconstruction error within hidden layers are simultaneously minimized. To achieve this and improve the classification accuracy of the DenseNet, we propose an improved predictive sparse decomposition (PSD) approach for extracting sparse features from the medical images. The sparse decomposition is achieved by using a linear combination of basis functions over the L2 norm. The effect of dropout and hidden layer expansion on the classification accuracy of the DenseNet is also investigated. CT scans of human lung samples are obtained from The Cancer Imaging Archive (TCIA) hosted by the University of Arkansas for Medical Sciences (UAMS). The proposed method outperforms seven other neural network architectures and machine learning algorithms with a classification accuracy of 95%. Copyright © Research Institute for Intelligent Computer Systems, 2020. All rights reserved.",Bone metastasis; Breast cancer; Convolutional neural networks; Deep learning; Image classification; Scintigraphy; Whole body,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85081541686
"Mienye I.D., Sun Y., Wang Z.",Improved predictive sparse decomposition method with densenet for prediction of lung cancer,2020,International Journal of Computing,19,4,,533,541,2,10.47839/ijc.19.4.1986,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103323355&doi=10.47839%2fijc.19.4.1986&partnerID=40&md5=ae02d49207af0a19dffa3b65b8498100,"Department of Electrical and Electronic Engineering Science, University of Johannesburg, Johannesburg, 2006, South Africa; Department of Electrical and Mining Engineering, University of South Africa, Florida, 1709, South Africa","Mienye, I.D., Department of Electrical and Electronic Engineering Science, University of Johannesburg, Johannesburg, 2006, South Africa; Sun, Y., Department of Electrical and Electronic Engineering Science, University of Johannesburg, Johannesburg, 2006, South Africa; Wang, Z., Department of Electrical and Mining Engineering, University of South Africa, Florida, 1709, South Africa","Automatic lung cancer diagnosis from computer tomography (CT) images requires the detection of nodule location as well as nodule malignancy prediction. This article proposes a joint lung nodule detection and classification network for simultaneous lung nodule detection, segmentation and classification subject to possible label uncertainty in the training set. It operates in an end-to-end manner and provides detection and classification of nodules simultaneously together with a segmentation of the detected nodules. Both the nodule detection and classification subnetworks of the proposed joint network adopt a 3-D encoder-decoder architecture for better exploration of the 3-D data. Moreover, the classification subnetwork utilizes the features extracted from the detection subnetwork and multiscale nodule-specific features for boosting the classification performance. The former serves as valuable prior information for optimizing the more complicated 3D classification network directly to better distinguish suspicious nodules from other tissues compared with direct backpropagation from the decoder. Experimental results show that this co-training yields better performance on both tasks. The framework is validated on the LUNA16 and LIDC-IDRI datasets and a pseudo-label approach is proposed for addressing the label uncertainty problem due to inconsistent annotations/labels. Experimental results show that the proposed nodule detector outperforms the state-of-the-art algorithms and yields comparable performance as state-of-the-art nodule classification algorithms when classification alone is considered. Since our joint detection/recognition approach can directly detect nodules and classify its malignancy instead of performing the tasks separately, our approach is more practical for automatic cancer and nodules detection. © 2013 IEEE.",convolutional neural network; deep learning; denseNet; predictive sparse decomposition,,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85103323355
"Rajesh P., Murugan A., Muruganantham B., Ganesh Kumar S.",Lung Cancer Diagnosis and Treatment Using AI and Mobile Applications,2020,International Journal of Interactive Mobile Technologies,14,17,,189,203,3,10.3991/ijim.v14i17.16607,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097441463&doi=10.3991%2fijim.v14i17.16607&partnerID=40&md5=330cae85460085751ead5da81b55d8c3,"SRM Institute of Science and TechnologyTamil Nadu, India","Rajesh, P., SRM Institute of Science and TechnologyTamil Nadu, India; Murugan, A., SRM Institute of Science and TechnologyTamil Nadu, India; Muruganantham, B., SRM Institute of Science and TechnologyTamil Nadu, India; Ganesh Kumar, S., SRM Institute of Science and TechnologyTamil Nadu, India","Lung cancer is among the world's worst cancers, and accounted for 27%of all cancers in 2018. Despite substantial improvement in recent diagnoses and medications, the five year cure ratio is just 19%. Before even the diagnosis, classification of lung nodule is an essential step, particularly because early detection can help doctors with a highly valued opinion. CT image detection and classification is possible easily and accurately with advanced vision devices and machine-learning technology. This field of work has been extremely successful. Researchers have already attempted to improve the accuracy of CAD structures by computational tomography (CT) in the screening of lung cancer in several deep learning models. In this paper, we proposed a fully automated lung CT system for lung nodule classification, namely, new transfer method (NTM) which has two parts. First features are extracted by applying different VOI and feature extraction techniques. We used intensity, shape, contrast of border and spicula extraction to extract the lung nodule. Then these nodules are transfer to the classification part where we used advance-fully convolution network (A-FCN) to classify the lung nodule between benign and malignant. Our A-FCN network contain three types of layers that helps to enhance the performance and accuracy of NTM network which are convolution layer, pooling layer and fully connected layer. The proposed model is trained on LIDC-IDRI dataset and attained an accuracy of 89.90 % with AUC of 0.9485. © 2020, Science and Information Organization.",Artificial intelligence; CAD; CNN; CT scan; K-means; Lung Cancer,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85097441463
"Gillani S.W., Ning B.",Classification of pulmonary nodule using new transfer method approach,2020,International Journal of Advanced Computer Science and Applications,11,9,,9,13,,10.14569/IJACSA.2020.0110902,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091894208&doi=10.14569%2fIJACSA.2020.0110902&partnerID=40&md5=7a888c25f7cf314588ad754d9410bc1c,"College of Information Science and Technology, Dalian Maritime University, Dalian, Liaoning, China","Gillani, S.W., College of Information Science and Technology, Dalian Maritime University, Dalian, Liaoning, China; Ning, B., College of Information Science and Technology, Dalian Maritime University, Dalian, Liaoning, China","The performance of lung segmentation is highly dependent on disease prediction task. Challenges for prediction and segmentation raise the need of using multiple learning techniques. Current models initially perform image segmentation in all CT scan images and then classify it as malicious or benign. This consumes more time since it segments both normal and abnormal CT's. So, due to improper segmentation of images the region of interest will be inaccurate and results in false classification of images. Therefore, by initially checking the CT which has malignancy and then segmenting those lesions will provide more accuracy in segmentation of cancerous nodules thereby helps to identify the stage of cancer the patient is suffering from. The aim is to improve the current cancer detection techniques using DCNN by filtering out malignant CT scan from the medical dataset and segmenting those images for stage identification. Segmentation is done using UNET++ architecture and stage identification is done by considering the ""size"" (T) parameter from the globally recognized standard named ""TNM staging"" for classifying the spread of each malignant nodule as T1-T4. 99.83 % accuracy is achieved in lung cancer classification using VGG-16 which yields better results for both segmentation and stage identification too. © 2020 Science and Information Organization.",Classification; Feature extraction; LIDC-IDRI dataset; New transfer method; VOI extraction,Biological organs; Classification (of information); Computer aided diagnosis; Computerized tomography; Convolution; Deep learning; Diseases; Feature extraction; Features extraction; Image detection; Images classification; LIDC-IDRI dataset; Lung Cancer; Lung nodule; New transfer method; Pulmonary nodules; Transfer method; VOI extraction; Extraction,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85091894208
"Balachandran S., Divya, Rajendran N., Giri B.",Detection of pulmonary nodules in ct images using deep learning technique,2020,Journal of Computer Science,16,4,,568,575,,10.3844/JCSSP.2020.568.575,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089216083&doi=10.3844%2fJCSSP.2020.568.575&partnerID=40&md5=2d2cd8e61fb0e57550549cc33cb80efe,"School of Computing, SASTRA Deemed to Be University, Thanjavur, Tamil Nadu, 613402, India","Balachandran, S., School of Computing, SASTRA Deemed to Be University, Thanjavur, Tamil Nadu, 613402, India; Divya, School of Computing, SASTRA Deemed to Be University, Thanjavur, Tamil Nadu, 613402, India; Rajendran, N., School of Computing, SASTRA Deemed to Be University, Thanjavur, Tamil Nadu, 613402, India; Giri, B., School of Computing, SASTRA Deemed to Be University, Thanjavur, Tamil Nadu, 613402, India","Lung cancer is known as the highest mortality rate cancer, which needs biopsy to determine its subtype for further treatment. Recently, deep learning has provided powerful tools in lung cancer diagnose and therapeutic regimen making. However, it is still a challenge to identify the pathological type of lung cancer in early stage by CT images due to the lack of public training data set and powerful artificial intelligent models. In this work, we firstly build up a data set of CT images from 125 patients of lung cancer in early stage. The data set is enhanced by revolving, shifting and reproducing operations to avoid its inherent imbalance. After that, a deep convolutional neural network namely VGG16-T is proposed and multiple VGG16-T worked as weak classifiers are trained with a boosting strategy. Such method achieves significant performance in identifying pathological type of lung cancer with CT images by joint voting. Experiments conducted on the enhanced data set of CT images show that 3 weak classifiers VGG16-T are sufficient to achieve accuracy 86.58% in identifying pathological type, which performs better than some state-of-the-art deep learning models, including AlexNet, ResNet-34 and DenseNet with or without Softmax weights. As well, VGG16-T is with accuracy 85% by diagnosing 20 randomly selected CT images, while two respiratory doctors from Grade 3A level hospitals obtain accuracy 55% and 65% by handcrafted diagnosing, respectively. To our best acknowledge, this is the first attempt of using deep models and boosting to identify pathological type of lung cancer in early stage from small scale CT images. © 2020 The Authors. Published by Atlantis Press SARL.",Computer aided diagnosis (CAD); Convolutional neural network (CNN); Lung cancer,,Article,Final,"All Open Access, Hybrid Gold",Scopus,2-s2.0-85089216083
"Pang S., Meng F., Wang X., Wang J., Song T., Wang X., Cheng X.",VGG16-T: A novel deep convolutional neural network with boosting to identify pathological type of lung cancer in early stage by ct images,2020,International Journal of Computational Intelligence Systems,13,1,,771,780,9,10.2991/ijcis.d.200608.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087107433&doi=10.2991%2fijcis.d.200608.001&partnerID=40&md5=07a914ef87bdd60afbebd62ac56c7580,"College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China; School of Electrical Engineering and Automation, Tiangong University, Xiqing, Tianjin, China; Departamento de Inteligencia Artificial, Universidad Politécnica de Madrid, Campus de Montegancedo Boadilla del Monte, Madrid, Spain; Department of Respiratory Medicine, Shandong Provincial Hospital Affiliated to Shandong University, Jinan, Shandong, China; School of Science and Technology, Middlesex University, The Burroughs, Hendon, London, United Kingdom","Pang, S., College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China; Meng, F., College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China; Wang, X., College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China; Wang, J., College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan, China; Song, T., College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China, School of Electrical Engineering and Automation, Tiangong University, Xiqing, Tianjin, China, Departamento de Inteligencia Artificial, Universidad Politécnica de Madrid, Campus de Montegancedo Boadilla del Monte, Madrid, Spain; Wang, X., Department of Respiratory Medicine, Shandong Provincial Hospital Affiliated to Shandong University, Jinan, Shandong, China; Cheng, X., School of Science and Technology, Middlesex University, The Burroughs, Hendon, London, United Kingdom","Computer-aided diagnosis systems with deep learning frameworks have been used to identify benign and malignant pulmonary nodules in lung cancer diagnosis. It's commonly known that a premise of training complex deep neural nets is the large-scale labeled datasets. However, the abundance of labeled datasets is usually unavailable in many medical image domains. This factor can lead to the poor generalization performance of deep learning models. In this paper, we propose a novel multi-discriminator generative adversarial network model combined with an encoder for the classification of benign and malignant pulmonary nodules. To the best of our knowledge, we are the first to apply unsupervised learning to identify benign and malignant lung nodules. Firstly, we use a multi-discriminator generative adversarial network to build a generative model trained with unlabeled benign lung nodule images. Then an encoder is combined with the trained generative model to establish a mapping of benign pulmonary nodule images to the latent space. The benign and malignant lung nodules are scored by calculating the GAN discriminator feature loss and image reconstruction loss. The model yields high anomaly scores on malignant images and low anomaly scores on benign images. Experimental results show that our method with only a small number of unlabeled datasets could achieve more competitive results compared with other supervised deep learning approaches. © 2013 IEEE.",,Biological organs; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Diagnosis; Diseases; Image enhancement; Artificial intelligent; Further treatments; Learning models; Mortality rate; Small scale; State of the art; Training data sets; Weak classifiers; Computerized tomography,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85087107433
"Tabares-Soto R., Orozco-Arias S., Romero-Cano V., Bucheli V.S., Rodríguez-Sotelo J.L., Jiménez-Varón C.F.",A comparative study of machine learning and deep learning algorithms to classify cancer types based on microarray gene expression data,2020,PeerJ Computer Science,2020,4,270,,,22,10.7717/peerj-cs.270,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085682566&doi=10.7717%2fpeerj-cs.270&partnerID=40&md5=f2fb02405183565d38a512f46c554405,"Department of Electronics and Automation, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia; Department of Computer Science, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia; Department of Systems and informatics, Universidad de Caldas, Manizales, Caldas, Colombia; Department of Automatics and Electronics, Universidad Autónoma de Occidente, Cali, Valle del Cauca, Colombia; Izmir International Biomedicine and Genome Institute, Dokuz Eylül University, Izmir, Turkey; Department of Physics and Mathematics, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia","Tabares-Soto, R., Department of Electronics and Automation, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia; Orozco-Arias, S., Department of Computer Science, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia, Department of Systems and informatics, Universidad de Caldas, Manizales, Caldas, Colombia; Romero-Cano, V., Department of Automatics and Electronics, Universidad Autónoma de Occidente, Cali, Valle del Cauca, Colombia; Bucheli, V.S., Izmir International Biomedicine and Genome Institute, Dokuz Eylül University, Izmir, Turkey; Rodríguez-Sotelo, J.L., Department of Electronics and Automation, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia; Jiménez-Varón, C.F., Department of Physics and Mathematics, Universidad Autónoma de Manizales, Manizales, Caldas, Colombia","With the development of medical imaging technology and the introduction of computed tomography (CT), early screening for lung cancer is becoming more and more possible. In this paper, we introduce the method of wavelet dynamic analysis to extract and repair the lung parenchyma, so as to exclude the noise interference outside the lung parenchyma. The algorithm can help us to locate the lung nodules with higher accuracy. Then, the convolution neural network (CNN) optimized by genetic algorithm and the traditional CNN are used to extract the features of CT image of pulmonary nodules. The corresponding features of different images are automatically distinguished. By comparing the accuracy of the two algorithms, it is proved that the CNN optimized by genetic algorithm has higher accuracy. Finally, the CNN optimized by genetic algorithm is used to detect and classify the existing pulmonary nodule images, which provides guidance for CT image detection technology of pulmonary nodule. © 2013 IEEE.",11_tumor database; Bioinformatics; Cancer classification; Deep Learning; Machine Learning; Microarray gene expression,Bioinformatics; Classification (of information); Computer aided diagnosis; Convolutional neural networks; Database systems; Diseases; Gene expression; Learning algorithms; Learning systems; Logistic regression; Supervised learning; Tumors; Cancer classification; Classification methods; Comparative studies; Hardware and software; Identification accuracy; K fold cross validations; Microarray gene expression data; Supervised machine learning; Deep learning,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85085682566
"Qin R., Wang Z., Jiang L., Qiao K., Hai J., Chen J., Xu J., Shi D., Yan B.",Fine-Grained Lung Cancer Classification from PET and CT Images Based on Multidimensional Attention Mechanism,2020,Complexity,2020,,6153657,,,14,10.1155/2020/6153657,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078978609&doi=10.1155%2f2020%2f6153657&partnerID=40&md5=d5cb07f50031eee9d8c881229cf2d972,"PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Department of Radiology, Henan Provincial People's Hospital, Zhengzhou, 450002, China","Qin, R., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Wang, Z., Department of Radiology, Henan Provincial People's Hospital, Zhengzhou, 450002, China; Jiang, L., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Qiao, K., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Hai, J., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Chen, J., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China; Xu, J., Department of Radiology, Henan Provincial People's Hospital, Zhengzhou, 450002, China; Shi, D., Department of Radiology, Henan Provincial People's Hospital, Zhengzhou, 450002, China; Yan, B., PLA Strategy Support Force Information Engineering University, Zhengzhou, 450001, China","The analysis of multi-modality positron emission tomography and computed tomography (PET-CT) images for computer-aided diagnosis applications (e.g., detection and segmentation) requires combining the sensitivity of PET to detect abnormal regions with anatomical localization from CT. Current methods for PET-CT image analysis either process the modalities separately or fuse information from each modality based on knowledge about the image analysis task. These methods generally do not consider the spatially varying visual characteristics that encode different information across different modalities, which have different priorities at different locations. For example, a high abnormal PET uptake in the lungs is more meaningful for tumor detection than physiological PET uptake in the heart. Our aim is to improve the fusion of the complementary information in multi-modality PET-CT with a new supervised convolutional neural network (CNN) that learns to fuse complementary information for multi-modality medical image analysis. Our CNN first encodes modality-specific features and then uses them to derive a spatially varying fusion map that quantifies the relative importance of each modality's feature across different spatial locations. These fusion maps are then multiplied with the modality-specific feature maps to obtain a representation of the complementary multi-modality information at different locations, which can then be used for image analysis. We evaluated the ability of our CNN to detect and segment multiple regions (lungs, mediastinum, and tumors) with different fusion requirements using a dataset of PET-CT images of lung cancer. We compared our method to baseline techniques for multi-modality image fusion (fused inputs (FSs), multi-branch (MB) techniques, and multi-channel (MC) techniques) and segmentation. Our findings show that our CNN had a significantly higher foreground detection accuracy (99.29%, p < {0.05) than the fusion baselines (FS: 99.00%, MB: 99.08%, and TC: 98.92%) and a significantly higher Dice score (63.85%) than the recent PET-CT tumor segmentation methods. © 1982-2012 IEEE.",,Biological organs; Clinical research; Computer aided diagnosis; Deep learning; Diseases; Extraction; Image classification; Medical computing; Area under the ROC curve; Attention mechanisms; Automated diagnosis; Automatic diagnosis; Comparative analysis; Learning architectures; Non-invasive diagnosis; Quantitative evaluation; Computerized tomography,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85078978609
"Cao H., Liu H., Song E., Hung C.-C., Ma G., Xu X., Jin R., Lu J.",Dual-branch residual network for lung nodule segmentation,2020,Applied Soft Computing Journal,86,,105934,,,44,10.1016/j.asoc.2019.105934,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075371721&doi=10.1016%2fj.asoc.2019.105934&partnerID=40&md5=002f56e8542efc61c231c2c83384a32f,"Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Kennesaw State University, The Laboratory for Machine Vision and Security Research, 1000 Chastain Rd., Kennesaw, GA  30144, United States","Cao, H., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Liu, H., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Song, E., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Hung, C.-C., Kennesaw State University, The Laboratory for Machine Vision and Security Research, 1000 Chastain Rd., Kennesaw, GA  30144, United States; Ma, G., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Xu, X., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Jin, R., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China; Lu, J., Huazhong University of Science and Technology, School of Computer Science & Technology, Wuhan, 430074, China","Computer aided detection (CADe) of pulmonary nodules plays an important role in assisting radiologists’ diagnosis and alleviating interpretation burden for lung cancer. Current CADe systems, aiming at simulating radiologists’ examination procedure, are built upon computer tomography (CT) images with feature extraction for detection and diagnosis. Human visual perception in CT image is reconstructed from sinogram, which is the original raw data acquired from CT scanner. In this work, different from the conventional image based CADe system, we propose a novel sinogram based CADe system in which the full projection information is used to explore additional effective features of nodules in the sinogram domain. Facing the challenges of limited research in this concept and unknown effective features in the sinogram domain, we design a new CADe system that utilizes the self-learning power of the convolutional neural network to learn and extract effective features from sinogram. The proposed system was validated on 208 patient cases from the publicly available online Lung Image Database Consortium database, with each case having at least one juxtapleural nodule annotation. Experimental results demonstrated that our proposed method obtained a value of 0.91 of the area under the curve (AUC) of receiver operating characteristic based on sinogram alone, comparing to 0.89 based on CT image alone. Moreover, a combination of sinogram and CT image could further improve the value of AUC to 0.92. This study indicates that pulmonary nodule detection in the sinogram domain is feasible with deep learning. © 2019, The Author(s).",Computer-aided diagnosis; Deep learning; Lung nodule segmentation; Residual neural networks,Biological organs; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Deep neural networks; Image enhancement; Image segmentation; Neural networks; Convolutional neural network; Generalization capability; Lung nodule segmentation; Multi-scale features; Robust segmentation; Sampling strategies; Segmentation performance; Similarity coefficients; Computerized tomography,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85075371721
"Gao Y., Tan J., Liang Z., Li L., Huo Y.",Improved computer-aided detection of pulmonary nodules via deep learning in the sinogram domain,2019,"Visual Computing for Industry, Biomedicine, and Art",2,1,15,,,3,10.1186/s42492-019-0029-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098674697&doi=10.1186%2fs42492-019-0029-2&partnerID=40&md5=22f3a27240922dacc770c5c41ec777b3,"Department of Radiology, State University of New York, Stony Brook, NY  11794, United States; Departments of Computer Science, City University of New York/CSI, Staten Island, NY  10314, United States; Engineering and Environmental Science, City University of New York/CSI, Staten Island, NY  10314, United States","Gao, Y., Department of Radiology, State University of New York, Stony Brook, NY  11794, United States; Tan, J., Department of Radiology, State University of New York, Stony Brook, NY  11794, United States, Departments of Computer Science, City University of New York/CSI, Staten Island, NY  10314, United States; Liang, Z., Department of Radiology, State University of New York, Stony Brook, NY  11794, United States; Li, L., Engineering and Environmental Science, City University of New York/CSI, Staten Island, NY  10314, United States; Huo, Y., Departments of Computer Science, City University of New York/CSI, Staten Island, NY  10314, United States","Lung cancer is a serious illness which leads to increased mortality rate globally. The identification of lung cancer at the beginning stage is the probable method of improving the survival rate of the patients. Generally, Computed Tomography (CT) scan is applied for finding the location of the tumor and determines the stage of cancer. Existing works has presented an effective diagnosis classification model for CT lung images. This paper designs an effective diagnosis and classification model for CT lung images. The presented model involves different stages namely pre-processing, segmentation, feature extraction and classification. The initial stage includes an adaptive histogram based equalization (AHE) model for image enhancement and bilateral filtering (BF) model for noise removal. The pre-processed images are fed into the second stage of watershed segmentation model for effectively segment the images. Then, a deep learning based Xception model is applied for prominent feature extraction and the classification takes place by the use of logistic regression (LR) classifier. A comprehensive simulation is carried out to ensure the effective classification of the lung CT images using a benchmark dataset. The outcome implied the outstanding performance of the presented model on the applied test images. © BEIESP.",Computed tomography; Computer-aided detection; Deep learning; Lung; Sinogram,Biological organs; Computer aided diagnosis; Computer aided instruction; Deep learning; Feature extraction; Image enhancement; Neural networks; 'current; Areas under the curves; Computer aided detection; Computer aided detection systems; Computer tomography images; Deep learning; Lung Cancer; Pulmonary nodules; Sinogram domain; Sinograms; Computerized tomography,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85098674697
"Jayaraj D., Sathiamoorthy S.",Deep learning based depthwise separable model for effective diagnosis and classification of lung Ct images,2019,International Journal of Engineering and Advanced Technology,9,1,,1808,1819,2,10.35940/ijeat.A1439.109119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074752739&doi=10.35940%2fijeat.A1439.109119&partnerID=40&md5=90106b1bcf74004a8ec8bf7597453892,"Department of Computer Science & Engineering, Annamalai University, Chidambaram, India; Tamil Virtual Academy, Chennai, India","Jayaraj, D., Department of Computer Science & Engineering, Annamalai University, Chidambaram, India; Sathiamoorthy, S., Tamil Virtual Academy, Chennai, India","Lung cancer is one of the major causes of cancer-related deaths due to its aggressive nature and delayed detections at advanced stages. Early detection of lung cancer is very important for the survival of an individual, and is a significant challenging problem. Generally, chest radiographs (X-ray) and computed tomography (CT) scans are used initially for the diagnosis of the malignant nodules; however, the possible existence of benign nodules leads to erroneous decisions. At early stages, the benign and the malignant nodules show very close resemblance to each other. In this paper, a novel deep learning-based model with multiple strategies is proposed for the precise diagnosis of the malignant nodules. Due to the recent achievements of deep convolutional neural networks (CNN) in image analysis, we have used two deep three-dimensional (3D) customized mixed link network (CMixNet) architectures for lung nodule detection and classification, respectively. Nodule detections were performed through faster R-CNN on efficiently-learned features from CMixNet and U-Net like encoder–decoder architecture. Classification of the nodules was performed through a gradient boosting machine (GBM) on the learned features from the designed 3D CMixNet structure. To reduce false positives and misdiagnosis results due to different types of errors, the final decision was performed in connection with physiological symptoms and clinical biomarkers. With the advent of the internet of things (IoT) and electro-medical technology, wireless body area networks (WBANs) provide continuous monitoring of patients, which helps in diagnosis of chronic diseases—especially metastatic cancers. The deep learning model for nodules’ detection and classification, combined with clinical factors, helps in the reduction of misdiagnosis and false positive (FP) results in early-stage lung cancer diagnosis. The proposed system was evaluated on LIDC-IDRI datasets in the form of sensitivity (94%) and specificity (91%), and better results were obatined compared to the existing methods. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Classification; CT images; Feature extraction; Lung cancer; Segmentation,,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85074752739
"Zhang S., Han F., Liang Z., Tan J., Cao W., Gao Y., Pomeroy M., Ng K., Hou W.",An investigation of CNN models for differentiating malignant from benign lesions using small pathologically proven datasets,2019,Computerized Medical Imaging and Graphics,77,,101645,,,19,10.1016/j.compmedimag.2019.101645,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071093088&doi=10.1016%2fj.compmedimag.2019.101645&partnerID=40&md5=8ae77cc9502150936e64e0b69fc97e6c,"Department of Radiology, Stony Brook University, Stony Brook, NY  11794, United States; Northeastern University, Shenyang, Liaoning  110819, China; Department of Biomedical Engineering, Stony Brook University, Stony Brook, NY  11794, United States; Department of Electrical & Computer Engineering, Stony Brook University, Stony Brook, NY  11794, United States; Department of Computer Science, City University of New York, the Graduate CenterNY  10016, United States; Department of Preventive Medicine, Stony Brook University, Stony Brook, NY  11794, United States","Zhang, S., Department of Radiology, Stony Brook University, Stony Brook, NY  11794, United States; Han, F., Northeastern University, Shenyang, Liaoning  110819, China; Liang, Z., Department of Radiology, Stony Brook University, Stony Brook, NY  11794, United States, Department of Biomedical Engineering, Stony Brook University, Stony Brook, NY  11794, United States, Department of Electrical & Computer Engineering, Stony Brook University, Stony Brook, NY  11794, United States; Tan, J., Department of Computer Science, City University of New York, the Graduate CenterNY  10016, United States; Cao, W., Department of Radiology, Stony Brook University, Stony Brook, NY  11794, United States; Gao, Y., Department of Radiology, Stony Brook University, Stony Brook, NY  11794, United States; Pomeroy, M., Department of Biomedical Engineering, Stony Brook University, Stony Brook, NY  11794, United States; Ng, K., Department of Electrical & Computer Engineering, Stony Brook University, Stony Brook, NY  11794, United States; Hou, W., Department of Preventive Medicine, Stony Brook University, Stony Brook, NY  11794, United States","While deep learning methods have demonstrated performance comparable to human readers in tasks such as computer-aided diagnosis, these models are difficult to interpret, do not incorporate prior domain knowledge, and are often considered as a “black-box.” The lack of model interpretability hinders them from being fully understood by end users such as radiologists. In this paper, we present a novel interpretable deep hierarchical semantic convolutional neural network (HSCNN) to predict whether a given pulmonary nodule observed on a computed tomography (CT) scan is malignant. Our network provides two levels of output: 1) low-level semantic features; and 2) a high-level prediction of nodule malignancy. The low-level outputs reflect diagnostic features often reported by radiologists and serve to explain how the model interprets the images in an expert-interpretable manner. The information from these low-level outputs, along with the representations learned by the convolutional layers, are then combined and used to infer the high-level output. This unified architecture is trained by optimizing a global loss function including both low- and high-level tasks, thereby learning all the parameters within a joint framework. Our experimental results using the Lung Image Database Consortium (LIDC) show that the proposed method not only produces interpretable lung cancer predictions but also achieves better results compared to using a 3D CNN alone. © 2019 Elsevier Ltd",Cancer imaging; Convolutional neural network; Machine learning; Nodule characterization; Pathologically proven datasets; Polyp characterization,"Computerized tomography; Convolution; Deep learning; Diseases; Image enhancement; Large dataset; Learning systems; Medical imaging; Neural networks; Cancer imaging; Classification performance; Computed tomographic; Convolutional neural network; Local binary patterns; Pathologically proven datasets; Receiver operating curves; Unbalanced datasets; Classification (of information); adenomatous polyp; adult; aged; area under the curve; Article; benign neoplasm; clinical feature; colorectal polyp; comparative study; controlled study; convolutional neural network; deep learning; diagnostic imaging; diagnostic test accuracy study; female; human; image processing; learning algorithm; lung nodule; machine learning; major clinical study; male; malignant neoplasm; priority journal; quantitative analysis; sensitivity and specificity; villous adenoma; visual field; x-ray computed tomography; colorectal tumor; computer assisted diagnosis; differential diagnosis; information processing; lung tumor; middle aged; pathology; procedures; very elderly; Aged; Aged, 80 and over; Colorectal Neoplasms; Datasets as Topic; Diagnosis, Computer-Assisted; Diagnosis, Differential; Female; Humans; Lung Neoplasms; Male; Middle Aged; Neural Networks, Computer; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85071093088
"Nasrullah N., Sang J., Alam M.S., Mateen M., Cai B., Hu H.",Automated lung nodule detection and classification using deep learning combined with multiple strategies,2019,Sensors (Switzerland),19,17,3722,,,96,10.3390/s19173722,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071753712&doi=10.3390%2fs19173722&partnerID=40&md5=3637e3d90e424d3a2f28d232cdeba48a,"Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; Department of Software Engineering, Foundation University Islamabad, Islamabad, 44000, Pakistan; Frank H. Dotterweich College of Engineering, Texas A&M University—Kingsville, Kingsville, TX  78363-8202, United States","Nasrullah, N., Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China, Department of Software Engineering, Foundation University Islamabad, Islamabad, 44000, Pakistan; Sang, J., Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; Alam, M.S., Frank H. Dotterweich College of Engineering, Texas A&M University—Kingsville, Kingsville, TX  78363-8202, United States; Mateen, M., Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; Cai, B., Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China; Hu, H., Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data & Software Engineering, Chongqing University, Chongqing, 401331, China","Currently, lung cancer has one of the highest mortality rates because it is often caught too late. Therefore, early detection is essential to reduce the risk of death. Pulmonary nodules are considered key indicators of primary lung cancer. Developing an efficient and accurate computer-aided diagnosis system for pulmonary nodule detection is an important goal. Typically, a computer-aided diagnosis system for pulmonary nodule detection consists of two parts: candidate nodule extraction and false-positive reduction of candidate nodules. The reduction of false positives (FPs) of candidate nodules remains an important challenge due to morphological characteristics of nodule height changes and similar characteristics to other organs. In this study, we propose a novel multi-scale heterogeneous three-dimensional (3D) convolutional neural network (MSH-CNN) based on chest computed tomography (CT) images. There are three main strategies of the design: (1) using multi-scale 3D nodule blocks with different levels of contextual information as inputs; (2) using two different branches of 3D CNN to extract the expression features; (3) using a set of weights which are determined by back propagation to fuse the expression features produced by step 2. In order to test the performance of the algorithm, we trained and tested on the Lung Nodule Analysis 2016 (LUNA16) dataset, achieving an average competitive performance metric (CPM) score of 0.874 and a sensitivity of 91.7% at two FPs/scan. Moreover, our framework is universal and can be easily extended to other candidate false-positive reduction tasks in 3D object detection, as well as 3D object classification. © 2019 by the authors.",Clinical biomarkers; Deep convolutional neural networks; Internet of things; Pulmonary nodules; Wireless body area networks,"Biological organs; Biomarkers; Biomedical engineering; Computer aided diagnosis; Computerized tomography; Convolution; Diseases; Internet of things; Network architecture; Neural networks; Wireless local area networks (WLAN); Automated lung nodule detection; Clinical biomarkers; Computed tomography scan; Convolutional neural network; Early-stage lung cancers; Internet of thing (IOT); Pulmonary nodules; Wireless body area network; Deep neural networks; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; factual database; human; image processing; lung; lung tumor; neoplasm; pathology; physiology; procedures; wireless communication; x-ray computed tomography; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Early Detection of Cancer; Humans; Image Processing, Computer-Assisted; Internet of Things; Lung; Lung Neoplasms; Neoplasms; Neural Networks, Computer; Radiographic Image Interpretation, Computer-Assisted; Tomography, X-Ray Computed; Wireless Technology",Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85071753712
"Kaur R., Doegar A.",Localization and classification of brain tumor using machine learning & deep learning techniques,2019,International Journal of Innovative Technology and Exploring Engineering,8,9,,59,66,8,10.35940/ijitee.I1010.0789S19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073272304&doi=10.35940%2fijitee.I1010.0789S19&partnerID=40&md5=b75803510cc5d4daeec7c7964731c7fc,"Department of Computer Science & Engineering, National Institute of Technical Teachers Training and Research (NITTTR), Chandigarh, India","Kaur, R., Department of Computer Science & Engineering, National Institute of Technical Teachers Training and Research (NITTTR), Chandigarh, India; Doegar, A., Department of Computer Science & Engineering, National Institute of Technical Teachers Training and Research (NITTTR), Chandigarh, India","The size and shape of a nodule are the essential indicators of malignancy in lung cancer diagnosis. However, effectively capturing the nodule's structural information from CT scans in a computer-aided system is a challenging task. Unlike previous models that proposed computationally intensive deep ensemble models or three-dimensional CNN models, we propose a lightweight, multiple view sampling based multi-section CNN architecture. The model obtains a nodule's cross sections from multiple view angles and encodes the nodule's volumetric information into a compact representation by aggregating information from its different cross sections via a view pooling layer. The compact feature is subsequently used for the task of nodule classification. The method does not require the nodule's spatial annotation and works directly on the cross sections generated from volume enclosing the nodule. We evaluated the proposed method on lung image database consortium (LIDC) and image database resource initiative (IDRI) dataset. It achieved the state-of-the-art performance with a mean 93.18% classification accuracy. The architecture could also be used to select the representative cross sections determining the nodule's malignancy that facilitates in the interpretation of results. Because of being lightweight, the model could be ported to mobile devices, which brings the power of artificial intelligence (AI) driven application directly into the practitioner's hand. © 2013 IEEE.",Brain Tumor; Machine Learning; MRI,,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85073272304
"Ponnada V.T., Naga Srinivasu S.V.",Edge AI system for pneumonia and lung cancer detection,2019,International Journal of Innovative Technology and Exploring Engineering,8,9,,1908,1915,4,10.35940/ijitee.i8584.078919,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070092727&doi=10.35940%2fijitee.i8584.078919&partnerID=40&md5=a2aded3b9082f77c4b282948a53bdd77,"Acharya Nagarjuna University, Nagarjuna Nagar, Guntur, Andhra Pradesh  522510, India; Computer science and engineering, Narasaraopeta Engineering College, Narasaraopet, Andhra Pradesh  522601, India","Ponnada, V.T., Acharya Nagarjuna University, Nagarjuna Nagar, Guntur, Andhra Pradesh  522510, India; Naga Srinivasu, S.V., Computer science and engineering, Narasaraopeta Engineering College, Narasaraopet, Andhra Pradesh  522601, India","Lung cancer is the top cause for deaths by cancers whose 5-year survival rate is less than 20%. To improve the survival rate of patients with lung cancers, the early detection and early diagnosis is significant. Furthermore, early detection of pulmonary nodules is essential for the detection and diagnosis of lung cancer in early stage. The National Lung Screening Trial (NLST) showed annual screening by low-dose computed tomography (LDCT) could help to reduce the deaths caused by lung cancer of high-risk subjects by 20% comparing with screening by chest radiography. In past decade, there has been lots of works on computer-aided detection (CADe) and computer-aided diagnosis (CADx) for pulmonary nodules in computed tomography (CT) scans, whose target is to detect, segment the nodules and further classify them into benign and malignant efficiently and precisely. This survey reviews some recent works on detection, segmentation and classification for pulmonary nodule in CT scans with deep learning techniques. © Journal of Medical Artificial Intelligence. All rights reserved.",Artificial Intelligence; CNN; Deep learning; Edge AI System; Lung Cancer Detection; Medical image analysis; Neural networks; Pneumonia Detection,,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85070092727
"Wu J., Qian T.","A survey of pulmonary nodule detection, segmentation and classification in computed tomography with deep learning techniques",2019,Journal of Medical Artificial Intelligence,2,April,8,,,14,10.21037/jmai.2019.04.01,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118278636&doi=10.21037%2fjmai.2019.04.01&partnerID=40&md5=1080ef1e1c7fb2f03446a41b17112cf1,"Technology Committee of Tencent Healthcare, Shenzhen, 518052, China","Wu, J., Technology Committee of Tencent Healthcare, Shenzhen, 518052, China; Qian, T., Technology Committee of Tencent Healthcare, Shenzhen, 518052, China","The accurate identification of malignant lung nodules on chest CT is critical for the early detection of lung cancer, which also offers patients the best chance of cure. Deep learning methods have recently been successfully introduced to computer vision problems, although substantial challenges remain in the detection of malignant nodules due to the lack of large training data sets. In this paper, we propose a multi-view knowledge-based collaborative (MV-KBC) deep model to separate malignant from benign nodules using limited chest CT data. Our model learns 3-D lung nodule characteristics by decomposing a 3-D nodule into nine fixed views. For each view, we construct a knowledge-based collaborative (KBC) submodel, where three types of image patches are designed to fine-tune three pre-trained ResNet-50 networks that characterize the nodules' overall appearance, voxel, and shape heterogeneity, respectively. We jointly use the nine KBC submodels to classify lung nodules with an adaptive weighting scheme learned during the error back propagation, which enables the MV-KBC model to be trained in an end-to-end manner. The penalty loss function is used for better reduction of the false negative rate with a minimal effect on the overall performance of the MV-KBC model. We tested our method on the benchmark LIDC-IDRI data set and compared it to the five state-of-the-art classification approaches. Our results show that the MV-KBC model achieved an accuracy of 91.60% for lung nodule classification with an AUC of 95.70%. These results are markedly superior to the state-of-the-art approaches. © 1982-2012 IEEE.",Convolutional neural networks (CNNs); Deep learning; Pulmonary nodule classification; Pulmonary nodule detection; Pulmonary nodule segmentation,,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85118278636
"Pesce E., Joseph Withey S., Ypsilantis P.-P., Bakewell R., Goh V., Montana G.",Learning to detect chest radiographs containing pulmonary lesions using visual attention networks,2019,Medical Image Analysis,53,,,26,38,42,10.1016/j.media.2018.12.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060047284&doi=10.1016%2fj.media.2018.12.007&partnerID=40&md5=84754f32ba8e1210188de9293e51377b,"Department of Biomedical Engineering, King's College London, London, United Kingdom; Department of Radiology, Guy's & St Thomas’ NHS Foundation Trust, London, United Kingdom; Department of Medicine, Imperial College Healthcare NHS Trust, London, United Kingdom; Department of Cancer Imaging, King's College London, London, United Kingdom","Pesce, E., Department of Biomedical Engineering, King's College London, London, United Kingdom; Joseph Withey, S., Department of Radiology, Guy's & St Thomas’ NHS Foundation Trust, London, United Kingdom, Department of Cancer Imaging, King's College London, London, United Kingdom; Ypsilantis, P.-P., Department of Biomedical Engineering, King's College London, London, United Kingdom; Bakewell, R., Department of Medicine, Imperial College Healthcare NHS Trust, London, United Kingdom; Goh, V., Department of Radiology, Guy's & St Thomas’ NHS Foundation Trust, London, United Kingdom, Department of Cancer Imaging, King's College London, London, United Kingdom; Montana, G., Department of Biomedical Engineering, King's College London, London, United Kingdom","Accurate and automatic segmentation of pulmonary nodules in 3D thoracic Computed Tomography (CT) images is of great significance for Computer-Aided medical Diagnosis (CAD) of lung cancer. Currently, this important task remains challenging for lack of the voxel-level annotation and training strategies that balance target/background voxels in thoracic CT images. In this paper, a new region-based network, called Nodule-plus Region-based CNN, is proposed to detect pulmonary nodules in 3D thoracic CT images effectively while synchronously generating an instance segmentation mask for every detected instance. Our new network is constructed with a stack of convolutional blocks in which lateral connections are used to alleviate the difficulty of vanishing gradients. In addition, in order to reduce annotation workload and make best use of unannotated samples, we proposed a new Deep Self-paced Active Learning (DSAL) strategy by combining Active Learning (AL) and Self-Paced Learning (SPL) strategies. For the purpose of evaluating the performance of our proposed Nodule-plus R-CNN, we conduct a series of experiments on the public LIDC-IDRI dataset, and our model achieves 0.66 Dice and 0.96 TP Dice, which are state-of-the-art best results of pulmonary nodule segmentation. When the amount of available annotated samples is limited, our model trained with the DSAL strategy performs much better than that trained with the standard strategy. © 2013 IEEE.",Deep learning; Image classification; Lung cancer; Object localisation; Visual attention; X-rays,"Biological organs; Classification (of information); Deep learning; Image classification; Learning algorithms; Medical applications; Natural language processing systems; Network architecture; Picture archiving and communication systems; Radiography; Reinforcement learning; X rays; Automated detection; Classification errors; Localisation; Lung Cancer; Machine learning approaches; Novel neural network; Training algorithms; Visual Attention; Behavioral research; algorithm; Article; automation; computer assisted radiography; deep learning; disease classification; feedback system; human; lung lesion; lung nodule; machine learning; natural language processing; priority journal; radiologist; reinforcement; thorax radiography; visual attention; computer assisted diagnosis; diagnostic imaging; information processing; lung disease; procedures; Algorithms; Datasets as Topic; Diagnosis, Computer-Assisted; Humans; Lung Diseases; Neural Networks, Computer; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85060047284
"Polat H., Mehr H.D.",Classification of pulmonary CT images by using hybrid 3D-deep convolutional neural network architecture,2019,Applied Sciences (Switzerland),9,5,940,,,49,10.3390/app9050940,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063694846&doi=10.3390%2fapp9050940&partnerID=40&md5=eedaf30424fc7b28c2cc18e2fd9e49a0,"Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, 06500, Turkey","Polat, H., Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, 06500, Turkey; Mehr, H.D., Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, 06500, Turkey","Pulmonary fissure detection in computed tomography (CT) is a critical component for automatic lobar segmentation. The majority of fissure detection methods use feature descriptors that are hand-crafted, low-level, and have local spatial extent. The design of such feature detectors is typically targeted toward normal fissure anatomy, yielding low sensitivity to weak, and abnormal fissures that are common in clinical data sets. Furthermore, local features commonly suffer from low specificity, as the complex textures in the lung can be indistinguishable from the fissure when the global context is not considered. We propose a supervised discriminative learning framework for simultaneous feature extraction and classification. The proposed framework, called FissureNet, is a coarse-to-fine cascade of two convolutional neural networks. The coarse-to-fine strategy alleviates the challenges associated with training a network to segment a thin structure that represents a small fraction of the image voxels. FissureNet was evaluated on a cohort of 3706 subjects with inspiration and expiration 3DCT scans from the COPDGene clinical trial and a cohort of 20 subjects with 4DCT scans from a lung cancer clinical trial. On both data sets, FissureNet showed superior performance compared with a deep learning approach using the U-Net architecture and a Hessian-based fissure detection method in terms of area under the precision-recall curve (PR-AUC). The overall PR-AUC for FissureNet, U-Net, and Hessian on the COPDGene (lung cancer) data set was 0.980 (0.966), 0.963 (0.937), and 0.158 (0.182), respectively. On a subset of 30 COPDGene scans, FissureNet was compared with a recently proposed advanced fissure detection method called derivative of sticks (DoS) and showed superior performance with a PR-AUC of 0.991 compared with 0.668 for DoS. © 1982-2012 IEEE.",Computed tomography; Convolutional neural network; Deep learning; Lung cancer diagnosis; Medical imaging; SVM classifier,,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85063694846
"Khosravan N., Celik H., Turkbey B., Jones E.C., Wood B., Bagci U.","A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning",2019,Medical Image Analysis,51,,,101,115,34,10.1016/j.media.2018.10.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055895805&doi=10.1016%2fj.media.2018.10.010&partnerID=40&md5=f9f5b157dddcbc6a837b8b7787f1aba3,"Center for Research in Computer Vision, University of Central FloridaFL, United States; Clinical Center, National Institutes of Health, Bethesda, MD, United States","Khosravan, N., Center for Research in Computer Vision, University of Central FloridaFL, United States; Celik, H., Clinical Center, National Institutes of Health, Bethesda, MD, United States; Turkbey, B., Clinical Center, National Institutes of Health, Bethesda, MD, United States; Jones, E.C., Clinical Center, National Institutes of Health, Bethesda, MD, United States; Wood, B., Clinical Center, National Institutes of Health, Bethesda, MD, United States; Bagci, U., Center for Research in Computer Vision, University of Central FloridaFL, United States","Volumetric lung tumor segmentation and accurate longitudinal tracking of tumor volume changes from computed tomography images are essential for monitoring tumor response to therapy. Hence, we developed two multiple resolution residually connected network (MRRN) formulations called incremental-MRRN and dense-MRRN. Our networks simultaneously combine features across multiple image resolution and feature levels through residual connections to detect and segment the lung tumors. We evaluated our method on a total of 1210 non-small cell (NSCLC) lung tumors and nodules from three data sets consisting of 377 tumors from the open-source Cancer Imaging Archive (TCIA), 304 advanced stage NSCLC treated with anti- PD-1 checkpoint immunotherapy from internal institution MSKCC data set, and 529 lung nodules from the Lung Image Database Consortium (LIDC). The algorithm was trained using 377 tumors from the TCIA data set and validated on the MSKCC and tested on LIDC data sets. The segmentation accuracy compared to expert delineations was evaluated by computing the dice similarity coefficient, Hausdorff distances, sensitivity, and precision metrics. Our best performing incremental-MRRN method produced the highest DSC of 0.74 ± 0.13 for TCIA, 0.75±0.12 for MSKCC, and 0.68±0.23 for the LIDC data sets. There was no significant difference in the estimations of volumetric tumor changes computed using the incremental-MRRN method compared with the expert segmentation. In summary, we have developed a multi-scale CNN approach for volumetrically segmenting lung tumors which enables accurate, automated identification of and serial measurement of tumor volumes in the lung. © 1982-2012 IEEE.",Attention; Eye-tracking; Graph sparsification; Lung cancer screening; Multi-task deep learning; Prostate cancer screening,"Biological organs; Clustering algorithms; Computer aided instruction; Deep learning; Diseases; Efficiency; Eye movements; Eye tracking; Graphic methods; Learning algorithms; Magnetic resonance imaging; Radiation; Radiology; Tumors; Urology; Attention; Computer Aided Diagnosis(CAD); Eye tracking technologies; Graph sparsification; Graph-based clustering; Lung cancer screening; Prostate cancers; Radiology reading rooms; Computer aided diagnosis; Article; cancer screening; collaborative learning; computer assisted diagnosis; computer assisted tomography; conceptual framework; diagnostic accuracy; eye tracking; learning algorithm; lung cancer; machine learning; multiparametric magnetic resonance imaging; priority journal; prostate cancer; qualitative analysis; quantitative analysis; radiologist; technology; algorithm; computer assisted diagnosis; diagnostic error; diagnostic imaging; early cancer diagnosis; eye movement; female; human; lung tumor; male; nuclear magnetic resonance imaging; prevention and control; procedures; prostate tumor; x-ray computed tomography; Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Diagnostic Errors; Early Detection of Cancer; Eye Movements; Female; Humans; Lung Neoplasms; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85055895805
"Masood A., Sheng B., Li P., Hou X., Wei X., Qin J., Feng D.",Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images,2018,Journal of Biomedical Informatics,79,,,117,128,108,10.1016/j.jbi.2018.01.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040686779&doi=10.1016%2fj.jbi.2018.01.005&partnerID=40&md5=47d37605644db9dd116bf96abd9341e4,"Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; Dept. of Computer Science, COMSATS Institute of Information Technology, Pakistan; Faculty of Information Technology, Macau University of Science and Technology, Macau; Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; School of Nursing, The Hong Kong Polytechnic University, Hong Kong; School of Information Technologies, The University of Sydney, Australia","Masood, A., Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China, Dept. of Computer Science, COMSATS Institute of Information Technology, Pakistan; Sheng, B., Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; Li, P., Faculty of Information Technology, Macau University of Science and Technology, Macau; Hou, X., Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; Wei, X., Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; Qin, J., School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Feng, D., School of Information Technologies, The University of Sydney, Australia","This paper focuses on the problem of lung nodule image classification, which plays a key role in lung cancer early diagnosis. In this work, we propose a novel model for lung nodule image feature representation that incorporates both local and global characters. First, lung nodule images are divided into local patches with Superpixel. Then these patches are transformed into fixed-length local feature vectors using unsupervised deep autoencoder (DAE). The visual vocabulary is constructed based on the local features and bag of visual words (BOVW) is used to describe the global feature representation of lung nodule image. Finally, softmax algorithm is employed for lung nodule type classification, which can assemble the whole training process as an end-to-end mode. Comprehensive evaluations are conducted on the widely used public available ELCAP lung image database. Experimental results with regard to different parameter setting, data augmentation, model sparsity, classifier algorithms, and model ensemble validate the effectiveness of our proposed approach. © 2018 Keming Mao et al.",Convolutional neural networks (CNN); Deep learning; Lung cancer stages; MBAN (Medical Body Area Network); mIoT (medical Internet of Things); Nodule detection,"Biological organs; Computer aided instruction; Computerized tomography; Convolution; Decision support systems; Deep learning; Diseases; Image classification; Internet of things; Medical information systems; Neural networks; Body Area Network; Convolutional Neural Networks (CNN); Lung Cancer; mIoT (medical Internet of Things); Nodule detection; Computer aided diagnosis; analytic method; Article; artificial neural network; cancer classification; cancer diagnosis; cancer staging; clinical article; clinical effectiveness; computer assisted diagnosis; computer assisted tomography; controlled study; decision support system; diagnostic accuracy; diagnostic test accuracy study; false positive result; fully convolutional neural network; human; Internet; lung cancer; lung nodule; machine learning; Medical Body Area Network; medical Internet of Thing; priority journal; retrospective study; sensitivity and specificity; algorithm; automated pattern recognition; cancer staging; clinical decision support system; computer assisted diagnosis; decision making; diagnostic imaging; factual database; image processing; lung; lung nodule; lung tumor; procedures; software; symptom assessment; x-ray computed tomography; Algorithms; Databases, Factual; Decision Making; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Internet; Lung; Lung Neoplasms; Machine Learning; Neoplasm Staging; Neural Networks (Computer); Pattern Recognition, Automated; Software; Solitary Pulmonary Nodule; Symptom Assessment; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85040686779
"Mao K., Tang R., Wang X., Zhang W., Wu H.",Feature Representation Using Deep Autoencoder for Lung Nodule Image Classification,2018,Complexity,2018,,3078374,,,19,10.1155/2018/3078374,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047554436&doi=10.1155%2f2018%2f3078374&partnerID=40&md5=364544b995e2b0b9afc00afbd9364af9,"College of Software, Northeastern University, Shenyang, Liaoning Province, 110004, China; China Mobile Group Zhejiang Co. Ltd., Hanzhou, Zhejiang Province, 310016, China","Mao, K., College of Software, Northeastern University, Shenyang, Liaoning Province, 110004, China; Tang, R., China Mobile Group Zhejiang Co. Ltd., Hanzhou, Zhejiang Province, 310016, China; Wang, X., College of Software, Northeastern University, Shenyang, Liaoning Province, 110004, China; Zhang, W., College of Software, Northeastern University, Shenyang, Liaoning Province, 110004, China; Wu, H., College of Software, Northeastern University, Shenyang, Liaoning Province, 110004, China","Automatic detection of pulmonary nodules in thoracic computed tomography (CT) scans has been an active area of research for the last two decades. However, there have only been few studies that provide a comparative performance evaluation of different systems on a common database. We have therefore set up the LUNA16 challenge, an objective evaluation framework for automatic nodule detection algorithms using the largest publicly available reference database of chest CT scans, the LIDC-IDRI data set. In LUNA16, participants develop their algorithm and upload their predictions on 888 CT scans in one of the two tracks: 1) the complete nodule detection track where a complete CAD system should be developed, or 2) the false positive reduction track where a provided set of nodule candidates should be classified. This paper describes the setup of LUNA16 and presents the results of the challenge so far. Moreover, the impact of combining individual systems on the detection performance was also investigated. It was observed that the leading solutions employed convolutional networks and used the provided set of nodule candidates. The combination of these solutions achieved an excellent sensitivity of over 95% at fewer than 1.0 false positives per scan. This highlights the potential of combining algorithms to improve the detection performance. Our observer study with four expert readers has shown that the best system detects nodules that were missed by expert readers who originally annotated the LIDC-IDRI data. We released this set of additional nodules for further development of CAD systems. © 2017 Elsevier B.V.",,Biological organs; Computer aided diagnosis; Learning systems; Classifier algorithms; Comprehensive evaluation; Feature representation; Global feature representations; Image feature representation; Local feature vectors; Type classifications; Visual vocabularies; Image classification,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85047554436
"Setio A.A.A., Traverso A., de Bel T., Berens M.S.N., Bogaard C.V.D., Cerello P., Chen H., Dou Q., Fantacci M.E., Geurts B., Gugten R.V.D., Heng P.A., Jansen B., de Kaste M.M.J., Kotov V., Lin J.Y.-H., Manders J.T.M.C., Sóñora-Mengana A., García-Naranjo J.C., Papavasileiou E., Prokop M., Saletta M., Schaefer-Prokop C.M., Scholten E.T., Scholten L., Snoeren M.M., Torres E.L., Vandemeulebroucke J., Walasek N., Zuidhof G.C.A., Ginneken B.V., Jacobs C.","Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: The LUNA16 challenge",2017,Medical Image Analysis,42,,,1,13,421,10.1016/j.media.2017.06.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024499580&doi=10.1016%2fj.media.2017.06.015&partnerID=40&md5=da9b8004ff533e1c464723bfa42214da,"Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands; Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Department of Radiology, Meander Medisch Centrum, Amersfoort, Netherlands; Centro de Biofísica Médica, Universidad de Oriente, Santiago de Cuba, Cuba; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussels, Belgium; IMEC, Leuven, Belgium; Department of Applied Science and Technology, Polytechnic University of Turin, Turin, Italy; Turin Section of Istituto Nazionale di Fisica Nucleare, Turin, Italy; Pisa Section of Istituto Nazionale di Fisica Nucleare, Pisa, Italy; Yan'an Xi Lu 129, 9th floor, Shanghai, China; Department of Physics, University of Pisa, Pisa, Italy; Center of Applied Technologies and Nuclear Development, La Habana, Cuba; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Radboud University, Nijmegen, Netherlands; Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Fraunhofer MEVIS, Bremen, Germany","Setio, A.A.A., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Department of Radiology, Meander Medisch Centrum, Amersfoort, Netherlands, Department of Applied Science and Technology, Polytechnic University of Turin, Turin, Italy, Turin Section of Istituto Nazionale di Fisica Nucleare, Turin, Italy, Fraunhofer MEVIS, Bremen, Germany; Traverso, A., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Department of Radiology, Meander Medisch Centrum, Amersfoort, Netherlands, Department of Applied Science and Technology, Polytechnic University of Turin, Turin, Italy, Turin Section of Istituto Nazionale di Fisica Nucleare, Turin, Italy, Fraunhofer MEVIS, Bremen, Germany; de Bel, T., Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Berens, M.S.N., Radboud University, Nijmegen, Netherlands; Bogaard, C.V.D., Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Cerello, P.; Chen, H., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Dou, Q., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Fantacci, M.E., Pisa Section of Istituto Nazionale di Fisica Nucleare, Pisa, Italy, Department of Physics, University of Pisa, Pisa, Italy; Geurts, B., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Gugten, R.V.D., Radboud University, Nijmegen, Netherlands; Heng, P.A., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Jansen, B., IMEC, Leuven, Belgium, Center of Applied Technologies and Nuclear Development, La Habana, Cuba; de Kaste, M.M.J., Radboud University, Nijmegen, Netherlands; Kotov, V., Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Lin, J.Y.-H., Yan'an Xi Lu 129, 9th floor, Shanghai, China; Manders, J.T.M.C., Radboud University, Nijmegen, Netherlands; Sóñora-Mengana, A., Centro de Biofísica Médica, Universidad de Oriente, Santiago de Cuba, Cuba, Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussels, Belgium, IMEC, Leuven, Belgium, Center of Applied Technologies and Nuclear Development, La Habana, Cuba; García-Naranjo, J.C., Centro de Biofísica Médica, Universidad de Oriente, Santiago de Cuba, Cuba; Papavasileiou, E., IMEC, Leuven, Belgium; Prokop, M., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Department of Radiology, Meander Medisch Centrum, Amersfoort, Netherlands, Fraunhofer MEVIS, Bremen, Germany; Saletta, M.; Schaefer-Prokop, C.M., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Department of Radiology, Meander Medisch Centrum, Amersfoort, Netherlands, Fraunhofer MEVIS, Bremen, Germany; Scholten, E.T., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Fraunhofer MEVIS, Bremen, Germany; Scholten, L., Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Snoeren, M.M., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Torres, E.L.; Vandemeulebroucke, J., IMEC, Leuven, Belgium; Walasek, N., Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, Netherlands; Zuidhof, G.C.A., Radboud University, Nijmegen, Netherlands; Ginneken, B.V., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands, Fraunhofer MEVIS, Bremen, Germany; Jacobs, C., Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, Netherlands",,Computed tomography; Computer-aided detection; Convolutional networks; Deep learning; Medical image challenges; Pulmonary nodules,"Computer aided instruction; Convolution; Deep learning; Medical imaging; Comparative performance; Computed tomography images; Computed tomography scan; Computer aided detection; Convolutional networks; Detection performance; False-positive reduction; Pulmonary nodules; Computerized tomography; algorithm; Article; automation; cancer screening; comparative study; computer assisted diagnosis; computer assisted tomography; false positive result; human; lung cancer; lung nodule; lung parenchyma; lung volume; priority journal; sensitivity and specificity; validation study; diagnostic imaging; factual database; lung nodule; lung tumor; procedures; three dimensional imaging; x-ray computed tomography; Algorithms; Databases, Factual; Humans; Imaging, Three-Dimensional; Lung Neoplasms; Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",Article,Final,"All Open Access, Green",Scopus,2-s2.0-85024499580
"Wang S., Zhou M., Liu Z., Liu Z., Gu D., Zang Y., Dong D., Gevaert O., Tian J.",Central focused convolutional neural networks: Developing a data-driven model for lung nodule segmentation,2017,Medical Image Analysis,40,,,172,183,237,10.1016/j.media.2017.06.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021726055&doi=10.1016%2fj.media.2017.06.014&partnerID=40&md5=067ebd5fb694ae854567017f00d548a0,"CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; University of Chinese Academy of Sciences, Beijing 100049, China; Guangdong General Hospital, Guangzhou, Guangdong 510080, China; Beijing Key Laboratory of Molecular Imaging, Beijing 100190, China","Wang, S., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Zhou, M., Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; Liu, Z., Guangdong General Hospital, Guangzhou, Guangdong 510080, China; Liu, Z., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; Gu, D., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Zang, Y., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Dong, D., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Gevaert, O., Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; Tian, J., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China, Beijing Key Laboratory of Molecular Imaging, Beijing 100190, China",,Computer-aided diagnosis; Convolutional neural networks; Deep learning; Lung nodule segmentation,"Biological organs; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Image segmentation; Neural networks; Convolutional neural network; Data-driven model; General hospitals; Learning strategy; Lung nodule segmentation; Nodule segmentation; Segmentation performance; Sensitive features; Computerized tomography; Article; comparative study; computer assisted tomography; controlled study; human; image analysis; image processing; lung nodule; outcome assessment; priority journal; artificial neural network; computer assisted diagnosis; diagnostic imaging; lung tumor; machine learning; procedures; sensitivity and specificity; x-ray computed tomography; Diagnosis, Computer-Assisted; Humans; Lung Neoplasms; Machine Learning; Neural Networks (Computer); Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Final,"All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85021726055
